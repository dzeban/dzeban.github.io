<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title type="text">Voluntary madness!</title>
  <id>http://alex.dzyoba.com/feed</id>
  <updated>2016-04-02T00:00:00Z</updated>
  <link href="http://alex.dzyoba.com" />
  <link href="http://alex.dzyoba.com/feed" rel="self" />
  <author>
    <name>Alex Dzyoba</name>
  </author>
  <generator>PyAtom</generator>
  <entry xml:base="http://alex.dzyoba.com/feed">
    <title type="text">Basic x86 interrupts</title>
    <id>programming/os-interrupts.html</id>
    <updated>2016-04-02T00:00:00Z</updated>
    <link href="programming/os-interrupts.html" />
    <author>
      <name>avd</name>
    </author>
    <content type="html">&lt;p&gt;From my&amp;nbsp;previous article on&amp;nbsp;a&amp;nbsp;&lt;a href="/programming/multiboot.html"&gt;multiboot kernel&lt;/a&gt;, we&amp;nbsp;saw how to&amp;nbsp;load a&amp;nbsp;trivial kernel, print text and halt forever. However, to&amp;nbsp;make it&amp;nbsp;usable I&amp;nbsp;want keyboard input, where things I&amp;nbsp;type will be&amp;nbsp;printed on&amp;nbsp;the screen.&lt;/p&gt;
&lt;p&gt;There is&amp;nbsp;more work than you might initially think because it&amp;nbsp;requires initialization of&amp;nbsp;x86 interrupts: this quirky and tricky x86 routine of&amp;nbsp;40 years legacy.&lt;/p&gt;
&lt;h2 id="x86-interrupts"&gt;x86 interrupts&lt;/h2&gt;
&lt;p&gt;Interrupts are events from devices to&amp;nbsp;the CPU signalizing that device has something to&amp;nbsp;tell, like user input on&amp;nbsp;the keyboard or&amp;nbsp;network packet arrival. Without interrupts you should’ve&amp;nbsp;been polling all your peripherals, thus wasting CPU time, introducing latency and being a&amp;nbsp;horrible person.&lt;/p&gt;
&lt;p&gt;There are 3 sources or&amp;nbsp;types of&amp;nbsp;interrupts:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;Hardware interrupts&amp;nbsp;&amp;mdash; comes from hardware devices like keyboard or&amp;nbsp;network card.&lt;/li&gt;
&lt;li&gt;Software interrupts&amp;nbsp;&amp;mdash; generated by&amp;nbsp;the software &lt;code&gt;int&lt;/code&gt; instruction. Before introducing &lt;code&gt;SYSENTER/SYSEXIT&lt;/code&gt; system calls invocation was implemented via software interrupt &lt;code&gt;int $0&amp;times;80&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Exceptions&amp;nbsp;&amp;mdash; generated by&amp;nbsp;CPU itself in&amp;nbsp;response to&amp;nbsp;some error like &amp;laquo;divide by&amp;nbsp;zero&amp;raquo; or&amp;nbsp;&amp;laquo;page fault&amp;raquo;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;x86 interrupt system is&amp;nbsp;tripartite in&amp;nbsp;the sense of&amp;nbsp;it&amp;nbsp;involves 3 parts to&amp;nbsp;work conjointly:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;&lt;strong&gt;Programmable Interrupt Controller (PIC)&lt;/strong&gt; must be&amp;nbsp;configured to&amp;nbsp;receive interrupt requests (IRQs) from devices and send them to&amp;nbsp;CPU.&lt;/li&gt;
&lt;li&gt;CPU must be&amp;nbsp;configured to&amp;nbsp;receive IRQs from PIC and invoke correct interrupt handler, via gate described in&amp;nbsp;a&amp;nbsp;&lt;strong&gt;Interrupt Descriptor Table (IDT)&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Operating system kernel must provide &lt;strong&gt;Interrupt Service Routines (ISRs)&lt;/strong&gt; to&amp;nbsp;handle interrupts and be&amp;nbsp;ready to&amp;nbsp;be&amp;nbsp;preempted by&amp;nbsp;an&amp;nbsp;interrupt. It&amp;nbsp;also must configure both PIC and CPU to&amp;nbsp;enable interrupts.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Here is&amp;nbsp;the reference figure, check it&amp;nbsp;as&amp;nbsp;you read throught the article&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img src="/assets/img/interrupts.png" alt="x86 interrupt system" /&gt;
&lt;p class="caption"&gt;x86 interrupt system&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Before proceeding to&amp;nbsp;configuring interrupts we&amp;nbsp;must have GDT setup as&amp;nbsp;we&amp;nbsp;&lt;a href="/programming/os-segmentation.html"&gt;did before&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="programmable-interrupt-controller-pic"&gt;Programmable interrupt controller (PIC)&lt;/h2&gt;
&lt;p&gt;PIC is&amp;nbsp;the piece of&amp;nbsp;hardware that various peripheral devices are connected to&amp;nbsp;instead of&amp;nbsp;CPU. Being essentially a&amp;nbsp;multiplexer/proxy, it&amp;nbsp;saves CPU pins and provides several nice features:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;More interrupt lines via PIC chaining (2 PICs give 15 interrupt lines)&lt;/li&gt;
&lt;li&gt;Ability to&amp;nbsp;mask particular interrupt line instead of&amp;nbsp;all (&lt;code&gt;cli&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Interrupts queueing, i.e. order interrupts delivery to&amp;nbsp;the CPU. When some interrupt is&amp;nbsp;disabled, PIC queues it&amp;nbsp;for later delivery instead of&amp;nbsp;dropping.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Original IBM PCs had separate 8259 PIC chip. Later it&amp;nbsp;was integrated as&amp;nbsp;part of&amp;nbsp;southbridge/ICH/PCH. Modern PC&amp;nbsp;systems have APIC (advanced programmable interrupt controller) that solves interrupts routing problems for &lt;nobr&gt;multi-core&lt;/nobr&gt;/processors machines. But for backward compatibility APIC emulates good ol’ 8259 PIC. So&amp;nbsp;if&amp;nbsp;you’re&amp;nbsp;not on&amp;nbsp;an&amp;nbsp;ancient hardware, you actually have an&amp;nbsp;APIC that is&amp;nbsp;configured in&amp;nbsp;some way by&amp;nbsp;you or&amp;nbsp;BIOS. In&amp;nbsp;this article, I&amp;nbsp;will rely on&amp;nbsp;BIOS configuration and will not configure PIC for 2 reasons. First, it’s&amp;nbsp;a&amp;nbsp;shitload of&amp;nbsp;quirks that impossible for the sensible human to&amp;nbsp;figure out, and second, later we&amp;nbsp;will configure APIC mode for SMP. BIOS will configure APIC as&amp;nbsp;in&amp;nbsp;IBM PC&amp;nbsp;AT&amp;nbsp;machine, i.e. 2 PICs with 15 lines.&lt;/p&gt;
&lt;p&gt;Apart from the line for raising interrupts in&amp;nbsp;CPU, PIC is&amp;nbsp;connected to&amp;nbsp;the CPU data bus. This bus is&amp;nbsp;used to&amp;nbsp;send IRQ number from PIC to&amp;nbsp;CPU and to&amp;nbsp;send configuration commands from CPU to&amp;nbsp;PIC. Configuration commands include PIC initialization (again, won’t&amp;nbsp;do&amp;nbsp;this for now), IRQ masking, &lt;nobr&gt;End-Of-Interrupt&lt;/nobr&gt; (EOI) command and so&amp;nbsp;on.&lt;/p&gt;
&lt;h2 id="interrupt-descriptor-table-idt"&gt;Interrupt descriptor table (IDT)&lt;/h2&gt;
&lt;p&gt;Interrupt descriptor table (IDT) is&amp;nbsp;an&amp;nbsp;x86 system table that holds descriptors for Interrupt Service Routines (ISRs) or&amp;nbsp;simply interrupt handlers.&lt;/p&gt;
&lt;p&gt;In&amp;nbsp;real mode, there is&amp;nbsp;an&amp;nbsp;IVT (interrupt vector table) that’s&amp;nbsp;located by&amp;nbsp;the fixed address &lt;code&gt;0&amp;times;0&lt;/code&gt; and contains &amp;laquo;interrupt handler pointers&amp;raquo; in&amp;nbsp;the form of&amp;nbsp;CS&amp;nbsp;and IP&amp;nbsp;registers values. This is&amp;nbsp;really inflexible and relies on&amp;nbsp;segmented memory management, and since 80286, there is&amp;nbsp;an&amp;nbsp;IDT for protected mode.&lt;/p&gt;
&lt;p&gt;IDT is&amp;nbsp;the table in&amp;nbsp;memory, created and filled by&amp;nbsp;OS&amp;nbsp;that is&amp;nbsp;pointed by&amp;nbsp;&lt;code&gt;idtr&lt;/code&gt; system register which is&amp;nbsp;loaded with &lt;code&gt;lidt&lt;/code&gt; instruction. You can use IDT only in&amp;nbsp;protected mode. IDT entries contain gate descriptors&amp;nbsp;&amp;mdash; not only addresses of&amp;nbsp;interrupts handlers (ISRs) in&amp;nbsp;&lt;nobr&gt;32-bit&lt;/nobr&gt; form but also flags and protection levels. IDT entries are descriptors that describe interrupt gates, and so&amp;nbsp;in&amp;nbsp;this sense, it&amp;nbsp;resembles GDT and its segment descriptors. Just look at&amp;nbsp;them:&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img src="/assets/img/idt-descriptor.png" alt="IDT descriptor" /&gt;
&lt;p class="caption"&gt;IDT descriptor&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The main part of&amp;nbsp;the descriptor is&amp;nbsp;offset&amp;nbsp;&amp;mdash; essentially a&amp;nbsp;pointer to&amp;nbsp;an&amp;nbsp;ISR within code segment chosen by&amp;nbsp;segment selector. The latter consists of&amp;nbsp;an&amp;nbsp;index in&amp;nbsp;GDT table, table indicator (GDT or&amp;nbsp;LDT) and Request Privilege Level (RPL). For interrupt gates, selectors are always for Kernel code segment in&amp;nbsp;GDT, that is&amp;nbsp;it’s&amp;nbsp;0&amp;times;08 for first GDT entry (each is&amp;nbsp;8 byte) with 0 RPL and 0 for GDT.&lt;/p&gt;
&lt;p&gt;Type specifies gate type&amp;nbsp;&amp;mdash; task, trap or&amp;nbsp;interrupt. For interrupt handleri, we’ll&amp;nbsp;use interrupt gate, because for interrupt gate CPU will clear IF&amp;nbsp;flag as&amp;nbsp;opposed to&amp;nbsp;trap gate, and TSS won’t&amp;nbsp;be&amp;nbsp;used as&amp;nbsp;opposed to&amp;nbsp;task gate (we&amp;nbsp;don’t&amp;nbsp;have one yet).&lt;/p&gt;
&lt;p&gt;So&amp;nbsp;basically, you just fill the IDT with descriptors that differ only in&amp;nbsp;offset, where you put the address of&amp;nbsp;ISR function.&lt;/p&gt;
&lt;h2 id="interrupt-service-routines-isr"&gt;Interrupt service routines (ISR)&lt;/h2&gt;
&lt;p&gt;The main purpose of&amp;nbsp;IDT is&amp;nbsp;to&amp;nbsp;store pointers to&amp;nbsp;ISR that will be&amp;nbsp;automatically invoked by&amp;nbsp;CPU on&amp;nbsp;interrupt receive. The important thing here is&amp;nbsp;that you can NOT control invocation of&amp;nbsp;an&amp;nbsp;interrupt handler. Once you have configured IDT and enabled interrupts (&lt;code&gt;sti&lt;/code&gt;) CPU will eventually pass the control to&amp;nbsp;your handler after some behind the curtain work. That &amp;laquo;behind the curtain work&amp;raquo; is&amp;nbsp;important to&amp;nbsp;know.&lt;/p&gt;
&lt;p&gt;If&amp;nbsp;interrupt occurred in&amp;nbsp;userspace (actually in&amp;nbsp;a&amp;nbsp;different privilege level), CPU does the following&lt;a href="#fn1" class="footnoteRef" id="fnref1"&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;Temporarily saves (internally) the current contents of&amp;nbsp;the SS, ESP, EFLAGS, CS&amp;nbsp;and EIP registers.&lt;/li&gt;
&lt;li&gt;Loads the segment selector and stack pointer for the new stack (that is, the stack for the privilege level being called) from the TSS into the SS&amp;nbsp;and ESP registers and switches to&amp;nbsp;the new stack.&lt;/li&gt;
&lt;li&gt;Pushes the temporarily saved SS, ESP, EFLAGS, CS, and EIP values for the interrupted procedure’s&amp;nbsp;stack onto the new stack.&lt;/li&gt;
&lt;li&gt;Pushes an&amp;nbsp;error code on&amp;nbsp;the new stack (if&amp;nbsp;appropriate).&lt;/li&gt;
&lt;li&gt;Loads the segment selector for the new code segment and the new instruction pointer (from the interrupt gate or&amp;nbsp;trap gate) into the CS&amp;nbsp;and EIP registers, respectively.&lt;/li&gt;
&lt;li&gt;If&amp;nbsp;the call is&amp;nbsp;through an&amp;nbsp;interrupt gate, clears the IF&amp;nbsp;flag in&amp;nbsp;the EFLAGS register.&lt;/li&gt;
&lt;li&gt;Begins execution of&amp;nbsp;the handler procedure at&amp;nbsp;the new privilege level.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If&amp;nbsp;an&amp;nbsp;interrupt occurred in&amp;nbsp;kernel space, CPU will not switch stacks, meaning that in&amp;nbsp;kernel space interrupt doesn’t&amp;nbsp;have its own stack, instead it&amp;nbsp;uses the stack of&amp;nbsp;the interrupted procedure. On&amp;nbsp;x64 it&amp;nbsp;may lead to&amp;nbsp;stack corruption because of&amp;nbsp;the red zone, that’s&amp;nbsp;why kernel code must be&amp;nbsp;compiled with &lt;code&gt;-&lt;nobr&gt;mno-red-zone&lt;/nobr&gt;&lt;/code&gt;. I&amp;nbsp;have &lt;a href="/programming/redzone.html"&gt;a&amp;nbsp;funny story about this&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;When interrupt occurs in&amp;nbsp;kernel mode, CPU will:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;Push the current contents of&amp;nbsp;the EFLAGS, CS, and EIP registers (in&amp;nbsp;that order) on&amp;nbsp;the stack.&lt;/li&gt;
&lt;li&gt;Push an&amp;nbsp;error code (if&amp;nbsp;appropriate) on&amp;nbsp;the stack.&lt;/li&gt;
&lt;li&gt;Load the segment selector for the new code segment and the new instruction pointer (from the interrupt gate or&amp;nbsp;trap gate) into the CS&amp;nbsp;and EIP registers, respectively.&lt;/li&gt;
&lt;li&gt;Clear the IF&amp;nbsp;flag in&amp;nbsp;the EFLAGS, if&amp;nbsp;the call is&amp;nbsp;through an&amp;nbsp;interrupt gate.&lt;/li&gt;
&lt;li&gt;Begin execution of&amp;nbsp;the handler procedure.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Note, that these 2 cases differ in&amp;nbsp;what is&amp;nbsp;pushed onto the stack. EFLAGS, CS&amp;nbsp;and EIP is&amp;nbsp;always pushed while interrupt in&amp;nbsp;userspace mode will additionally push old SS&amp;nbsp;and ESP.&lt;/p&gt;
&lt;p&gt;This means that when interrupt handler begins it&amp;nbsp;has the following stack:&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img src="/assets/img/isr-stack.png" alt="ISR stack" /&gt;
&lt;p class="caption"&gt;ISR stack&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Now, when the control is&amp;nbsp;passed to&amp;nbsp;the interrupt handler, what should it&amp;nbsp;do?&lt;/p&gt;
&lt;p&gt;Remember, that interrupt occurred in&amp;nbsp;the middle of&amp;nbsp;some code in&amp;nbsp;userspace or&amp;nbsp;even kernelspace, so&amp;nbsp;the first thing to&amp;nbsp;do&amp;nbsp;is&amp;nbsp;to&amp;nbsp;save the state of&amp;nbsp;the interrupted procedure before proceeding to&amp;nbsp;interrupt handling. Procedure state is&amp;nbsp;defined by&amp;nbsp;its registers, and there is&amp;nbsp;a&amp;nbsp;special instruction &lt;code&gt;pusha&lt;/code&gt; that saves general purpose registers onto the stack.&lt;/p&gt;
&lt;p&gt;Next thing is&amp;nbsp;to&amp;nbsp;completely switch the environment for interrupt handler in&amp;nbsp;the means of&amp;nbsp;segment registers. CPU automatically switches CS, so&amp;nbsp;interrupt handler must reload 4 data segment register DS, FS, ES&amp;nbsp;and GS. And don’t&amp;nbsp;forget to&amp;nbsp;save and later restore the previous values.&lt;/p&gt;
&lt;p&gt;After state is&amp;nbsp;saved and environment is&amp;nbsp;ready, interrupt handler should do&amp;nbsp;its work whatever it&amp;nbsp;is, but first and most important to&amp;nbsp;do&amp;nbsp;is&amp;nbsp;to&amp;nbsp;acknowledge interrupt by&amp;nbsp;sending special EOI command to&amp;nbsp;PIC.&lt;/p&gt;
&lt;p&gt;Finally, after doing all its work there should be&amp;nbsp;clean return from interrupt, that will restore the state of&amp;nbsp;interrupted procedure (restore data segment registers, &lt;code&gt;popa&lt;/code&gt;), enable interrupts (&lt;code&gt;sti&lt;/code&gt;) that were disabled by&amp;nbsp;CPU before entering ISR (penultimate step of&amp;nbsp;CPU work) and call &lt;code&gt;iret&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Here is&amp;nbsp;the basic ISR algorithm:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;Save the state of&amp;nbsp;interrupted procedure&lt;/li&gt;
&lt;li&gt;Save previous data segment&lt;/li&gt;
&lt;li&gt;Reload data segment registers with kernel data descriptors&lt;/li&gt;
&lt;li&gt;Acknowledge interrupt by&amp;nbsp;sending EOI to&amp;nbsp;PIC&lt;/li&gt;
&lt;li&gt;Do&amp;nbsp;the work&lt;/li&gt;
&lt;li&gt;Restore data segment&lt;/li&gt;
&lt;li&gt;Restore the state of&amp;nbsp;interrupted procedure&lt;/li&gt;
&lt;li&gt;Enable interrupts&lt;/li&gt;
&lt;li&gt;Exit interrupt handler with &lt;code&gt;iret&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="putting-it-all-together"&gt;Putting it&amp;nbsp;all together&lt;/h2&gt;
&lt;p&gt;Now to&amp;nbsp;complete the picture lets see how keyboard press is&amp;nbsp;handled:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;Setup interrupts:
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;Create IDT table&lt;/li&gt;
&lt;li&gt;Set IDT entry #9 &lt;a href="#fn2" class="footnoteRef" id="fnref2"&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; with interrupt gate pointing to&amp;nbsp;keyboard ISR&lt;/li&gt;
&lt;li&gt;Load IDT address with &lt;code&gt;lidt&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Send interrupt mask &lt;code&gt;0xfd&lt;/code&gt; (&lt;code&gt;11111101&lt;/code&gt;) to&amp;nbsp;PIC1 to&amp;nbsp;unmask (enable) IRQ1&lt;/li&gt;
&lt;li&gt;Enable interrupts with &lt;code&gt;sti&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;Human hits keyboard button&lt;/li&gt;
&lt;li&gt;Keyboard controller raises interrupt line IRQ1 in&amp;nbsp;PIC1&lt;/li&gt;
&lt;li&gt;PIC checks if&amp;nbsp;this line is&amp;nbsp;not masked (it’s&amp;nbsp;not) and send interrupt number 9 to&amp;nbsp;CPU&lt;/li&gt;
&lt;li&gt;CPU checks if&amp;nbsp;interrupts disabled by&amp;nbsp;checking IF&amp;nbsp;in&amp;nbsp;EFLAGS (it’s&amp;nbsp;not)&lt;/li&gt;
&lt;li&gt;(Assume that currently we’re&amp;nbsp;executing in&amp;nbsp;kernel mode)&lt;/li&gt;
&lt;li&gt;Push EFLAGS, CS, and EIP on&amp;nbsp;the stack&lt;/li&gt;
&lt;li&gt;Push an&amp;nbsp;error code from PIC (if&amp;nbsp;appropriate) on&amp;nbsp;the stack&lt;/li&gt;
&lt;li&gt;Look into IDT pointed by&amp;nbsp;&lt;code&gt;idtr&lt;/code&gt; and fetch segment selector from IDT descriptor 9.&lt;/li&gt;
&lt;li&gt;Check privilege levels and load segment selector and ISR address into the CS:EIP&lt;/li&gt;
&lt;li&gt;Clear IF&amp;nbsp;flag because IDT entries are interrupt gates&lt;/li&gt;
&lt;li&gt;Pass control to&amp;nbsp;ISR&lt;/li&gt;
&lt;li&gt;Receive interrupt in&amp;nbsp;ISR:
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;Disable interrupt with &lt;code&gt;cli&lt;/code&gt; (just in&amp;nbsp;case)&lt;/li&gt;
&lt;li&gt;Save interrupted procedure state with &lt;code&gt;pusha&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Push current DS&amp;nbsp;value on&amp;nbsp;the stack&lt;/li&gt;
&lt;li&gt;Reload DS, ES, FS, GS&amp;nbsp;from kernel data segment&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;Acknowledge interrupt by&amp;nbsp;sending EOI (&lt;code&gt;0&amp;times;20&lt;/code&gt;) to&amp;nbsp;master PIC (I/O port &lt;code&gt;0&amp;times;20&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Read keyboard status from keyboard controller (I/O port &lt;code&gt;0&amp;times;64&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;If&amp;nbsp;status is&amp;nbsp;1 then read keycode from keyboard controller (I/O port &lt;code&gt;0&amp;times;60&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Finally, print char via VGA buffer or&amp;nbsp;send it&amp;nbsp;to&amp;nbsp;TTY&lt;/li&gt;
&lt;li&gt;Return from interrupt:
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;Pop from stack and restore DS&lt;/li&gt;
&lt;li&gt;Restore interrupted procedure state with &lt;code&gt;popa&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Enable interrupts with &lt;code&gt;sti&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;iret&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Note, that this happens every time you hit the keyboard key. And don’t&amp;nbsp;forget that there are few dozens of&amp;nbsp;other interrupts like clocks, network packets and such that is&amp;nbsp;handled seamlessly without you even noticing that. Can you imagine how fast is&amp;nbsp;your hardware? Can you imagine how well written your operating system is? Now think about it&amp;nbsp;and give OS&amp;nbsp;writers and hardware designers a&amp;nbsp;good praise.&lt;/p&gt;
&lt;div class="footnotes"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn1"&gt;&lt;p&gt;Citing &amp;laquo;Intel software developer’s&amp;nbsp;manual, Volume 1&amp;raquo;.&lt;a href="#fnref1"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn2"&gt;&lt;p&gt;Without PIC programming and remapping interrupts, keyboard has interrupt number 9 in&amp;nbsp;CPU (but IRQ1 in&amp;nbsp;PIC)&lt;a href="#fnref2"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content>
  </entry>
  <entry xml:base="http://alex.dzyoba.com/feed">
    <title type="text">OS kernel segmentation</title>
    <id>programming/os-segmentation.html</id>
    <updated>2015-12-27T00:00:00Z</updated>
    <link href="programming/os-segmentation.html" />
    <author>
      <name>avd</name>
    </author>
    <content type="html">&lt;p&gt;Previously, I&amp;nbsp;had boot the &lt;a href="/programming/multiboot.html"&gt;trivial Multiboot kernel&lt;/a&gt;. Despite it&amp;nbsp;was really fun, I&amp;nbsp;need more than just showing a&amp;nbsp;letter on&amp;nbsp;a&amp;nbsp;screen. My&amp;nbsp;goal is&amp;nbsp;to&amp;nbsp;write a&amp;nbsp;simple kernel with &lt;nobr&gt;Unix-ready&lt;/nobr&gt; userspace.&lt;/p&gt;
&lt;p&gt;I&amp;nbsp;have been writing my&amp;nbsp;kernel for the last couple of&amp;nbsp;months (on&amp;nbsp;and off) and with help of&amp;nbsp;&lt;a href="http://wiki.osdev.org"&gt;OSDev wiki&lt;/a&gt; I&amp;nbsp;got a&amp;nbsp;quite good kernel based on&amp;nbsp;&lt;a href="http://wiki.osdev.org/Meaty_Skeleton"&gt;meaty skeleton&lt;/a&gt; and now I&amp;nbsp;want to&amp;nbsp;go&amp;nbsp;further. But where to? My&amp;nbsp;milestone is&amp;nbsp;to&amp;nbsp;make keyboard input working. This will require working interrupts, but it’s&amp;nbsp;not the first thing to&amp;nbsp;do.&lt;/p&gt;
&lt;p&gt;According to&amp;nbsp;Multiboot specification after bootloader passed the control to&amp;nbsp;our kernel, the machine is&amp;nbsp;in&amp;nbsp;pretty reasonable state except 3 things (quoting chapter &lt;a href="https://www.gnu.org/software/grub/manual/multiboot/html_node/Machine-state.html#Machine-state"&gt;3.2. Machine state&lt;/a&gt;):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;‘ESP’&amp;nbsp;&amp;mdash; The OS&amp;nbsp;image must create its own stack as&amp;nbsp;soon as&amp;nbsp;it&amp;nbsp;needs one.&lt;/li&gt;
&lt;li&gt;‘GDTR’&amp;nbsp;&amp;mdash; Even though the segment registers are set up&amp;nbsp;as&amp;nbsp;described above, the ‘GDTR’ may be&amp;nbsp;invalid, so&amp;nbsp;the OS&amp;nbsp;image must not load any segment registers (even just reloading the same values!) until it&amp;nbsp;sets up&amp;nbsp;its own ‘GDT’.&lt;/li&gt;
&lt;li&gt;‘IDTR’ The OS&amp;nbsp;image must leave interrupts disabled until it&amp;nbsp;sets up&amp;nbsp;its own IDT.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Setting up&amp;nbsp;a&amp;nbsp;stack is&amp;nbsp;simple&amp;nbsp;&amp;mdash; you just put 2 labels divided by&amp;nbsp;your stack size. &lt;a href="https://github.com/dzeban/hydra/blob/86b67dfe27001a9f21de64307eb6ec3395aecddd/arch/i386/boot.S#L15-L19"&gt;In&amp;nbsp;&amp;laquo;hydra&amp;raquo; it’s&amp;nbsp;16 KiB&lt;/a&gt;:&lt;/p&gt;
&lt;pre class="asm"&gt;&lt;code&gt;# Reserve a stack for the initial thread.
.section .bootstrap_stack, &amp;quot;aw&amp;quot;, @nobits
stack_bottom:
.skip 16384 # 16 KiB
stack_top:&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, we&amp;nbsp;need to&amp;nbsp;setup segmentation. We&amp;nbsp;have to&amp;nbsp;do&amp;nbsp;this before setting up&amp;nbsp;interrupts because each IDT descriptor gate must contain segment selector for destination code segment&amp;nbsp;&amp;mdash; a&amp;nbsp;kernel code segment that we&amp;nbsp;must setup.&lt;/p&gt;
&lt;p&gt;Nevertheless it&amp;nbsp;almost certainly will work even without setting up&amp;nbsp;GDT because Multiboot bootloader sets it&amp;nbsp;by&amp;nbsp;itself and we&amp;nbsp;left with its configuration that usually will set up&amp;nbsp;flat memory model. For example, here is&amp;nbsp;the GDT that legacy grub set:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class="header"&gt;
&lt;th align="left"&gt;Index&lt;/th&gt;
&lt;th align="left"&gt;Base&lt;/th&gt;
&lt;th align="left"&gt;Size&lt;/th&gt;
&lt;th align="left"&gt;DPL&lt;/th&gt;
&lt;th align="left"&gt;Info&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class="odd"&gt;
&lt;td align="left"&gt;00 (Selector 0&amp;times;0000)&lt;/td&gt;
&lt;td align="left"&gt;0&amp;times;0&lt;/td&gt;
&lt;td align="left"&gt;0xfff0&lt;/td&gt;
&lt;td align="left"&gt;0&lt;/td&gt;
&lt;td align="left"&gt;Unused&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class="even"&gt;
&lt;td align="left"&gt;01 (Selector 0&amp;times;0008)&lt;/td&gt;
&lt;td align="left"&gt;0&amp;times;0&lt;/td&gt;
&lt;td align="left"&gt;0xffffffff&lt;/td&gt;
&lt;td align="left"&gt;0&lt;/td&gt;
&lt;td align="left"&gt;&lt;nobr&gt;32-bit&lt;/nobr&gt; code&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class="odd"&gt;
&lt;td align="left"&gt;02 (Selector 0&amp;times;0010)&lt;/td&gt;
&lt;td align="left"&gt;0&amp;times;0&lt;/td&gt;
&lt;td align="left"&gt;0xffffffff&lt;/td&gt;
&lt;td align="left"&gt;0&lt;/td&gt;
&lt;td align="left"&gt;&lt;nobr&gt;32-bit&lt;/nobr&gt; data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class="even"&gt;
&lt;td align="left"&gt;03 (Selector 0&amp;times;0018)&lt;/td&gt;
&lt;td align="left"&gt;0&amp;times;0&lt;/td&gt;
&lt;td align="left"&gt;0xffff&lt;/td&gt;
&lt;td align="left"&gt;0&lt;/td&gt;
&lt;td align="left"&gt;&lt;nobr&gt;16-bit&lt;/nobr&gt; code&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class="odd"&gt;
&lt;td align="left"&gt;04 (Selector 0&amp;times;0020)&lt;/td&gt;
&lt;td align="left"&gt;0&amp;times;0&lt;/td&gt;
&lt;td align="left"&gt;0xffff&lt;/td&gt;
&lt;td align="left"&gt;0&lt;/td&gt;
&lt;td align="left"&gt;&lt;nobr&gt;16-bit&lt;/nobr&gt; data&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;It’s&amp;nbsp;fine for &lt;nobr&gt;kernel-only&lt;/nobr&gt; mode because it&amp;nbsp;has &lt;nobr&gt;32-bit&lt;/nobr&gt; segments for code and data of&amp;nbsp;size 2&lt;sup&gt;32&lt;/sup&gt;, but no&amp;nbsp;segments with DPL=3 and also &lt;nobr&gt;16-bit&lt;/nobr&gt; code segments that we&amp;nbsp;don’t&amp;nbsp;want.&lt;/p&gt;
&lt;p&gt;But really it&amp;nbsp;is&amp;nbsp;just plain stupid to&amp;nbsp;rely on&amp;nbsp;undefined values, so&amp;nbsp;we&amp;nbsp;set up&amp;nbsp;segmentation by&amp;nbsp;ourselves.&lt;/p&gt;
&lt;h2 id="segmentation-on-x86"&gt;Segmentation on&amp;nbsp;x86&lt;/h2&gt;
&lt;p&gt;Segmentation is&amp;nbsp;a&amp;nbsp;technique used in&amp;nbsp;x86 CPUs to&amp;nbsp;expand amount of&amp;nbsp;available memory. There are 2 different segmentation models depending on&amp;nbsp;CPU mode&amp;nbsp;&amp;mdash; &lt;nobr&gt;real-address&lt;/nobr&gt; model and protected model.&lt;/p&gt;
&lt;h3 id="segmentation-in-real-mode"&gt;Segmentation in&amp;nbsp;Real mode&lt;/h3&gt;
&lt;p&gt;Real mode is&amp;nbsp;a&amp;nbsp;&lt;nobr&gt;16-bit&lt;/nobr&gt; Intel 8086 CPU mode, it’s&amp;nbsp;a&amp;nbsp;mode where processor starts working upon reset. With a&amp;nbsp;&lt;nobr&gt;16-bit&lt;/nobr&gt; processor you may address at&amp;nbsp;most 2&lt;sup&gt;16&lt;/sup&gt; = 64 KiB of&amp;nbsp;memory which even by&amp;nbsp;the times of&amp;nbsp;1978 was way too small. So&amp;nbsp;Intel decided to&amp;nbsp;extend address space to&amp;nbsp;1 MiB and made address bus 20 bits wide (&lt;code&gt;2&lt;/code&gt;&lt;sup&gt;&lt;code&gt;20&lt;/code&gt;&lt;/sup&gt;&lt;code&gt;= 1048576 bytes = 1 MiB&lt;/code&gt;). But you can’t&amp;nbsp;address 20 bits wide address space with &lt;nobr&gt;16-bit&lt;/nobr&gt; registers, you have to&amp;nbsp;expand your registers by&amp;nbsp;4 bits. This is&amp;nbsp;where segmentation comes in.&lt;/p&gt;
&lt;p&gt;The idea of&amp;nbsp;segmentation is&amp;nbsp;to&amp;nbsp;organize address space in&amp;nbsp;chunks called segments, where your address from &lt;nobr&gt;16-bit&lt;/nobr&gt; register would be&amp;nbsp;an&amp;nbsp;offset in&amp;nbsp;the segment.&lt;/p&gt;
&lt;p&gt;With segmentation you use 2 registers to&amp;nbsp;address memory: segment register and &lt;nobr&gt;general-purpose&lt;/nobr&gt; register representing offset. Linear address (the one that will be&amp;nbsp;issued on&amp;nbsp;the address bus of&amp;nbsp;CPU) is&amp;nbsp;calculated like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Linear address = Segment &amp;lt;&amp;lt; 4 + Offset&lt;/code&gt;&lt;/pre&gt;
&lt;div class="figure"&gt;
&lt;img src="/assets/img/real-mode-segmentation.png" alt="Real mode segmentation" /&gt;
&lt;p class="caption"&gt;Real mode segmentation&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Note, that with this formula it’s&amp;nbsp;up&amp;nbsp;to&amp;nbsp;you to&amp;nbsp;choose segments size. The only limitation is&amp;nbsp;that segments size is&amp;nbsp;at&amp;nbsp;least 16 bytes, implied by&amp;nbsp;4 bit shift, and maximum of&amp;nbsp;64 KiB implied by&amp;nbsp;&lt;code&gt;Offset&lt;/code&gt; size.&lt;/p&gt;
&lt;p&gt;In&amp;nbsp;the example above we’ve&amp;nbsp;used &lt;strong&gt;logical address&lt;/strong&gt; &lt;code&gt;0&amp;times;0002:0&amp;times;0005&lt;/code&gt; that gave us&amp;nbsp;&lt;strong&gt;linear address&lt;/strong&gt; &lt;code&gt;0&amp;times;00025&lt;/code&gt;. In&amp;nbsp;my&amp;nbsp;example I’ve&amp;nbsp;chosen to&amp;nbsp;use 32 bytes segments, but this is&amp;nbsp;only my&amp;nbsp;mental representation&amp;nbsp;&amp;mdash; how I&amp;nbsp;choose to&amp;nbsp;construct logical addresses. There are many ways to&amp;nbsp;represent the same address with segmentation:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;0x0000:0x0025 = 0x0 &amp;lt;&amp;lt; 14 + 0x25 = 0x00 + 0x25 = 0x00025
0x0002:0x0025 = 0x2 &amp;lt;&amp;lt; 14 + 0x25 = 0x20 + 0x25 = 0x00025
0xffff:0x0035 = 0xffff0 + 0x35 = 0x100025 = (Wrap around 20 bit) = 0x00025
0xfffe:0x0045 = 0xfffe0 + 0x45 = 0x100025 = (Wrap around 20 bit) = 0x00025
...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note the wrap around part. this is&amp;nbsp;where it&amp;nbsp;starts to&amp;nbsp;be&amp;nbsp;complicated and it’s&amp;nbsp;time to&amp;nbsp;tell the fun story about &lt;nobr&gt;Gate-A20&lt;/nobr&gt;.&lt;/p&gt;
&lt;p&gt;On&amp;nbsp;Intel 8086 segment register loading was a&amp;nbsp;slow operation, so&amp;nbsp;some DOS programmers used &lt;nobr&gt;wrap-around&lt;/nobr&gt; trick to&amp;nbsp;avoid it&amp;nbsp;and speed up&amp;nbsp;the programs. Placing the code in&amp;nbsp;high addresses of&amp;nbsp;memory (close to&amp;nbsp;1MiB) and accessing data in&amp;nbsp;lower addresses (I/O buffers) was possible without reloading segment thanks to&amp;nbsp;&lt;nobr&gt;wrap-around&lt;/nobr&gt;.&lt;/p&gt;
&lt;p&gt;Now Intel introduces 80286 processor with &lt;nobr&gt;24-bit&lt;/nobr&gt; address bus. CPU started in&amp;nbsp;real mode assuming &lt;nobr&gt;20-bit&lt;/nobr&gt; address space and then you could switch to&amp;nbsp;protected mode and enjoy all 16 MiB of&amp;nbsp;RAM available for your &lt;nobr&gt;24-bit&lt;/nobr&gt; addresses. But nobody forced you to&amp;nbsp;switch to&amp;nbsp;protected mode. You could still use your old programs written for Real mode. Unfortunately, 80286 processor had bug&amp;nbsp;&amp;mdash; in&amp;nbsp;Real mode it&amp;nbsp;didn’t&amp;nbsp;zero out 21st address line&amp;nbsp;&amp;mdash; A20 line (starting from A0). So&amp;nbsp;&lt;nobr&gt;wrap-around&lt;/nobr&gt; trick was not longer working. All those tricky speedy DOS programs were broken!&lt;/p&gt;
&lt;p&gt;IBM that was selling PC/AT computers with 80286 fixed this bug by&amp;nbsp;inserting logic gate on&amp;nbsp;A20 line between CPU and system bus that can be&amp;nbsp;controlled from software. On&amp;nbsp;reset BIOS enables A20 line to&amp;nbsp;count system memory and then disables it&amp;nbsp;back before passing control to&amp;nbsp;operating CPU, thus enabling &lt;nobr&gt;wrap-around&lt;/nobr&gt; trick. Yay! Read more shenanigans about A20 &lt;a href="http://www.win.tue.nl/~aeb/linux/kbd/A20.html"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;So, from now on&amp;nbsp;all x86 and x86_64 PCs has this &lt;nobr&gt;Gate-A20&lt;/nobr&gt;. Enabling it&amp;nbsp;is&amp;nbsp;one of&amp;nbsp;the required things to&amp;nbsp;switch into protected mode.&lt;/p&gt;
&lt;p&gt;Needless to&amp;nbsp;say that Multiboot compatible bootloader enables it&amp;nbsp;and switching into protected mode before passing control to&amp;nbsp;the kernel.&lt;/p&gt;
&lt;h3 id="segmentation-in-protected-mode"&gt;Segmentation in&amp;nbsp;Protected mode&lt;/h3&gt;
&lt;p&gt;As&amp;nbsp;you might saw in&amp;nbsp;previous section, segmentation is&amp;nbsp;awkward and &lt;nobr&gt;error-prone&lt;/nobr&gt; mechanism for memory organization and protection. Intel had understood it&amp;nbsp;quickly and in&amp;nbsp;80386 introduced &lt;strong&gt;paging&lt;/strong&gt;&amp;nbsp;&amp;mdash; flexible and powerful system for real memory management. Paging is&amp;nbsp;available only in&amp;nbsp;&lt;strong&gt;protected mode&lt;/strong&gt;&amp;nbsp;&amp;mdash; successor of&amp;nbsp;the real mode that was introduced in&amp;nbsp;80286, providing new features in&amp;nbsp;segmentation like segment limit checking, &lt;nobr&gt;read-only&lt;/nobr&gt; and &lt;nobr&gt;execute-only&lt;/nobr&gt; segments and 4 privilege levels (CPU rings).&lt;/p&gt;
&lt;p&gt;Although paging is&amp;nbsp;&lt;em&gt;the&lt;/em&gt; mechanism for memory management, when operating in&amp;nbsp;protected mode all memory references are subject of&amp;nbsp;segmentation for the sake of&amp;nbsp;backward compatibility. And it&amp;nbsp;drastically differs from segmentation in&amp;nbsp;real mode.&lt;/p&gt;
&lt;p&gt;In&amp;nbsp;protected mode, instead of&amp;nbsp;segment base, segment register holds a&amp;nbsp;segment selector, value used to&amp;nbsp;index segments table called &lt;strong&gt;Global Descriptor Table (GDT)&lt;/strong&gt;. This selector chooses entry in&amp;nbsp;GDT called &lt;strong&gt;Segment Descriptor&lt;/strong&gt;. Segment descriptor is&amp;nbsp;a&amp;nbsp;8 bytes structure that contains base address of&amp;nbsp;the segment and various fields used for various design choices howsoever exotic they are.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img src="/assets/img/segment-descriptor.png" alt="Segment descriptor" /&gt;
&lt;p class="caption"&gt;Segment descriptor&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;GDT is&amp;nbsp;located in&amp;nbsp;memory (on&amp;nbsp;8 bytes boundary) and pointed by&amp;nbsp;&lt;code&gt;gdtr&lt;/code&gt; register.&lt;/p&gt;
&lt;p&gt;All memory operations either explicitly or&amp;nbsp;implicitly contains segment registers. CPU uses segment register to&amp;nbsp;fetch segment selector from GDT, finds out that segment base address and add offset from memory operand to&amp;nbsp;it.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img src="/assets/img/protected-mode-segmentation.png" alt="Protected mode segmentation" /&gt;
&lt;p class="caption"&gt;Protected mode segmentation&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;You can mimic &lt;nobr&gt;real-mode&lt;/nobr&gt; segmentation model by&amp;nbsp;configuring overlapping segments. And actually, absolute most of&amp;nbsp;operating systems do&amp;nbsp;this. They setup all segments from 0 to&amp;nbsp;4 GiB, thus fully overlapping and carry out memory management to&amp;nbsp;paging.&lt;/p&gt;
&lt;h2 id="how-to-configure-segmentation-in-protected-mode"&gt;How to&amp;nbsp;configure segmentation in&amp;nbsp;protected mode&lt;/h2&gt;
&lt;p&gt;First of&amp;nbsp;all, lets make it&amp;nbsp;clear&amp;nbsp;&amp;mdash; there are a&amp;nbsp;lot of&amp;nbsp;stuff. When I&amp;nbsp;was reading Intel System programming manual, my&amp;nbsp;head started hurting. And actually, you don’t&amp;nbsp;need all this stuff because it’s&amp;nbsp;segmentation and you want to&amp;nbsp;set it&amp;nbsp;up&amp;nbsp;so&amp;nbsp;it&amp;nbsp;will just work and prepare system for paging.&lt;/p&gt;
&lt;p&gt;In&amp;nbsp;most cases, you will need at&amp;nbsp;least 4 segments:&lt;/p&gt;
&lt;ol start="0" style="list-style-type: decimal"&gt;
&lt;li&gt;Null segment (required by&amp;nbsp;Intel)&lt;/li&gt;
&lt;li&gt;Kernel code segment&lt;/li&gt;
&lt;li&gt;Kernel data segment&lt;/li&gt;
&lt;li&gt;Userspace code segment&lt;/li&gt;
&lt;li&gt;Userspace data segment&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This structure not only sane, but is&amp;nbsp;also required if&amp;nbsp;you want to&amp;nbsp;use &lt;code&gt;SYSCALL&lt;/code&gt;/&lt;code&gt;SYSRET&lt;/code&gt;&amp;nbsp;&amp;mdash; fast system call mechanism without CPU exception overhead of&amp;nbsp;&lt;code&gt;int 0&amp;times;80&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;These 4 segments are &lt;nobr&gt;&amp;laquo;non-system&amp;raquo;&lt;/nobr&gt;, as&amp;nbsp;defined by&amp;nbsp;a&amp;nbsp;flag &lt;code&gt;S&lt;/code&gt; in&amp;nbsp;segment descriptor. You use such segments for normal code and data, both for kernel and userspace. There are also &amp;laquo;system&amp;raquo; segments that has special meaning for CPU. Intel CPUs support 6 system descriptors types of&amp;nbsp;which you should have at&amp;nbsp;least one &lt;nobr&gt;Task-state&lt;/nobr&gt; segment (TSS) for each CPU (core) in&amp;nbsp;the system. TSS is&amp;nbsp;used to&amp;nbsp;implement &lt;nobr&gt;multi-tasking&lt;/nobr&gt; and I’ll&amp;nbsp;cover it&amp;nbsp;in&amp;nbsp;later articles.&lt;/p&gt;
&lt;p&gt;Four segments that we&amp;nbsp;set up&amp;nbsp;differs in&amp;nbsp;flags. Code segments are execute/read only, while data segments are read/write. Kernel segments differs from userspace by&amp;nbsp;DPL&amp;nbsp;&amp;mdash; descriptor privilege level. Privilege levels form &lt;em&gt;CPU protection rings&lt;/em&gt;. Intel CPUs have 4 rings, where 0 is&amp;nbsp;the most privileged and 3 is&amp;nbsp;least privileged.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img src="http://static.duartes.org/img/blogPosts/x86rings.png" alt="Lovely CPU rings image courtesy of Gustavo Duartes" /&gt;
&lt;p class="caption"&gt;Lovely CPU rings image courtesy of&amp;nbsp;&lt;a href="http://duartes.org/gustavo/blog/about/"&gt;Gustavo Duartes&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;CPU rings is&amp;nbsp;a&amp;nbsp;way to&amp;nbsp;protect privileged code such as&amp;nbsp;operating system kernel from direct access of&amp;nbsp;wild userspace. Usually, you create kernel segments in&amp;nbsp;a&amp;nbsp;ring 0, and userspace segments in&amp;nbsp;ring 3. It’s&amp;nbsp;not that it’s&amp;nbsp;impossible to&amp;nbsp;access kernel code from userspace, it&amp;nbsp;is, but there is&amp;nbsp;a&amp;nbsp;well defined, controlled by&amp;nbsp;kernel, mechanism involving (among other things) switch from ring 3 to&amp;nbsp;ring 0.&lt;/p&gt;
&lt;p&gt;Besides DPL (descriptor privilege level) that is&amp;nbsp;stored in&amp;nbsp;segment descriptor itself there are also CPL (Current Privilege Level) and RPL (Requested Privilege Level). CPL is&amp;nbsp;stored in&amp;nbsp;CS&amp;nbsp;and SS&amp;nbsp;segment registers. RPL is&amp;nbsp;encoded in&amp;nbsp;segment selector. Before loading segment selector into segment register CPU performs privilege check, using this formula&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;MAX(CPL, RPL) &amp;lt;= DPL&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Because RPL is&amp;nbsp;under calling software control, it&amp;nbsp;may be&amp;nbsp;used to&amp;nbsp;tamper privileged software. To&amp;nbsp;prevent this CPL is&amp;nbsp;used in&amp;nbsp;access checking.&lt;/p&gt;
&lt;p&gt;Lets look how control is&amp;nbsp;transferred between code segments. We&amp;nbsp;will look into simplest case of&amp;nbsp;control transfer with far jmp/call, Special instructions SYSENTER/SYSEXIT, interrupts/exceptions and task switching is&amp;nbsp;another topic.&lt;/p&gt;
&lt;p&gt;Far jmp/call instructions in&amp;nbsp;contrast to&amp;nbsp;near jmp/call contains segment selector as&amp;nbsp;part of&amp;nbsp;operand. Here are examples&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;jmp eax      ; Near jump
jmp 0x10:eax ; Far jump&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When you issue far jmp/call CPU takes CPL from CS, RPL from segment selector encoded into far instruction operand and DPL from target segment descriptor that is&amp;nbsp;found by&amp;nbsp;offset from segment selector. Then it&amp;nbsp;performs privilege check. If&amp;nbsp;it&amp;nbsp;was successful, segment selector is&amp;nbsp;loaded into segment register. From now you’re&amp;nbsp;in&amp;nbsp;a&amp;nbsp;new segment and EIP is&amp;nbsp;an&amp;nbsp;offset in&amp;nbsp;this segment. Called procedure is&amp;nbsp;executed in&amp;nbsp;its own stack. Each privilege level has its own stack. Fourth privilege level stack is&amp;nbsp;pointed by&amp;nbsp;SS&amp;nbsp;and ESP register, while stack for privilege levels 2, 1 and 0 is&amp;nbsp;stored in&amp;nbsp;TSS.&lt;/p&gt;
&lt;p&gt;Finally, lets see how it’s&amp;nbsp;all working.&lt;/p&gt;
&lt;p&gt;As&amp;nbsp;you might saw, things got more complicated and conversion from logical to&amp;nbsp;linear address (without paging it’ll&amp;nbsp;be&amp;nbsp;physical address) now goes like this:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;Logical address is&amp;nbsp;split in&amp;nbsp;2 parts: segment selector and offset&lt;/li&gt;
&lt;li&gt;If&amp;nbsp;it’s&amp;nbsp;not a&amp;nbsp;control transfer instruction (far jmp/call, SYSENTER/SYSCALL, call gate, TSS or&amp;nbsp;task gate) then go&amp;nbsp;to&amp;nbsp;step 8.&lt;/li&gt;
&lt;li&gt;If&amp;nbsp;it’s&amp;nbsp;a&amp;nbsp;control transfer instruction then load CPL from CS, RPL from segment selector and DPL from descriptor pointed by&amp;nbsp;segment selector.&lt;/li&gt;
&lt;li&gt;Perform access check: &lt;code&gt;MAX(CPL,RPL) &amp;lt;= DPL&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;If&amp;nbsp;it’s&amp;nbsp;not successful, then generate &lt;code&gt;#GF&lt;/code&gt; exception (General Protection Fault)&lt;/li&gt;
&lt;li&gt;Otherwise, load segment register with segment selector.&lt;/li&gt;
&lt;li&gt;Fetch based address, limit and access information and cache in&amp;nbsp;hidden part of&amp;nbsp;segment register&lt;/li&gt;
&lt;li&gt;Finally, add current segment base address taken from segment register (actually cached value from hidden part of&amp;nbsp;segment register) and offset taken from logical address (instruction operand), producing linear address.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Note, that without segments switching address translation is&amp;nbsp;pretty straightforward: take base address and add offset. Segment switching is&amp;nbsp;a&amp;nbsp;real pain, so&amp;nbsp;most operating systems avoids it&amp;nbsp;and set up&amp;nbsp;just 4 segments&amp;nbsp;&amp;mdash; minimum amount to&amp;nbsp;please CPU and protect kernel from userspace.&lt;/p&gt;
&lt;h2 id="segments-layout-examples"&gt;Segments layout examples&lt;/h2&gt;
&lt;h3 id="linux-kernel"&gt;Linux kernel&lt;/h3&gt;
&lt;p&gt;Linux kernel describes segment descriptor as&amp;nbsp;desc_struct structure in&amp;nbsp;&lt;a href="http://lxr.free-electrons.com/source/arch/x86/include/asm/desc_defs.h?v=4.2#L14"&gt;arch/x86/include/asm/desc_defs.h&lt;/a&gt;&lt;/p&gt;
&lt;pre class="sourceCode c"&gt;&lt;code class="sourceCode c"&gt;&lt;span class="kw"&gt;struct&lt;/span&gt; desc_struct {
        &lt;span class="kw"&gt;union&lt;/span&gt; {
                &lt;span class="kw"&gt;struct&lt;/span&gt; {
                        &lt;span class="dt"&gt;unsigned&lt;/span&gt; &lt;span class="dt"&gt;int&lt;/span&gt; a;
                        &lt;span class="dt"&gt;unsigned&lt;/span&gt; &lt;span class="dt"&gt;int&lt;/span&gt; b;
                };
                &lt;span class="kw"&gt;struct&lt;/span&gt; {
                        u16 limit0;
                        u16 base0;
                        &lt;span class="dt"&gt;unsigned&lt;/span&gt; base1: &lt;span class="dv"&gt;8&lt;/span&gt;, type: &lt;span class="dv"&gt;4&lt;/span&gt;, s: &lt;span class="dv"&gt;1&lt;/span&gt;, dpl: &lt;span class="dv"&gt;2&lt;/span&gt;, p: &lt;span class="dv"&gt;1&lt;/span&gt;;
                        &lt;span class="dt"&gt;unsigned&lt;/span&gt; limit: &lt;span class="dv"&gt;4&lt;/span&gt;, avl: &lt;span class="dv"&gt;1&lt;/span&gt;, l: &lt;span class="dv"&gt;1&lt;/span&gt;, d: &lt;span class="dv"&gt;1&lt;/span&gt;, g: &lt;span class="dv"&gt;1&lt;/span&gt;, base2: &lt;span class="dv"&gt;8&lt;/span&gt;;
                };
        };
} __attribute__((packed));

&lt;span class="ot"&gt;#define GDT_ENTRY_INIT(flags, base, limit) { { { \&lt;/span&gt;
&lt;span class="ot"&gt;        .a = ((limit) &amp;amp; 0xffff) | (((base) &amp;amp; 0xffff) &amp;lt;&amp;lt; 16), \&lt;/span&gt;
&lt;span class="ot"&gt;        .b = (((base) &amp;amp; 0xff0000) &amp;gt;&amp;gt; 16) | (((flags) &amp;amp; 0xf0ff) &amp;lt;&amp;lt; 8) | \&lt;/span&gt;
&lt;span class="ot"&gt;            ((limit) &amp;amp; 0xf0000) | ((base) &amp;amp; 0xff000000), \&lt;/span&gt;
&lt;span class="ot"&gt;    } } }&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;GDT itself defined in&amp;nbsp;&lt;a href="http://lxr.free-electrons.com/source/arch/x86/kernel/cpu/common.c?v=4.2#L94"&gt;arch/x86/kernel/cpu/common.c&lt;/a&gt;:&lt;/p&gt;
&lt;pre class="sourceCode c"&gt;&lt;code class="sourceCode c"&gt;.gdt = { 
    [GDT_ENTRY_KERNEL_CS]           = GDT_ENTRY_INIT(&lt;span class="bn"&gt;0xc09a&lt;/span&gt;, &lt;span class="dv"&gt;0&lt;/span&gt;, &lt;span class="bn"&gt;0xfffff&lt;/span&gt;),
    [GDT_ENTRY_KERNEL_DS]           = GDT_ENTRY_INIT(&lt;span class="bn"&gt;0xc092&lt;/span&gt;, &lt;span class="dv"&gt;0&lt;/span&gt;, &lt;span class="bn"&gt;0xfffff&lt;/span&gt;),
    [GDT_ENTRY_DEFAULT_USER_CS]     = GDT_ENTRY_INIT(&lt;span class="bn"&gt;0xc0fa&lt;/span&gt;, &lt;span class="dv"&gt;0&lt;/span&gt;, &lt;span class="bn"&gt;0xfffff&lt;/span&gt;),
    [GDT_ENTRY_DEFAULT_USER_DS]     = GDT_ENTRY_INIT(&lt;span class="bn"&gt;0xc0f2&lt;/span&gt;, &lt;span class="dv"&gt;0&lt;/span&gt;, &lt;span class="bn"&gt;0xfffff&lt;/span&gt;),
...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Basically, there is&amp;nbsp;a&amp;nbsp;flat memory model with 4 segments from &lt;code&gt;0&lt;/code&gt; to&amp;nbsp;&lt;code&gt;0xfffff * granularity&lt;/code&gt;, where granularity flag set to&amp;nbsp;1 specifies 4096 increments, thus giving us&amp;nbsp;limit of&amp;nbsp;4 GiB. Userspace and kernel segments differs in&amp;nbsp;DPL only.&lt;/p&gt;
&lt;h3 id="first-linux-version-0.01"&gt;First Linux version 0.01&lt;/h3&gt;
&lt;p&gt;In&amp;nbsp;the Linux version 0.01 there were no&amp;nbsp;userspace segments. In&amp;nbsp;&lt;a href="http://code.metager.de/source/xref/linux/historic/0.01/boot/head.s#171"&gt;boot/head.s&lt;/a&gt;&lt;/p&gt;
&lt;pre class="asm"&gt;&lt;code&gt;_gdt:   .quad 0x0000000000000000    /* NULL descriptor */
    .quad 0x00c09a00000007ff    /* 8Mb */
    .quad 0x00c09200000007ff    /* 8Mb */
    .quad 0x0000000000000000    /* TEMPORARY - don&amp;#39;t use */
    .fill 252,8,0           /* space for LDT&amp;#39;s and TSS&amp;#39;s etc */&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Unfortunately, I&amp;nbsp;wasn’t&amp;nbsp;able to&amp;nbsp;track down how userspace was set up&amp;nbsp;(TSS only?).&lt;/p&gt;
&lt;h3 id="netbsd"&gt;NetBSD&lt;/h3&gt;
&lt;p&gt;NetBSD kernel defines 4 segments as&amp;nbsp;everybody. In&amp;nbsp;&lt;a href="http://nxr.netbsd.org/xref/src/sys/arch/i386/include/segments.h#285"&gt;sys/arch/i386/include/segments.h&lt;/a&gt;&lt;/p&gt;
&lt;pre class="sourceCode c"&gt;&lt;code class="sourceCode c"&gt;&lt;span class="ot"&gt;#define GNULL_SEL   0   &lt;/span&gt;&lt;span class="co"&gt;/* Null descriptor */&lt;/span&gt;
&lt;span class="ot"&gt;#define GCODE_SEL   1   &lt;/span&gt;&lt;span class="co"&gt;/* Kernel code descriptor */&lt;/span&gt;
&lt;span class="ot"&gt;#define GDATA_SEL   2   &lt;/span&gt;&lt;span class="co"&gt;/* Kernel data descriptor */&lt;/span&gt;
&lt;span class="ot"&gt;#define GUCODE_SEL  3   &lt;/span&gt;&lt;span class="co"&gt;/* User code descriptor */&lt;/span&gt;
&lt;span class="ot"&gt;#define GUDATA_SEL  4   &lt;/span&gt;&lt;span class="co"&gt;/* User data descriptor */&lt;/span&gt;
...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Segments are set up&amp;nbsp;in&amp;nbsp;&lt;a href="http://nxr.netbsd.org/xref/src/sys/arch/i386/i386/machdep.c#953"&gt;sys/arch/i386/i386/machdep.c&lt;/a&gt;, function &lt;code&gt;initgdt&lt;/code&gt;:&lt;/p&gt;
&lt;pre class="sourceCode c"&gt;&lt;code class="sourceCode c"&gt;setsegment(&amp;amp;gdt[GCODE_SEL].sd, &lt;span class="dv"&gt;0&lt;/span&gt;, &lt;span class="bn"&gt;0xfffff&lt;/span&gt;, SDT_MEMERA, SEL_KPL, &lt;span class="dv"&gt;1&lt;/span&gt;, &lt;span class="dv"&gt;1&lt;/span&gt;);
setsegment(&amp;amp;gdt[GDATA_SEL].sd, &lt;span class="dv"&gt;0&lt;/span&gt;, &lt;span class="bn"&gt;0xfffff&lt;/span&gt;, SDT_MEMRWA, SEL_KPL, &lt;span class="dv"&gt;1&lt;/span&gt;, &lt;span class="dv"&gt;1&lt;/span&gt;);
setsegment(&amp;amp;gdt[GUCODE_SEL].sd, &lt;span class="dv"&gt;0&lt;/span&gt;, x86_btop(I386_MAX_EXE_ADDR) - &lt;span class="dv"&gt;1&lt;/span&gt;,
    SDT_MEMERA, SEL_UPL, &lt;span class="dv"&gt;1&lt;/span&gt;, &lt;span class="dv"&gt;1&lt;/span&gt;);
setsegment(&amp;amp;gdt[GUCODEBIG_SEL].sd, &lt;span class="dv"&gt;0&lt;/span&gt;, &lt;span class="bn"&gt;0xfffff&lt;/span&gt;,
    SDT_MEMERA, SEL_UPL, &lt;span class="dv"&gt;1&lt;/span&gt;, &lt;span class="dv"&gt;1&lt;/span&gt;);
setsegment(&amp;amp;gdt[GUDATA_SEL].sd, &lt;span class="dv"&gt;0&lt;/span&gt;, &lt;span class="bn"&gt;0xfffff&lt;/span&gt;,
    SDT_MEMRWA, SEL_UPL, &lt;span class="dv"&gt;1&lt;/span&gt;, &lt;span class="dv"&gt;1&lt;/span&gt;);&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Where &lt;code&gt;setsegment&lt;/code&gt; has &lt;a href="http://nxr.netbsd.org/xref/src/sys/arch/i386/i386/machdep.c#907"&gt;following signature&lt;/a&gt;:&lt;/p&gt;
&lt;pre class="sourceCode c"&gt;&lt;code class="sourceCode c"&gt;&lt;span class="dt"&gt;void&lt;/span&gt;
setsegment(&lt;span class="kw"&gt;struct&lt;/span&gt; segment_descriptor *sd, &lt;span class="dt"&gt;const&lt;/span&gt; &lt;span class="dt"&gt;void&lt;/span&gt; *base, size_t limit,
    &lt;span class="dt"&gt;int&lt;/span&gt; type, &lt;span class="dt"&gt;int&lt;/span&gt; dpl, &lt;span class="dt"&gt;int&lt;/span&gt; def32, &lt;span class="dt"&gt;int&lt;/span&gt; gran)&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="openbsd"&gt;OpenBSD&lt;/h3&gt;
&lt;p&gt;Similar to&amp;nbsp;NetBSD, but segments order is&amp;nbsp;different. In&amp;nbsp;&lt;a href="http://bxr.su/OpenBSD/sys/arch/i386/include/segments.h#211"&gt;sys/arch/i386/include/segments.h&lt;/a&gt;:&lt;/p&gt;
&lt;pre class="sourceCode c"&gt;&lt;code class="sourceCode c"&gt;&lt;span class="co"&gt;/*&lt;/span&gt;
&lt;span class="co"&gt; * Entries in the Global Descriptor Table (GDT)&lt;/span&gt;
&lt;span class="co"&gt; */&lt;/span&gt;
&lt;span class="ot"&gt;#define GNULL_SEL   0   &lt;/span&gt;&lt;span class="co"&gt;/* Null descriptor */&lt;/span&gt;
&lt;span class="ot"&gt;#define GCODE_SEL   1   &lt;/span&gt;&lt;span class="co"&gt;/* Kernel code descriptor */&lt;/span&gt;
&lt;span class="ot"&gt;#define GDATA_SEL   2   &lt;/span&gt;&lt;span class="co"&gt;/* Kernel data descriptor */&lt;/span&gt;
&lt;span class="ot"&gt;#define GLDT_SEL    3   &lt;/span&gt;&lt;span class="co"&gt;/* Default LDT descriptor */&lt;/span&gt;
&lt;span class="ot"&gt;#define GCPU_SEL    4   &lt;/span&gt;&lt;span class="co"&gt;/* per-CPU segment */&lt;/span&gt;
&lt;span class="ot"&gt;#define GUCODE_SEL  5   &lt;/span&gt;&lt;span class="co"&gt;/* User code descriptor (a stack short) */&lt;/span&gt;
&lt;span class="ot"&gt;#define GUDATA_SEL  6   &lt;/span&gt;&lt;span class="co"&gt;/* User data descriptor */&lt;/span&gt;
...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As&amp;nbsp;you can see, userspace code and data segments are at&amp;nbsp;positions 5 and 6 in&amp;nbsp;GDT. I&amp;nbsp;don’t&amp;nbsp;know how &lt;code&gt;SYSENTER/SYSEXIT&lt;/code&gt; will work here because you set the value of&amp;nbsp;&lt;code&gt;SYSENTER&lt;/code&gt; segment in&amp;nbsp;&lt;code&gt;IA32_SYSENTER_CS&lt;/code&gt; MSR. All other segments are calculated as&amp;nbsp;offset from this MSR, e.g. &lt;code&gt;SYSEXIT&lt;/code&gt; target segment is&amp;nbsp;an&amp;nbsp;16 bytes offset&amp;nbsp;&amp;mdash; GDT entry that is&amp;nbsp;after next to&amp;nbsp;&lt;code&gt;SYSENTER&lt;/code&gt; segment. In&amp;nbsp;this case &lt;code&gt;SYSEXIT&lt;/code&gt; will hit LDT. Some help from OpenBSD kernel folks will be&amp;nbsp;great here.&lt;/p&gt;
&lt;p&gt;Everything else is&amp;nbsp;same.&lt;/p&gt;
&lt;h3 id="xv6"&gt;xv6&lt;/h3&gt;
&lt;p&gt;xv6 is&amp;nbsp;a&amp;nbsp;&lt;nobr&gt;re-implementation&lt;/nobr&gt; of&amp;nbsp;Dennis Ritchie’s&amp;nbsp;and Ken Thompson’s&amp;nbsp;Unix Version 6 (v6). It’s&amp;nbsp;a&amp;nbsp;small operating system that is&amp;nbsp;taught in&amp;nbsp;MIT.&lt;/p&gt;
&lt;p&gt;It’s&amp;nbsp;really pleasant to&amp;nbsp;read it’s&amp;nbsp;source code. There is&amp;nbsp;a&amp;nbsp;&lt;a href="http://code.metager.de/source/xref/mit/xv6/main.c#14"&gt;&lt;code&gt;main&lt;/code&gt;&lt;/a&gt; in&amp;nbsp;main.c that calls &lt;a href="http://code.metager.de/source/xref/mit/xv6/vm.c#14"&gt;&lt;code&gt;seginit&lt;/code&gt;&lt;/a&gt; in&amp;nbsp;vm.c&lt;/p&gt;
&lt;p&gt;This function sets up&amp;nbsp;6 segments:&lt;/p&gt;
&lt;pre class="sourceCode c"&gt;&lt;code class="sourceCode c"&gt;&lt;span class="ot"&gt;#define SEG_KCODE 1  &lt;/span&gt;&lt;span class="co"&gt;// kernel code&lt;/span&gt;
&lt;span class="ot"&gt;#define SEG_KDATA 2  &lt;/span&gt;&lt;span class="co"&gt;// kernel data+stack&lt;/span&gt;
&lt;span class="ot"&gt;#define SEG_KCPU  3  &lt;/span&gt;&lt;span class="co"&gt;// kernel per-cpu data&lt;/span&gt;
&lt;span class="ot"&gt;#define SEG_UCODE 4  &lt;/span&gt;&lt;span class="co"&gt;// user code&lt;/span&gt;
&lt;span class="ot"&gt;#define SEG_UDATA 5  &lt;/span&gt;&lt;span class="co"&gt;// user data+stack&lt;/span&gt;
&lt;span class="ot"&gt;#define SEG_TSS   6  &lt;/span&gt;&lt;span class="co"&gt;// this process&amp;#39;s task state&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;like this&lt;/p&gt;
&lt;pre class="sourceCode c"&gt;&lt;code class="sourceCode c"&gt;&lt;span class="co"&gt;// Map &amp;quot;logical&amp;quot; addresses to virtual addresses using identity map.&lt;/span&gt;
&lt;span class="co"&gt;// Cannot share a CODE descriptor for both kernel and user&lt;/span&gt;
&lt;span class="co"&gt;// because it would have to have DPL_USR, but the CPU forbids&lt;/span&gt;
&lt;span class="co"&gt;// an interrupt from CPL=0 to DPL=3.&lt;/span&gt;
c = &amp;amp;cpus[cpunum()];
c-&amp;gt;gdt[SEG_KCODE] = SEG(STA_X|STA_R, &lt;span class="dv"&gt;0&lt;/span&gt;, &lt;span class="bn"&gt;0xffffffff&lt;/span&gt;, &lt;span class="dv"&gt;0&lt;/span&gt;);
c-&amp;gt;gdt[SEG_KDATA] = SEG(STA_W, &lt;span class="dv"&gt;0&lt;/span&gt;, &lt;span class="bn"&gt;0xffffffff&lt;/span&gt;, &lt;span class="dv"&gt;0&lt;/span&gt;);
c-&amp;gt;gdt[SEG_UCODE] = SEG(STA_X|STA_R, &lt;span class="dv"&gt;0&lt;/span&gt;, &lt;span class="bn"&gt;0xffffffff&lt;/span&gt;, DPL_USER);
c-&amp;gt;gdt[SEG_UDATA] = SEG(STA_W, &lt;span class="dv"&gt;0&lt;/span&gt;, &lt;span class="bn"&gt;0xffffffff&lt;/span&gt;, DPL_USER);

&lt;span class="co"&gt;// Map cpu, and curproc&lt;/span&gt;
c-&amp;gt;gdt[SEG_KCPU] = SEG(STA_W, &amp;amp;c-&amp;gt;cpu, &lt;span class="dv"&gt;8&lt;/span&gt;, &lt;span class="dv"&gt;0&lt;/span&gt;);&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Four segments for kernel and userspace code and data, one for TSS, nice and simple code, clear logic, great OS&amp;nbsp;for education.&lt;/p&gt;
&lt;h2 id="to-read"&gt;To&amp;nbsp;read&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Intel&lt;sup&gt;&lt;small&gt;&amp;reg;&lt;/small&gt;&lt;/sup&gt; 64 and &lt;nobr&gt;IA-32&lt;/nobr&gt; Architectures Software Developer’s&amp;nbsp;Manual Volume 3a&lt;/li&gt;
&lt;li&gt;Gustavo Duartes articles are great as&amp;nbsp;usual (why he’s&amp;nbsp;not writing anymore?):
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://duartes.org/gustavo/blog/post/memory-translation-and-segmentation/"&gt;Memory Translation and Segmentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://duartes.org/gustavo/blog/post/cpu-rings-privilege-and-protection/"&gt;CPU Rings, Privilege, and Protection&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;OsDev wiki topics for GDT:
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://wiki.osdev.org/GDT_Tutorial"&gt;GDT Tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://wiki.osdev.org/GDT"&gt;Global Descriptor Table&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;</content>
  </entry>
  <entry xml:base="http://alex.dzyoba.com/feed">
    <title type="text">Linux profiling. SystemTap</title>
    <id>linux/profiling-systemtap.html</id>
    <updated>2015-11-30T00:00:00Z</updated>
    <link href="linux/profiling-systemtap.html" />
    <author>
      <name>Alex Dzyoba</name>
    </author>
    <content type="html">&lt;p&gt;TOC:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;&lt;a href="/linux/profiling-intro.html"&gt;Intro&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/linux/profiling-gprof-gcov.html"&gt;Userspace profiling: gprof, gcov&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/linux/profiling-valgrind.html"&gt;Userspace profiling: Valgrind&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/linux/profiling-kernel.html"&gt;Kernel profiling: Intro&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/linux/profiling-ftrace.html"&gt;Kernel profiling: ftrace&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/linux/profiling-perf.html"&gt;Kernel profiling: perf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Kernel profiling: SystemTap&lt;/li&gt;
&lt;li&gt;Various tools&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="systemtap"&gt;SystemTap&lt;/h2&gt;
&lt;p&gt;SystemTap is&amp;nbsp;a&amp;nbsp;profiling and debugging infrastructure &lt;a href="https://sourceware.org/systemtap/systemtap-ols.pdf"&gt;based on&amp;nbsp;kprobes&lt;/a&gt;. Essentially, it’s&amp;nbsp;a&amp;nbsp;scripting facility for kprobes. It&amp;nbsp;allows you to&amp;nbsp;dynamically instrument the kernel and user application to&amp;nbsp;track down complex and obscure problems in&amp;nbsp;system behavior.&lt;/p&gt;
&lt;p&gt;With SystemTap you write a&amp;nbsp;tapscript in&amp;nbsp;a&amp;nbsp;special language inspired by&amp;nbsp;C, awk and dtrace. SystemTap language asks you to&amp;nbsp;write handlers for probes defined in&amp;nbsp;kernel or&amp;nbsp;userspace that will be&amp;nbsp;invoked when execution hits these probes. You can define your own functions and use extensive &lt;a href="https://sourceware.org/systemtap/tapsets/"&gt;tapsets&lt;/a&gt; library. Language provides you integers, strings, associative arrays and statistics, without requiring types and memory allocation. Comprehensive information about SystemTap language can be&amp;nbsp;found in&amp;nbsp;&lt;a href="https://sourceware.org/systemtap/langref/"&gt;language reference&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Scripts that you wrote are elaborated (resolving references to&amp;nbsp;tapsets, kernel and userspace symbols), translated to&amp;nbsp;C, wrapped with kprobes &lt;acronym title="Application programming interface" lang="en"&gt;API&lt;/acronym&gt; invocation, compiled into kernel module that, finally, is&amp;nbsp;loaded into kernel.&lt;/p&gt;
&lt;p&gt;Script output and other data collected is&amp;nbsp;transferred from kernel to&amp;nbsp;userspace via &lt;nobr&gt;high-performance&lt;/nobr&gt; transport like relayfs or&amp;nbsp;netlink.&lt;/p&gt;
&lt;h2 id="setup"&gt;Setup&lt;/h2&gt;
&lt;p&gt;Installation part is&amp;nbsp;boring and depends on&amp;nbsp;your distro, on&amp;nbsp;Fedora it’s&amp;nbsp;as&amp;nbsp;simple as:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ dnf install systemtap&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You will need SystemTap runtime and client tools along with tapsets and other development files for building your modules.&lt;/p&gt;
&lt;p&gt;Also, you will need kernel debug info:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ dnf debuginfo-install kernel&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After installation, you may check if&amp;nbsp;it’s&amp;nbsp;working:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;stap -v -e &amp;#39;probe begin { println(&amp;quot;Started&amp;quot;) }&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="playground"&gt;Playground&lt;/h2&gt;
&lt;p&gt;Various examples of&amp;nbsp;what SystemTap can do&amp;nbsp;can be&amp;nbsp;found &lt;a href="https://sourceware.org/systemtap/examples/keyword-index.html"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You can see call graphs with &lt;a href="https://sourceware.org/systemtap/examples/general/para-callgraph.stp"&gt;&lt;nobr&gt;para-callgraph&lt;/nobr&gt;.stp&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ stap para-callgraph.stp &amp;#39;process(&amp;quot;/home/avd/dev/block_hasher/block_hasher&amp;quot;).function(&amp;quot;*&amp;quot;)&amp;#39; \
  -c &amp;#39;/home/avd/dev/block_hasher/block_hasher -d /dev/md0 -b 1048576 -t 10 -n 10000&amp;#39;

     0 block_hasher(10792):-&amp;gt;_start 
    11 block_hasher(10792): -&amp;gt;__libc_csu_init 
    14 block_hasher(10792):  -&amp;gt;_init 
    17 block_hasher(10792):  &amp;lt;-_init 
    18 block_hasher(10792):  -&amp;gt;frame_dummy 
    21 block_hasher(10792):   -&amp;gt;register_tm_clones 
    23 block_hasher(10792):   &amp;lt;-register_tm_clones 
    25 block_hasher(10792):  &amp;lt;-frame_dummy 
    26 block_hasher(10792): &amp;lt;-__libc_csu_init 
    31 block_hasher(10792): -&amp;gt;main argc=0x9 argv=0x7ffc78849278
    44 block_hasher(10792):  -&amp;gt;bdev_open dev_path=0x7ffc78849130
    88 block_hasher(10792):  &amp;lt;-bdev_open return=0x163b010
     0 block_hasher(10796):-&amp;gt;thread_func arg=0x163b2c8
     0 block_hasher(10797):-&amp;gt;thread_func arg=0x163b330
     0 block_hasher(10795):-&amp;gt;thread_func arg=0x163b260
     0 block_hasher(10798):-&amp;gt;thread_func arg=0x163b398
     0 block_hasher(10799):-&amp;gt;thread_func arg=0x163b400
     0 block_hasher(10800):-&amp;gt;thread_func arg=0x163b468
     0 block_hasher(10801):-&amp;gt;thread_func arg=0x163b4d0
     0 block_hasher(10802):-&amp;gt;thread_func arg=0x163b538
     0 block_hasher(10803):-&amp;gt;thread_func arg=0x163b5a0
     0 block_hasher(10804):-&amp;gt;thread_func arg=0x163b608
407360 block_hasher(10799): -&amp;gt;time_diff start={...} end={...}
407371 block_hasher(10799): &amp;lt;-time_diff 
407559 block_hasher(10799):&amp;lt;-thread_func return=0x0
436757 block_hasher(10795): -&amp;gt;time_diff start={...} end={...}
436765 block_hasher(10795): &amp;lt;-time_diff 
436872 block_hasher(10795):&amp;lt;-thread_func return=0x0
489156 block_hasher(10797): -&amp;gt;time_diff start={...} end={...}
489163 block_hasher(10797): &amp;lt;-time_diff 
489277 block_hasher(10797):&amp;lt;-thread_func return=0x0
506616 block_hasher(10803): -&amp;gt;time_diff start={...} end={...}
506628 block_hasher(10803): &amp;lt;-time_diff 
506754 block_hasher(10803):&amp;lt;-thread_func return=0x0
526005 block_hasher(10801): -&amp;gt;time_diff start={...} end={...}
526010 block_hasher(10801): &amp;lt;-time_diff 
526075 block_hasher(10801):&amp;lt;-thread_func return=0x0
9840716 block_hasher(10804): -&amp;gt;time_diff start={...} end={...}
9840723 block_hasher(10804): &amp;lt;-time_diff 
9840818 block_hasher(10804):&amp;lt;-thread_func return=0x0
9857787 block_hasher(10802): -&amp;gt;time_diff start={...} end={...}
9857792 block_hasher(10802): &amp;lt;-time_diff 
9857895 block_hasher(10802):&amp;lt;-thread_func return=0x0
9872655 block_hasher(10796): -&amp;gt;time_diff start={...} end={...}
9872664 block_hasher(10796): &amp;lt;-time_diff 
9872816 block_hasher(10796):&amp;lt;-thread_func return=0x0
9875681 block_hasher(10798): -&amp;gt;time_diff start={...} end={...}
9875686 block_hasher(10798): &amp;lt;-time_diff 
9874408 block_hasher(10800): -&amp;gt;time_diff start={...} end={...}
9874413 block_hasher(10800): &amp;lt;-time_diff 
9875767 block_hasher(10798):&amp;lt;-thread_func return=0x0
9874482 block_hasher(10800):&amp;lt;-thread_func return=0x0
9876305 block_hasher(10792):  -&amp;gt;bdev_close dev=0x163b010
10180742 block_hasher(10792):  &amp;lt;-bdev_close 
10180801 block_hasher(10792): &amp;lt;-main return=0x0
10180808 block_hasher(10792): -&amp;gt;__do_global_dtors_aux 
10180814 block_hasher(10792):  -&amp;gt;deregister_tm_clones 
10180817 block_hasher(10792):  &amp;lt;-deregister_tm_clones 
10180819 block_hasher(10792): &amp;lt;-__do_global_dtors_aux 
10180821 block_hasher(10792): -&amp;gt;_fini 
10180823 block_hasher(10792): &amp;lt;-_fini 
Pass 5: run completed in 20usr/3200sys/10716real ms.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can find generic source of&amp;nbsp;latency with &lt;a href="https://sourceware.org/systemtap/examples/profiling/latencytap.stp"&gt;latencytap.stp&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ stap -v latencytap.stp -c \
&amp;#39;/home/avd/dev/block_hasher/block_hasher -d /dev/md0 -b 1048576 -t 10 -n 1000000&amp;#39;

Reason                                            Count  Average(us)  Maximum(us) Percent%
Reading from file                                   490        49311        53833      96%
Userspace lock contention                             8       118734       929420       3%
Page fault                                           17           27           65       0%
unmapping memory                                      4           37           55       0%
mprotect() system call                                6           25           45       0%
                                                      4           19           37       0%
                                                      3           23           49       0%
Page fault                                            2           24           46       0%
Page fault                                            2           20           36       0%&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note: you may need to&amp;nbsp;change timer interval in&amp;nbsp;latencytap.stp:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;-probe timer.s(30) {
+probe timer.s(5) {&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is&amp;nbsp;even &lt;a href="https://sourceware.org/systemtap/examples/stapgames/2048.stp"&gt;2048 written in&amp;nbsp;SystemTap&lt;/a&gt;!&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img src="/assets/img/stap-2048.png" alt="SystemTap 2048" /&gt;
&lt;p class="caption"&gt;SystemTap 2048&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;All in&amp;nbsp;all, it’s&amp;nbsp;simple and convenient. You can wrap your head around it&amp;nbsp;in&amp;nbsp;a&amp;nbsp;single day! And it&amp;nbsp;works as&amp;nbsp;you expect and this is&amp;nbsp;a&amp;nbsp;big deal because it&amp;nbsp;gives you certainty and confidence in&amp;nbsp;infirm ground of&amp;nbsp;profiling kernel problems.&lt;/p&gt;
&lt;h2 id="profiling-io-latency-for-block_hasher"&gt;Profiling I/O latency for block_hasher&lt;/h2&gt;
&lt;p&gt;So, how can we&amp;nbsp;use it&amp;nbsp;for profiling kernel, module or&amp;nbsp;userspace application? The thing is&amp;nbsp;that we&amp;nbsp;have almost unlimited power in&amp;nbsp;our hands. We&amp;nbsp;can do&amp;nbsp;whatever we&amp;nbsp;want and howsoever we&amp;nbsp;want, but we&amp;nbsp;must know what we&amp;nbsp;&lt;em&gt;want&lt;/em&gt; and express it&amp;nbsp;in&amp;nbsp;SystemTap language.&lt;/p&gt;
&lt;p&gt;You have a&amp;nbsp;tapsets&amp;nbsp;&amp;mdash; standard library for SystemTap&amp;nbsp;&amp;mdash; that contains a&amp;nbsp;&lt;a href="https://sourceware.org/systemtap/tapsets/"&gt;massive variety&lt;/a&gt; of&amp;nbsp;probes and functions that are available for your tapscripts.&lt;/p&gt;
&lt;p&gt;But, let’s&amp;nbsp;be&amp;nbsp;honest, nobody wants to&amp;nbsp;write scripts, everybody wants to&amp;nbsp;use scripts written by&amp;nbsp;someone who has expertise and who already spent a&amp;nbsp;lot of&amp;nbsp;time, debugged and tweaked the script.&lt;/p&gt;
&lt;p&gt;Let’s&amp;nbsp;look what we&amp;nbsp;can find in&amp;nbsp;&lt;a href="https://sourceware.org/systemtap/examples/keyword-index.html#IO"&gt;SystemTap I/O examples&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;There is&amp;nbsp;one that seems legit: &lt;a href="https://sourceware.org/systemtap/examples/io/ioblktime.stp"&gt;&amp;laquo;ioblktime&amp;raquo;&lt;/a&gt;. Let’s&amp;nbsp;launch it:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;stap -v ioblktime.stp -o ioblktime -c \
&amp;#39;/home/avd/dev/block_hasher/block_hasher -d /dev/md0 -b 1048576 -t 10 -n 10000&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s&amp;nbsp;what we’ve&amp;nbsp;got:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;device  rw total (us)      count   avg (us)
  ram4   R     101628        981        103
  ram5   R      99328        981        101
  ram6   R      64973        974         66
  ram2   R      57002        974         58
  ram3   R      66635        974         68
  ram0   R     101806        974        104
  ram1   R      98470        974        101
  ram7   R      64250        974         65
  dm-0   R   48337401        974      49627
   sda   W    3871495        376      10296
   sda   R     125794         14       8985
device  rw total (us)      count   avg (us)
   sda   W     278560         18      15475&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We&amp;nbsp;see a&amp;nbsp;strange device &lt;nobr&gt;dm-0&lt;/nobr&gt;. Quick check:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ dmsetup info /dev/dm-0 
Name:              delayed
State:             ACTIVE
Read Ahead:        256
Tables present:    LIVE
Open count:        1
Event number:      0
Major, minor:      253, 0
Number of targets: 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;DeviceMapper’s&amp;nbsp;&amp;laquo;delayed&amp;raquo; target that we&amp;nbsp;saw &lt;a href="/linux/profiling-perf.html#dm-delay"&gt;previously&lt;/a&gt;. This target creates block device that identically maps to&amp;nbsp;disk, but delays each request by&amp;nbsp;given amount of&amp;nbsp;milliseconds. &lt;strong&gt;This is&amp;nbsp;a&amp;nbsp;cause of&amp;nbsp;our RAID problems: performance of&amp;nbsp;a&amp;nbsp;striped RAID is&amp;nbsp;a&amp;nbsp;performance of&amp;nbsp;the slowest disk.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I’ve&amp;nbsp;look for other examples, but they mostly show which process generates the most I/O.&lt;/p&gt;
&lt;p&gt;Let’s&amp;nbsp;try to&amp;nbsp;write our own script!&lt;/p&gt;
&lt;p&gt;There is&amp;nbsp;a&amp;nbsp;tapset dedicated for &lt;a href="https://sourceware.org/systemtap/tapsets/iosched.stp.html"&gt;I/O scheduler and block I/O&lt;/a&gt;. Let’s&amp;nbsp;use &lt;code&gt;probe:ioblock.end&lt;/code&gt; matching our RAID device and print backtrace.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;probe ioblock.end
{
    if (devname == &amp;quot;md0&amp;quot;) {
        printf(&amp;quot;%s: %d\n&amp;quot;, devname, sector);
        print_backtrace()
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Unfortunately, this won’t&amp;nbsp;work because RAID device request end up&amp;nbsp;in&amp;nbsp;concrete disk, so&amp;nbsp;we&amp;nbsp;have to&amp;nbsp;hook into &lt;code&gt;raid0&lt;/code&gt; module.&lt;/p&gt;
&lt;p&gt;Dive into &lt;a href="http://lxr.free-electrons.com/source/drivers/md/raid0.c?v=4.2"&gt;&lt;code&gt;drivers/md/raid0.c&lt;/code&gt;&lt;/a&gt; and look to&amp;nbsp;&lt;a href="http://lxr.free-electrons.com/source/drivers/md/raid0.c?v=4.2#L507"&gt;&lt;code&gt;raid0_make_request&lt;/code&gt;&lt;/a&gt;. Core of&amp;nbsp;the RAID 0 is&amp;nbsp;encoded in&amp;nbsp;these lines:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;530                 if (sectors &amp;lt; bio_sectors(bio)) {
531                         split = bio_split(bio, sectors, GFP_NOIO, fs_bio_set);
532                         bio_chain(split, bio);
533                 } else {
534                         split = bio;
535                 }
536 
537                 zone = find_zone(mddev-&amp;gt;private, &amp;amp;sector);
538                 tmp_dev = map_sector(mddev, zone, sector, &amp;amp;sector);
539                 split-&amp;gt;bi_bdev = tmp_dev-&amp;gt;bdev;
540                 split-&amp;gt;bi_iter.bi_sector = sector + zone-&amp;gt;dev_start +
541                         tmp_dev-&amp;gt;data_offset;
                           ...
548                         generic_make_request(split);&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;that tell us: &amp;laquo;split bio requests to&amp;nbsp;raid md&amp;nbsp;device, map it&amp;nbsp;to&amp;nbsp;particular disk and issue &lt;code&gt;generic_make_request&lt;/code&gt;&amp;raquo;.&lt;/p&gt;
&lt;p&gt;Closer look to&amp;nbsp;&lt;code&gt;generic_make_request&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;1966         do {
1967                 struct request_queue *q = bdev_get_queue(bio-&amp;gt;bi_bdev);
1968 
1969                 q-&amp;gt;make_request_fn(q, bio);
1970 
1971                 bio = bio_list_pop(current-&amp;gt;bio_list);
1972         } while (bio);&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;will show us&amp;nbsp;that it&amp;nbsp;gets request queue from block device, in&amp;nbsp;our case a&amp;nbsp;particular disk, and issue &lt;code&gt;make_request_fn&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;This will lead us&amp;nbsp;to&amp;nbsp;see which block devices our RAID consists of:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ mdadm --misc -D /dev/md0 
/dev/md0:
        Version : 1.2
  Creation Time : Mon Nov 30 11:15:51 2015
     Raid Level : raid0
     Array Size : 3989504 (3.80 GiB 4.09 GB)
   Raid Devices : 8
  Total Devices : 8
    Persistence : Superblock is persistent

    Update Time : Mon Nov 30 11:15:51 2015
          State : clean 
 Active Devices : 8
Working Devices : 8
 Failed Devices : 0
  Spare Devices : 0

     Chunk Size : 512K

           Name : alien:0  (local to host alien)
           UUID : d2960b14:bc29a1c5:040efdc6:39daf5cf
         Events : 0

    Number   Major   Minor   RaidDevice State
       0       1        0        0      active sync   /dev/ram0
       1       1        1        1      active sync   /dev/ram1
       2       1        2        2      active sync   /dev/ram2
       3       1        3        3      active sync   /dev/ram3
       4       1        4        4      active sync   /dev/ram4
       5       1        5        5      active sync   /dev/ram5
       6       1        6        6      active sync   /dev/ram6
       7     253        0        7      active sync   /dev/dm-0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and here we&amp;nbsp;go&amp;nbsp;&amp;mdash; last device is&amp;nbsp;our strange &lt;code&gt;/dev/&lt;nobr&gt;dm-0&lt;/nobr&gt;&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;And again, I&amp;nbsp;knew it&amp;nbsp;from the beginning, and tried to&amp;nbsp;come into the root of&amp;nbsp;the problem with SystemTap. But SystemTap was just a&amp;nbsp;motivation to&amp;nbsp;look into kernel code and think deeper, which is&amp;nbsp;nice, though. This again proofs that the best tool to&amp;nbsp;investigate any problem, be&amp;nbsp;that performance issue or&amp;nbsp;bug, is&amp;nbsp;your brain and experience.&lt;/p&gt;
&lt;p&gt;Thanks for reading.&lt;/p&gt;</content>
  </entry>
  <entry xml:base="http://alex.dzyoba.com/feed">
    <title type="text">Multiboot kernel</title>
    <id>programming/multiboot.html</id>
    <updated>2015-09-28T00:00:00Z</updated>
    <link href="programming/multiboot.html" />
    <author>
      <name>avd</name>
    </author>
    <content type="html">&lt;p&gt;As&amp;nbsp;a&amp;nbsp;headcase, in&amp;nbsp;my&amp;nbsp;spare time (among other things) I’m&amp;nbsp;writing an&amp;nbsp;operating system kernel. There is&amp;nbsp;nothing much at&amp;nbsp;this moment because I’m&amp;nbsp;digging into boot process of&amp;nbsp;x86 system&lt;a href="#fn1" class="footnoteRef" id="fnref1"&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;. And, to&amp;nbsp;commit my&amp;nbsp;knowledge so&amp;nbsp;far, I’ll&amp;nbsp;explain first simple but really important steps of&amp;nbsp;booting trivial kernel.&lt;/p&gt;
&lt;h2 id="the-kernel"&gt;The &amp;laquo;kernel&amp;raquo;&lt;/h2&gt;
&lt;p&gt;For illustrations I’m&amp;nbsp;gonna use &amp;laquo;Hello world&amp;raquo; kernel that is&amp;nbsp;written in&amp;nbsp;NASM assembly (grab the source &lt;a href="http://github.com/dzeban/hello-kernel"&gt;from github&lt;/a&gt;):&lt;/p&gt;
&lt;pre class="sourceCode nasm"&gt;&lt;code class="sourceCode nasm"&gt;    &lt;span class="kw"&gt;global&lt;/span&gt; start                    &lt;span class="co"&gt;; the entry symbol for ELF&lt;/span&gt;

    MAGIC_NUMBER &lt;span class="dt"&gt;equ&lt;/span&gt; &lt;span class="bn"&gt;0x1BADB002&lt;/span&gt;     &lt;span class="co"&gt;; define the magic number constant&lt;/span&gt;
    FLAGS        &lt;span class="dt"&gt;equ&lt;/span&gt;&lt;span class="bn"&gt; 0x0            &lt;/span&gt;&lt;span class="co"&gt;; multiboot flags&lt;/span&gt;
    CHECKSUM     &lt;span class="dt"&gt;equ&lt;/span&gt; -MAGIC_NUMBER  &lt;span class="co"&gt;; calculate the checksum&lt;/span&gt;
                                    &lt;span class="co"&gt;; (magic number + checksum + flags should equal 0)&lt;/span&gt;

    &lt;span class="kw"&gt;section&lt;/span&gt; .text:                  &lt;span class="co"&gt;; start of the text (code) section&lt;/span&gt;
    &lt;span class="kw"&gt;align&lt;/span&gt; &lt;span class="dv"&gt;4&lt;/span&gt;                         &lt;span class="co"&gt;; the code must be 4 byte aligned&lt;/span&gt;
        &lt;span class="dt"&gt;dd&lt;/span&gt; MAGIC_NUMBER             &lt;span class="co"&gt;; write the magic number to the machine code,&lt;/span&gt;
        &lt;span class="dt"&gt;dd&lt;/span&gt; FLAGS                    &lt;span class="co"&gt;; the flags,&lt;/span&gt;
        &lt;span class="dt"&gt;dd&lt;/span&gt; CHECKSUM                 &lt;span class="co"&gt;; and the checksum&lt;/span&gt;

&lt;span class="fu"&gt;    start:&lt;/span&gt;                          &lt;span class="co"&gt;; the loader label (defined as entry point in linker script)&lt;/span&gt;
      &lt;span class="kw"&gt;mov&lt;/span&gt; &lt;span class="kw"&gt;ebx&lt;/span&gt;, &lt;span class="bn"&gt;0xb8000&lt;/span&gt; &lt;span class="co"&gt;; VGA area base&lt;/span&gt;
      &lt;span class="kw"&gt;mov&lt;/span&gt; &lt;span class="kw"&gt;ecx&lt;/span&gt;, &lt;span class="dv"&gt;80&lt;/span&gt;*&lt;span class="dv"&gt;25&lt;/span&gt; &lt;span class="co"&gt;; console size&lt;/span&gt;

      &lt;span class="co"&gt;; Clear screen&lt;/span&gt;
      &lt;span class="kw"&gt;mov&lt;/span&gt; &lt;span class="kw"&gt;edx&lt;/span&gt;, &lt;span class="bn"&gt;0x0020&lt;/span&gt;&lt;span class="co"&gt;;  space symbol (0x20) on black background&lt;/span&gt;
&lt;span class="fu"&gt;    clear_loop:&lt;/span&gt;
      &lt;span class="kw"&gt;mov&lt;/span&gt; [&lt;span class="kw"&gt;ebx&lt;/span&gt; + &lt;span class="kw"&gt;ecx&lt;/span&gt;], &lt;span class="kw"&gt;edx&lt;/span&gt;
      &lt;span class="kw"&gt;dec&lt;/span&gt; &lt;span class="kw"&gt;ecx&lt;/span&gt;
      &lt;span class="kw"&gt;cmp&lt;/span&gt; &lt;span class="kw"&gt;ecx&lt;/span&gt;, -&lt;span class="dv"&gt;1&lt;/span&gt;
      &lt;span class="kw"&gt;jnz&lt;/span&gt; clear_loop
      
      &lt;span class="co"&gt;; Print red &amp;#39;A&amp;#39;&lt;/span&gt;
      &lt;span class="kw"&gt;mov&lt;/span&gt; &lt;span class="kw"&gt;eax&lt;/span&gt;, ( &lt;span class="dv"&gt;4&lt;/span&gt; &amp;lt;&amp;lt; &lt;span class="dv"&gt;8&lt;/span&gt; | &lt;span class="bn"&gt;0x41&lt;/span&gt;) &lt;span class="co"&gt;; &amp;#39;A&amp;#39; symbol (0x41) print in red (0x4)&lt;/span&gt;
      &lt;span class="kw"&gt;mov&lt;/span&gt; [&lt;span class="kw"&gt;ebx&lt;/span&gt;], &lt;span class="kw"&gt;eax&lt;/span&gt;

&lt;span class="fu"&gt;    .loop:&lt;/span&gt;
        &lt;span class="kw"&gt;jmp&lt;/span&gt; .&lt;span class="kw"&gt;loop&lt;/span&gt;                   &lt;span class="co"&gt;; loop forever&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This kernel works with VGA buffer&amp;nbsp;&amp;mdash; it&amp;nbsp;clears the screen from the old BIOS messages and print capital ‘A’ letter in&amp;nbsp;red. After it, it&amp;nbsp;just loop forever.&lt;/p&gt;
&lt;p&gt;Compile it&amp;nbsp;with&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nasm -f elf32 kernel.S -o kernel.o&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;nasm&lt;/code&gt; generates object file, which is&amp;nbsp;NOT suitable for executing because its addresses need to&amp;nbsp;be&amp;nbsp;relocated from base address &lt;code&gt;0&amp;times;0&lt;/code&gt;, combined with other section, resolve external symbols and so&amp;nbsp;on. This is&amp;nbsp;a&amp;nbsp;job of&amp;nbsp;the linker program.&lt;/p&gt;
&lt;p&gt;When compiling program for userspace application &lt;code&gt;gcc&lt;/code&gt; will invoke linker for you with default linker script. But for kernel space code you must provide your own link script that will tell where to&amp;nbsp;put various sections of&amp;nbsp;the code. Our kernel code has only &lt;code&gt;.text&lt;/code&gt; section, no&amp;nbsp;stack or&amp;nbsp;heap, and multiboot header is&amp;nbsp;hardcoded into &lt;code&gt;.text&lt;/code&gt; section. So&amp;nbsp;link script is&amp;nbsp;pretty simple:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ENTRY(start)                /* the name of the entry label */

SECTIONS {
    . = 0x00100000;          /* the code should be loaded at 1 MB */

    .text ALIGN (0x1000) :   /* align at 4 KB */
    {
        *(.text)             /* all text sections from all files */
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I’ve&amp;nbsp;already touched linking part in&amp;nbsp;&lt;a href="http://alex.dzyoba.com/programming/restrict-memory.html#Linker"&gt;Restricting program memory article&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Basically, we’re&amp;nbsp;saying &amp;laquo;Start our code at&amp;nbsp;1MiB and put section &lt;code&gt;.text&lt;/code&gt; in&amp;nbsp;the beginning with 4K alignment. Entry point is&amp;nbsp;&lt;code&gt;start&lt;/code&gt;&amp;raquo;.&lt;/p&gt;
&lt;p&gt;Link like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ld -melf_i386 -T link.ld kernel.o -o kernel&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And run kernel directly with QEMU:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ qemu-system-i386 -kernel kernel&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You’re&amp;nbsp;got it:&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img src="/assets/img/qemu-kernel.png" alt="QEMU direct kernel" /&gt;
&lt;p class="caption"&gt;QEMU direct kernel&lt;/p&gt;
&lt;/div&gt;
&lt;h2 id="the-multiboot-part"&gt;The multiboot part&lt;/h2&gt;
&lt;p&gt;When computer is&amp;nbsp;being power up&amp;nbsp;it&amp;nbsp;starts executing code according to&amp;nbsp;its &amp;laquo;reset vector&amp;raquo;. For modern x86 processors it&amp;nbsp;is&amp;nbsp;&lt;code&gt;0xFFFFFFF0&lt;/code&gt;. At&amp;nbsp;this address motherboard sets jump instruction to&amp;nbsp;the BIOS code. CPU is&amp;nbsp;in&amp;nbsp;&amp;laquo;Real mode&amp;raquo; (16 bit addressing with segmentation (up&amp;nbsp;to&amp;nbsp;1MiB), no&amp;nbsp;protection, no&amp;nbsp;paging).&lt;/p&gt;
&lt;p&gt;BIOS does all the usual work like scan for devices and initializes it&amp;nbsp;and finds bootable device. After bootable device found it&amp;nbsp;passes control to&amp;nbsp;bootloader on&amp;nbsp;this device.&lt;/p&gt;
&lt;p&gt;Bootloader loads itself from disk (in&amp;nbsp;case of&amp;nbsp;&lt;nobr&gt;multi-stage&lt;/nobr&gt;) finds kernel and load it&amp;nbsp;into memory. In&amp;nbsp;the dark old days every OS&amp;nbsp;had its own format and rules, so&amp;nbsp;there was a&amp;nbsp;variaty of&amp;nbsp;incompatible bootloaders. But now there is&amp;nbsp;a&amp;nbsp;Multiboot specification that gives your kernel some guarantees and amenities in&amp;nbsp;exchange to&amp;nbsp;comply the specification and provide Multiboot header.&lt;/p&gt;
&lt;p&gt;Dependence on&amp;nbsp;Multiboot specification is&amp;nbsp;a&amp;nbsp;big deal because it&amp;nbsp;helps make the life MUCH easier and this is&amp;nbsp;how:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;nobr&gt;Multiboot-compliant&lt;/nobr&gt; bootloader sets the system &lt;a href="http://www.gnu.org/software/grub/manual/multiboot/multiboot.html#Machine-state"&gt;to&amp;nbsp;&lt;nobr&gt;well-defined&lt;/nobr&gt; state&lt;/a&gt;, most notably:
&lt;ul&gt;
&lt;li&gt;Transfer CPU to&amp;nbsp;protected mode to&amp;nbsp;allow you access all the memory&lt;/li&gt;
&lt;li&gt;Enable A20 line&amp;nbsp;&amp;mdash; an&amp;nbsp;old quirk to&amp;nbsp;access additional segment in&amp;nbsp;real mode&lt;/li&gt;
&lt;li&gt;Global descriptor table and Interrupt descriptor table are undefined, so&amp;nbsp;OS&amp;nbsp;must setup its own&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;nobr&gt;Multiboot-compliant&lt;/nobr&gt; OS&amp;nbsp;kernels:
&lt;ul&gt;
&lt;li&gt;Can (and should) be&amp;nbsp;in&amp;nbsp;ELF format&lt;/li&gt;
&lt;li&gt;Must set only 12 bytes to&amp;nbsp;correctly boot&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In&amp;nbsp;general, booting multiboot compliant kernel is&amp;nbsp;simple, especially if&amp;nbsp;it’s&amp;nbsp;in&amp;nbsp;ELF format:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Multiboot bootloader search first 8K bytes of&amp;nbsp;kernel image for Multiboot header (find it&amp;nbsp;by&amp;nbsp;magic &lt;code&gt;0&amp;times;1BADB002&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;If&amp;nbsp;the image is&amp;nbsp;in&amp;nbsp;ELF format it&amp;nbsp;loads section according to&amp;nbsp;the section table&lt;/li&gt;
&lt;li&gt;If&amp;nbsp;the image is&amp;nbsp;not in&amp;nbsp;ELF format it&amp;nbsp;loads kernel to&amp;nbsp;address either supplied in&amp;nbsp;address field or&amp;nbsp;in&amp;nbsp;the flags field.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In&amp;nbsp;our kernel’s&amp;nbsp;text section we’ve&amp;nbsp;done it:&lt;/p&gt;
&lt;pre class="sourceCode nasm"&gt;&lt;code class="sourceCode nasm"&gt;    MAGIC_NUMBER &lt;span class="dt"&gt;equ&lt;/span&gt; &lt;span class="bn"&gt;0x1BADB002&lt;/span&gt;     &lt;span class="co"&gt;; define the magic number constant&lt;/span&gt;
    FLAGS        &lt;span class="dt"&gt;equ&lt;/span&gt;&lt;span class="bn"&gt; 0x0            &lt;/span&gt;&lt;span class="co"&gt;; multiboot flags&lt;/span&gt;
    CHECKSUM     &lt;span class="dt"&gt;equ&lt;/span&gt; -MAGIC_NUMBER  &lt;span class="co"&gt;; calculate the checksum&lt;/span&gt;
                                    &lt;span class="co"&gt;; (magic number + checksum + flags should equal 0)&lt;/span&gt;

    &lt;span class="kw"&gt;section&lt;/span&gt; .text:                  &lt;span class="co"&gt;; start of the text (code) section&lt;/span&gt;
    &lt;span class="kw"&gt;align&lt;/span&gt; &lt;span class="dv"&gt;4&lt;/span&gt;                         &lt;span class="co"&gt;; the code must be 4 byte aligned&lt;/span&gt;
        &lt;span class="dt"&gt;dd&lt;/span&gt; MAGIC_NUMBER             &lt;span class="co"&gt;; write the magic number to the machine code,&lt;/span&gt;
        &lt;span class="dt"&gt;dd&lt;/span&gt; FLAGS                    &lt;span class="co"&gt;; the flags,&lt;/span&gt;
        &lt;span class="dt"&gt;dd&lt;/span&gt; CHECKSUM                 &lt;span class="co"&gt;; and the checksum&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We&amp;nbsp;didn’t&amp;nbsp;specify any flags because we&amp;nbsp;don’t&amp;nbsp;need anything from bootloader like memory maps and stuff, and bootloader doesn’t&amp;nbsp;need anything from us&amp;nbsp;because we’re&amp;nbsp;in&amp;nbsp;ELF format. For other formats you must supply loading address in&amp;nbsp;its multiboot header. Multiboot header is&amp;nbsp;pretty simple:&lt;/p&gt;
&lt;table summary&gt;
&lt;tbody&gt;
&lt;tr align="left"&gt;
&lt;td valign="top" width="10%"&gt;
Offset &lt;/td&gt;
&lt;td valign="top" width="10%"&gt;
Type &lt;/td&gt;
&lt;td valign="top" width="20%"&gt;
Field Name
&lt;/td&gt;
&lt;td valign="top" width="50%"&gt;
Note &lt;br&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr align="left"&gt;
&lt;td valign="top" width="10%"&gt;
0 &lt;/td&gt;
&lt;td valign="top" width="10%"&gt;
u32 &lt;/td&gt;
&lt;td valign="top" width="20%"&gt;
magic &lt;/td&gt;
&lt;td valign="top" width="50%"&gt;
required &lt;br&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr align="left"&gt;
&lt;td valign="top" width="10%"&gt;
4 &lt;/td&gt;
&lt;td valign="top" width="10%"&gt;
u32 &lt;/td&gt;
&lt;td valign="top" width="20%"&gt;
flags &lt;/td&gt;
&lt;td valign="top" width="50%"&gt;
required &lt;br&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr align="left"&gt;
&lt;td valign="top" width="10%"&gt;
8 &lt;/td&gt;
&lt;td valign="top" width="10%"&gt;
u32 &lt;/td&gt;
&lt;td valign="top" width="20%"&gt;
checksum &lt;/td&gt;
&lt;td valign="top" width="50%"&gt;
required &lt;br&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr align="left"&gt;
&lt;td valign="top" width="10%"&gt;
12 &lt;/td&gt;
&lt;td valign="top" width="10%"&gt;
u32 &lt;/td&gt;
&lt;td valign="top" width="20%"&gt;
header_addr &lt;/td&gt;
&lt;td valign="top" width="50%"&gt;
if&amp;nbsp;flags[16] is&amp;nbsp;set &lt;br&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr align="left"&gt;
&lt;td valign="top" width="10%"&gt;
16 &lt;/td&gt;
&lt;td valign="top" width="10%"&gt;
u32 &lt;/td&gt;
&lt;td valign="top" width="20%"&gt;
load_addr &lt;/td&gt;
&lt;td valign="top" width="50%"&gt;
if&amp;nbsp;flags[16] is&amp;nbsp;set &lt;br&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr align="left"&gt;
&lt;td valign="top" width="10%"&gt;
20 &lt;/td&gt;
&lt;td valign="top" width="10%"&gt;
u32 &lt;/td&gt;
&lt;td valign="top" width="20%"&gt;
load_end_addr &lt;/td&gt;
&lt;td valign="top" width="50%"&gt;
if&amp;nbsp;flags[16] is&amp;nbsp;set &lt;br&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr align="left"&gt;
&lt;td valign="top" width="10%"&gt;
24 &lt;/td&gt;
&lt;td valign="top" width="10%"&gt;
u32 &lt;/td&gt;
&lt;td valign="top" width="20%"&gt;
bss_end_addr &lt;/td&gt;
&lt;td valign="top" width="50%"&gt;
if&amp;nbsp;flags[16] is&amp;nbsp;set &lt;br&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr align="left"&gt;
&lt;td valign="top" width="10%"&gt;
28 &lt;/td&gt;
&lt;td valign="top" width="10%"&gt;
u32 &lt;/td&gt;
&lt;td valign="top" width="20%"&gt;
entry_addr &lt;/td&gt;
&lt;td valign="top" width="50%"&gt;
if&amp;nbsp;flags[16] is&amp;nbsp;set &lt;br&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr align="left"&gt;
&lt;td valign="top" width="10%"&gt;
32 &lt;/td&gt;
&lt;td valign="top" width="10%"&gt;
u32 &lt;/td&gt;
&lt;td valign="top" width="20%"&gt;
mode_type &lt;/td&gt;
&lt;td valign="top" width="50%"&gt;
if&amp;nbsp;flags[2] is&amp;nbsp;set &lt;br&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr align="left"&gt;
&lt;td valign="top" width="10%"&gt;
36 &lt;/td&gt;
&lt;td valign="top" width="10%"&gt;
u32 &lt;/td&gt;
&lt;td valign="top" width="20%"&gt;
width &lt;/td&gt;
&lt;td valign="top" width="50%"&gt;
if&amp;nbsp;flags[2] is&amp;nbsp;set &lt;br&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr align="left"&gt;
&lt;td valign="top" width="10%"&gt;
40 &lt;/td&gt;
&lt;td valign="top" width="10%"&gt;
u32 &lt;/td&gt;
&lt;td valign="top" width="20%"&gt;
height &lt;/td&gt;
&lt;td valign="top" width="50%"&gt;
if&amp;nbsp;flags[2] is&amp;nbsp;set &lt;br&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr align="left"&gt;
&lt;td valign="top" width="10%"&gt;
44 &lt;/td&gt;
&lt;td valign="top" width="10%"&gt;
u32 &lt;/td&gt;
&lt;td valign="top" width="20%"&gt;
depth &lt;/td&gt;
&lt;td valign="top" width="50%"&gt;
if&amp;nbsp;flags[2] is&amp;nbsp;set &lt;br&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id="the-booting"&gt;The booting&lt;/h2&gt;
&lt;p&gt;Now lets boot our kernel like a&amp;nbsp;serious guys.&lt;/p&gt;
&lt;p&gt;First, we&amp;nbsp;create ISO image with help of&amp;nbsp;&lt;code&gt;&lt;nobr&gt;grub2-mkrescue&lt;/nobr&gt;&lt;/code&gt;. Create hierarchy like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;isodir/
&amp;#9492;&amp;#9472;&amp;#9472; boot
    &amp;#9500;&amp;#9472;&amp;#9472; grub
    &amp;#9474;   &amp;#9492;&amp;#9472;&amp;#9472; grub.cfg
    &amp;#9492;&amp;#9472;&amp;#9472; kernel&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Where grub.cfg is:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;menuentry &amp;quot;kernel&amp;quot; {
    multiboot /boot/kernel
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And then invoke &lt;code&gt;&lt;nobr&gt;grub2-mkrescue&lt;/nobr&gt;&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;grub2-mkrescue -o hello-kernel.iso isodir&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And now we&amp;nbsp;can boot it&amp;nbsp;in&amp;nbsp;any PC&amp;nbsp;compatible machine:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;qemu-system-i386 -cdrom hello-kernel.iso&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’ll&amp;nbsp;see grub2 menu, where we&amp;nbsp;can select our &amp;laquo;kernel&amp;raquo; and see the red ‘A’ letter.&lt;/p&gt;
&lt;p&gt;Isn’t&amp;nbsp;it&amp;nbsp;great?&lt;/p&gt;
&lt;div class="footnotes"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn1"&gt;&lt;p&gt;My&amp;nbsp;brain hurts: all these real/protected mode, A20 line, segmentation, etc. are so&amp;nbsp;quirky. I&amp;nbsp;hope ARM booting is&amp;nbsp;not that complicated.&lt;a href="#fnref1"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content>
  </entry>
  <entry xml:base="http://alex.dzyoba.com/feed">
    <title type="text">Linux profiling. Perf</title>
    <id>linux/profiling-perf.html</id>
    <updated>2015-09-09T00:00:00Z</updated>
    <link href="linux/profiling-perf.html" />
    <author>
      <name>Alex Dzyoba</name>
    </author>
    <content type="html">&lt;p&gt;TOC:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;&lt;a href="/linux/profiling-intro.html"&gt;Intro&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/linux/profiling-gprof-gcov.html"&gt;Userspace profiling: gprof, gcov&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/linux/profiling-valgrind.html"&gt;Userspace profiling: Valgrind&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/linux/profiling-kernel.html"&gt;Kernel profiling: Intro&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/linux/profiling-ftrace.html"&gt;Kernel profiling: ftrace&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Kernel profiling: perf&lt;/li&gt;
&lt;li&gt;&lt;a href="/linux/profiling-systemtap.html"&gt;Kernel profiling: SystemTap&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Various tools&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="perf-overview"&gt;Perf overview&lt;/h2&gt;
&lt;p&gt;Perf is&amp;nbsp;a&amp;nbsp;facility comprised of&amp;nbsp;kernel infrastructure for gathering various events and userspace tool to&amp;nbsp;get gathered data from the kernel and analyze it. It&amp;nbsp;is&amp;nbsp;like a&amp;nbsp;&lt;code&gt;gprof&lt;/code&gt;, but it&amp;nbsp;is&amp;nbsp;&lt;nobr&gt;non-invasive&lt;/nobr&gt;, &lt;nobr&gt;low-overhead&lt;/nobr&gt; and profile whole stack, including your app, libraries, system calls AND kernel with CPU!&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;perf&lt;/code&gt; tool supports a&amp;nbsp;list of&amp;nbsp;measurable events that you can view with &lt;code&gt;perf list&lt;/code&gt; command. The tool and underlying kernel interface can measure events coming from different sources. For instance, some events are pure kernel counters, in&amp;nbsp;this case they are called software events. Examples include: &lt;nobr&gt;context-switches&lt;/nobr&gt;, &lt;nobr&gt;minor-faults&lt;/nobr&gt;, &lt;nobr&gt;page-faults&lt;/nobr&gt; and others.&lt;/p&gt;
&lt;p&gt;Another source of&amp;nbsp;events is&amp;nbsp;the processor itself and its Performance Monitoring Unit (PMU). It&amp;nbsp;provides a&amp;nbsp;list of&amp;nbsp;events to&amp;nbsp;measure &lt;nobr&gt;micro-architectural&lt;/nobr&gt; events such as&amp;nbsp;the number of&amp;nbsp;cycles, instructions retired, L1 cache misses and so&amp;nbsp;on. Those events are called &amp;laquo;PMU hardware events&amp;raquo; or&amp;nbsp;&amp;laquo;hardware events&amp;raquo; for short. They vary with each processor type and model&amp;nbsp;&amp;mdash; look at&amp;nbsp;&lt;a href="http://web.eece.maine.edu/~vweaver/projects/perf_events/support.html"&gt;this Vince Weaver’s&amp;nbsp;perf page&lt;/a&gt; for details&lt;/p&gt;
&lt;p&gt;The &amp;laquo;perf_events&amp;raquo; interface also provides a&amp;nbsp;small set of&amp;nbsp;common hardware events monikers. On&amp;nbsp;each processor, those events get mapped onto an&amp;nbsp;actual events provided by&amp;nbsp;the CPU if&amp;nbsp;they exist, otherwise the event cannot be&amp;nbsp;used. Somewhat confusingly, these are also called hardware events and hardware cache events.&lt;/p&gt;
&lt;p&gt;Finally, there are also tracepoint events which are implemented by&amp;nbsp;the kernel &lt;a href="/linux/profiling-ftrace.html"&gt;ftrace&lt;/a&gt; infrastructure. Those are only available with the 2.6.3x and newer kernels.&lt;/p&gt;
&lt;p&gt;Thanks to&amp;nbsp;such a&amp;nbsp;variety of&amp;nbsp;events and analysis abilities of&amp;nbsp;userspace tool (see below) &lt;code&gt;perf&lt;/code&gt; is&amp;nbsp;a&amp;nbsp;big fish in&amp;nbsp;the world of&amp;nbsp;tracing and profiling of&amp;nbsp;Linux systems. It&amp;nbsp;is&amp;nbsp;a&amp;nbsp;really versatile tool that may be&amp;nbsp;used in&amp;nbsp;several ways of&amp;nbsp;which I&amp;nbsp;know a&amp;nbsp;few:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;Record a&amp;nbsp;profile and analyze it&amp;nbsp;later: &lt;code&gt;perf record&lt;/code&gt; + &lt;code&gt;perf report&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Gather statistics for application or&amp;nbsp;system: &lt;code&gt;perf stat&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;nobr&gt;Real-time&lt;/nobr&gt; &lt;nobr&gt;function-wise&lt;/nobr&gt; analysis: &lt;code&gt;perf top&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Trace application or&amp;nbsp;system: &lt;code&gt;perf trace&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Each of&amp;nbsp;these approaches include tremendous amount of&amp;nbsp;possibilities for sorting, filtering, grouping and so&amp;nbsp;on.&lt;/p&gt;
&lt;p&gt;But as&amp;nbsp;someone said, &lt;code&gt;perf&lt;/code&gt; is&amp;nbsp;a&amp;nbsp;powerful tool with a&amp;nbsp;little documentation. So&amp;nbsp;in&amp;nbsp;this article I’ll&amp;nbsp;try to&amp;nbsp;share some of&amp;nbsp;my&amp;nbsp;knowledge about it.&lt;/p&gt;
&lt;h2 id="basic-perf-workflows"&gt;Basic perf workflows&lt;/h2&gt;
&lt;h3 id="preflight-check"&gt;Preflight check&lt;/h3&gt;
&lt;p&gt;First thing to&amp;nbsp;do&amp;nbsp;when you start working with Perf is&amp;nbsp;to&amp;nbsp;launch &lt;code&gt;perf test&lt;/code&gt;. This will check your system and kernel features and report if&amp;nbsp;something isn’t&amp;nbsp;available. Usually, you need to&amp;nbsp;make as&amp;nbsp;much as&amp;nbsp;possible &amp;laquo;OK"s. Beware though that &lt;code&gt;perf&lt;/code&gt; will behave differently when launched under &amp;laquo;root&amp;raquo; and ordinary user. It’s&amp;nbsp;smart enough to&amp;nbsp;let you do&amp;nbsp;some things without root priveleges. There is&amp;nbsp;a&amp;nbsp;control file at&amp;nbsp;&amp;laquo;/proc/sys/kernel/perf_event_paranoid&amp;raquo; that you can tweak in&amp;nbsp;order to&amp;nbsp;change access to&amp;nbsp;perf events:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ perf stat -a
Error:
You may not have permission to collect system-wide stats.
Consider tweaking /proc/sys/kernel/perf_event_paranoid:
 -1 - Not paranoid at all
  0 - Disallow raw tracepoint access for unpriv
  1 - Disallow cpu events for unpriv
  2 - Disallow kernel profiling for unpriv&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After you played with &lt;code&gt;perf test&lt;/code&gt;, you can see what hardware events are available to&amp;nbsp;you with &lt;code&gt;perf list&lt;/code&gt;. Again, the list will differ depending on&amp;nbsp;current user id. Also, the amount of&amp;nbsp;events will depend on&amp;nbsp;your hardware: x86_64 CPUs have much more hardware events than some &lt;nobr&gt;low-end&lt;/nobr&gt; ARM processors.&lt;/p&gt;
&lt;h3 id="system-statistics"&gt;System statistics&lt;/h3&gt;
&lt;p&gt;Now to&amp;nbsp;some real profiling. To&amp;nbsp;check general health of&amp;nbsp;your system you can gather statistics with &lt;code&gt;perf stat&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# perf stat -a sleep 5

 Performance counter stats for &amp;#39;system wide&amp;#39;:

      20005.830934      task-clock (msec)         #    3.999 CPUs utilized            (100.00%)
             4,236      context-switches          #    0.212 K/sec                    (100.00%)
               160      cpu-migrations            #    0.008 K/sec                    (100.00%)
             2,193      page-faults               #    0.110 K/sec                  
     2,414,170,118      cycles                    #    0.121 GHz                      (83.35%)
     4,196,068,507      stalled-cycles-frontend   #  173.81% frontend cycles idle     (83.34%)
     3,735,211,886      stalled-cycles-backend    #  154.72% backend  cycles idle     (66.68%)
     2,109,428,612      instructions              #    0.87  insns per cycle        
                                                  #    1.99  stalled cycles per insn  (83.34%)
       406,168,187      branches                  #   20.302 M/sec                    (83.32%)
         6,869,950      branch-misses             #    1.69% of all branches          (83.32%)

       5.003164377 seconds time elapsed&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here you can see how many context switches, migrations, page faults and other events happened during 5 seconds, along with some simple calculations. In&amp;nbsp;fact &lt;code&gt;perf&lt;/code&gt; tool highlight statistics that you should worry about. In&amp;nbsp;my&amp;nbsp;case it’s&amp;nbsp;a&amp;nbsp;&lt;nobr&gt;stalled-cycles-frontend&lt;/nobr&gt;/backend. This counter shows how much time CPU pipeline is&amp;nbsp;stalled (i.e. not advanced) due to&amp;nbsp;some external cause like waiting for memory access.&lt;/p&gt;
&lt;p&gt;Along with &lt;code&gt;perf stat&lt;/code&gt; you have &lt;code&gt;perf top&lt;/code&gt;&amp;nbsp;&amp;mdash; a&amp;nbsp;&lt;code&gt;top&lt;/code&gt; like utility, but that works &lt;nobr&gt;symbol-wise&lt;/nobr&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# perf top -a --stdio

PerfTop:     361 irqs/sec  kernel:35.5%  exact:  0.0% [4000Hz cycles],  (all, 4 CPUs)
----------------------------------------------------------------------------------------

 2.06%  libglib-2.0.so.0.4400.1     [.] g_mutex_lock                   
 1.99%  libglib-2.0.so.0.4400.1     [.] g_mutex_unlock                 
 1.47%  [kernel]                    [k] __fget                         
 1.34%  libpython2.7.so.1.0         [.] PyEval_EvalFrameEx             
 1.07%  [kernel]                    [k] copy_user_generic_string       
 1.00%  libpthread-2.21.so          [.] pthread_mutex_lock             
 0.96%  libpthread-2.21.so          [.] pthread_mutex_unlock           
 0.85%  libc-2.21.so                [.] _int_malloc                    
 0.83%  libpython2.7.so.1.0         [.] PyParser_AddToken              
 0.82%  [kernel]                    [k] do_sys_poll                    
 0.81%  libQtCore.so.4.8.6          [.] QMetaObject::activate          
 0.77%  [kernel]                    [k] fput                           
 0.76%  [kernel]                    [k] __audit_syscall_exit           
 0.75%  [kernel]                    [k] unix_stream_recvmsg            
 0.63%  [kernel]                    [k] ia32_sysenter_target           &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here you can see kernel functions, glib library functions, CPython functions, Qt&amp;nbsp;framework functions and a&amp;nbsp;pthread functions combined with its overhead. It’s&amp;nbsp;a&amp;nbsp;great tool to&amp;nbsp;peek into system state to&amp;nbsp;see what’s&amp;nbsp;going on.&lt;/p&gt;
&lt;h3 id="application-profiling"&gt;Application profiling&lt;/h3&gt;
&lt;p&gt;To&amp;nbsp;profile particular application, either already running or&amp;nbsp;not, you use &lt;code&gt;perf record&lt;/code&gt; to&amp;nbsp;collect events and then &lt;code&gt;perf report&lt;/code&gt; to&amp;nbsp;analyze program behavior. Let’s&amp;nbsp;see:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# perf record -bag updatedb
[ perf record: Woken up 259 times to write data ]
[ perf record: Captured and wrote 65.351 MB perf.data (127127 samples) ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now dive into data with &lt;code&gt;perf report&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# perf report&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You will see a&amp;nbsp;nice interactive TUI interface.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img src="/assets/img/perf-tui.png" alt="perf tui" /&gt;
&lt;p class="caption"&gt;perf tui&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;You can zoom into pid/thread&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img src="/assets/img/perf-zoom-into-thread.png" alt="perf zoom into thread" /&gt;
&lt;p class="caption"&gt;perf zoom into thread&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;and see what’s&amp;nbsp;going on&amp;nbsp;there&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img src="/assets/img/perf-thread-info.png" alt="perf thread info" /&gt;
&lt;p class="caption"&gt;perf thread info&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;You can look into nice assembly code (this looks almost as&amp;nbsp;in&amp;nbsp;&lt;a href="http://www.radare.org/r/"&gt;radare&lt;/a&gt;)&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img src="/assets/img/perf-assembly.png" alt="perf assembly" /&gt;
&lt;p class="caption"&gt;perf assembly&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;and run scripts on&amp;nbsp;it&amp;nbsp;to&amp;nbsp;see, for example, function calls histogram:&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img src="/assets/img/perf-histogram.png" alt="perf histogram" /&gt;
&lt;p class="caption"&gt;perf histogram&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;If&amp;nbsp;it’s&amp;nbsp;not enough to&amp;nbsp;you, there are a&amp;nbsp;lot of&amp;nbsp;options both for &lt;code&gt;perf record&lt;/code&gt; and &lt;code&gt;perf report&lt;/code&gt; so&amp;nbsp;play with it.&lt;/p&gt;
&lt;h3 id="other"&gt;Other&lt;/h3&gt;
&lt;p&gt;In&amp;nbsp;addition to&amp;nbsp;that you can find tools to&amp;nbsp;profile kernel memory subsystem, locking, kvm guests, scheduling, do&amp;nbsp;benchmarking and even create timecharts.&lt;/p&gt;
&lt;p&gt;Now let’s&amp;nbsp;try to&amp;nbsp;solve &lt;a href="/linux/profiling-intro.html"&gt;our problem with &lt;code&gt;block_hasher&lt;/code&gt;&lt;/a&gt; with help of&amp;nbsp;&lt;code&gt;perf&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id="hot-spots-profiling"&gt;Hot spots profiling&lt;/h2&gt;
&lt;p&gt;All right, as&amp;nbsp;we&amp;nbsp;saw &lt;a href="/linux/profiling-gprof-gcov.html#not-application"&gt;previously&lt;/a&gt; we&amp;nbsp;spend time in&amp;nbsp;kernel waiting for I/O. Let’s&amp;nbsp;see if&amp;nbsp;&lt;code&gt;perf&lt;/code&gt; can help us.&lt;/p&gt;
&lt;p&gt;Start with &lt;code&gt;perf stat&lt;/code&gt; giving options for detailed and scaled counters for CPU (&amp;laquo;-dac&amp;raquo;)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# perf stat -dac ./block_hasher -d /dev/md0 -b 1048576 -t 10 -n 1000

 Performance counter stats for &amp;#39;system wide&amp;#39;:

      32978.276562      task-clock (msec)         #    4.000 CPUs utilized            (100.00%)
             6,349      context-switches          #    0.193 K/sec                    (100.00%)
               142      cpu-migrations            #    0.004 K/sec                    (100.00%)
             2,709      page-faults               #    0.082 K/sec                  
    20,998,366,508      cycles                    #    0.637 GHz                      (41.08%)
    23,007,780,670      stalled-cycles-frontend   #  109.57% frontend cycles idle     (37.50%)
    18,687,140,923      stalled-cycles-backend    #   88.99% backend  cycles idle     (42.64%)
    23,466,705,987      instructions              #    1.12  insns per cycle        
                                                  #    0.98  stalled cycles per insn  (53.74%)
     4,389,207,421      branches                  #  133.094 M/sec                    (55.51%)
        11,086,505      branch-misses             #    0.25% of all branches          (55.53%)
     7,435,101,164      L1-dcache-loads           #  225.455 M/sec                    (37.50%)
       248,499,989      L1-dcache-load-misses     #    3.34% of all L1-dcache hits    (26.52%)
       111,621,984      LLC-loads                 #    3.385 M/sec                    (28.77%)
   &amp;lt;not supported&amp;gt;      LLC-load-misses:HG       

       8.245518548 seconds time elapsed&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Well, nothing really suspicious. 6K page context switches is&amp;nbsp;OK&amp;nbsp;because my&amp;nbsp;machine is&amp;nbsp;&lt;nobr&gt;2-core&lt;/nobr&gt; and I’m&amp;nbsp;running 10 threads. 2K page faults is&amp;nbsp;fine since we’re&amp;nbsp;reading a&amp;nbsp;lot of&amp;nbsp;data from disks. Big &lt;nobr&gt;stalled-cycles-frontend&lt;/nobr&gt;/backend is&amp;nbsp;kind of&amp;nbsp;outliers here since it’s&amp;nbsp;still big on&amp;nbsp;simple &lt;code&gt;ls&lt;/code&gt; and &lt;code&gt;-&lt;nobr&gt;per-core&lt;/nobr&gt;&lt;/code&gt; statistics shows 0.00% percents of&amp;nbsp;&lt;nobr&gt;stalled-cycles&lt;/nobr&gt;.&lt;/p&gt;
&lt;p&gt;Let’s&amp;nbsp;collect profile:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# perf record -a -g -s -d -b ./block_hasher -d /dev/md0 -b 1048576 -t 10 -n 1000
[ perf record: Woken up 73 times to write data ]
[ perf record: Captured and wrote 20.991 MB perf.data (33653 samples) ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Options are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;-a for all CPUs&lt;/li&gt;
&lt;li&gt;-g for call graphs&lt;/li&gt;
&lt;li&gt;-s for per thread count&lt;/li&gt;
&lt;li&gt;-d for sampling addresses. Not sure about this one, but it&amp;nbsp;doesn’t&amp;nbsp;affect profile&lt;/li&gt;
&lt;li&gt;-b for sample any taken branches&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now show me&amp;nbsp;the profile:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# perf report -g -T&lt;/code&gt;&lt;/pre&gt;
&lt;div class="figure"&gt;
&lt;img src="/assets/img/perf-report-block-hasher.png" alt="perf report of block_hasher" /&gt;
&lt;p class="caption"&gt;perf report of&amp;nbsp;block_hasher&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Nothing much. I’ve&amp;nbsp;looked into block_hasher threads, I’ve&amp;nbsp;built a&amp;nbsp;histogram, looked for vmlinux DSO, found instruction with most overhead&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img src="/assets/img/perf-lock-acquire-assembly.png" alt="perf __lock_acquire" /&gt;
&lt;p class="caption"&gt;perf __lock_acquire&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;and still can’t&amp;nbsp;say I&amp;nbsp;found what’s&amp;nbsp;wrong. That’s&amp;nbsp;because there is&amp;nbsp;no&amp;nbsp;real overhead, nothing is&amp;nbsp;spinning in&amp;nbsp;vain. Something is&amp;nbsp;just plain sleeping.&lt;/p&gt;
&lt;p&gt;What we’ve&amp;nbsp;done here and &lt;a href="/linux/profiling-ftrace.html"&gt;before in&amp;nbsp;ftrace part&lt;/a&gt; is&amp;nbsp;a&amp;nbsp;hot spots analysis, i.e. we&amp;nbsp;try to&amp;nbsp;find places in&amp;nbsp;our application or&amp;nbsp;system that cause CPU to&amp;nbsp;spin in&amp;nbsp;useless cycles. Usually, it’s&amp;nbsp;what you want but not today. We&amp;nbsp;need to&amp;nbsp;understand why &lt;code&gt;pread&lt;/code&gt; is&amp;nbsp;sleeping. And that’s&amp;nbsp;what I&amp;nbsp;call &amp;laquo;latency profiling&amp;raquo;.&lt;/p&gt;
&lt;h2 id="latency-profiling"&gt;Latency profiling&lt;/h2&gt;
&lt;h3 id="record-sched_stat-and-sched_switch-events"&gt;Record sched_stat and sched_switch events&lt;/h3&gt;
&lt;p&gt;When you search for perf documentation, first thing you find is&amp;nbsp;&lt;a href="https://perf.wiki.kernel.org/index.php/Tutorial"&gt;&amp;laquo;Perf tutorial&amp;raquo;&lt;/a&gt;. The &amp;laquo;perf tutorial&amp;raquo; page is&amp;nbsp;almost entirely dedicated to&amp;nbsp;the &amp;laquo;hot spots&amp;raquo; scenario, but, fortunately, there is&amp;nbsp;an&amp;nbsp;&amp;laquo;Other scenarios&amp;raquo; section with &lt;a href="https://perf.wiki.kernel.org/index.php/Tutorial#Other_Scenarios"&gt;&amp;laquo;Profiling sleep times&amp;raquo;&lt;/a&gt; tutorial.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Profiling sleep times&lt;/p&gt;
&lt;p&gt;This feature shows where and how long a&amp;nbsp;program is&amp;nbsp;sleeping or&amp;nbsp;waiting something.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Whoa, that’s&amp;nbsp;what we&amp;nbsp;need!&lt;/p&gt;
&lt;p&gt;Unfortunately scheduling stats profiling is&amp;nbsp;not working by&amp;nbsp;default. &lt;code&gt;perf inject&lt;/code&gt; failing with&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# perf inject -v -s -i perf.data.raw -o perf.data
registering plugin: /usr/lib64/traceevent/plugins/plugin_kmem.so
registering plugin: /usr/lib64/traceevent/plugins/plugin_mac80211.so
registering plugin: /usr/lib64/traceevent/plugins/plugin_function.so
registering plugin: /usr/lib64/traceevent/plugins/plugin_hrtimer.so
registering plugin: /usr/lib64/traceevent/plugins/plugin_sched_switch.so
registering plugin: /usr/lib64/traceevent/plugins/plugin_jbd2.so
registering plugin: /usr/lib64/traceevent/plugins/plugin_cfg80211.so
registering plugin: /usr/lib64/traceevent/plugins/plugin_scsi.so
registering plugin: /usr/lib64/traceevent/plugins/plugin_xen.so
registering plugin: /usr/lib64/traceevent/plugins/plugin_kvm.so
overriding event (263) sched:sched_switch with new print handler
build id event received for [kernel.kallsyms]:
8adbfad59810c80cb47189726415682e0734788a
failed to write feature 2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The reason is&amp;nbsp;that it&amp;nbsp;can’t&amp;nbsp;find in&amp;nbsp;&lt;nobr&gt;build-id&lt;/nobr&gt; cache scheduling stats symbols because CONFIG_SCHEDSTATS is&amp;nbsp;disabled because it&amp;nbsp;introduces some &amp;laquo;&lt;nobr&gt;non-trivial&lt;/nobr&gt; performance impact for context switches&amp;raquo;. Details in&amp;nbsp;Red Hat bugzilla &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1026506"&gt;Bug 1026506&lt;/a&gt; and &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1013225"&gt;Bug 1013225&lt;/a&gt;. Debian kernels also don’t&amp;nbsp;enable this option.&lt;/p&gt;
&lt;p&gt;You can recompile kernel enabling &amp;laquo;Collect scheduler statistics&amp;raquo; in&amp;nbsp;&lt;code&gt;make menuconfig&lt;/code&gt;, but happy Fedora users can just install &lt;a href="http://pkgs.fedoraproject.org/cgit/kernel.git/commit/?id=73e4f49352c74eeb2d0b951c47adf0b53278f84b"&gt;debug kernel&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;dnf install kernel-debug kernel-debug-devel kernel-debug-debuginfo&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, when everything works, we&amp;nbsp;can give it&amp;nbsp;a&amp;nbsp;try:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# perf record -e sched:sched_stat_sleep -e sched:sched_switch  -e sched:sched_process_exit -g -o perf.data.raw ./block_hasher -d /dev/md0 -b 1048576 -t 10 -n 1000
[ perf record: Woken up 1 times to write data ]
[ perf record: Captured and wrote 0.564 MB perf.data.raw (2001 samples) ]

# perf inject -v -s -i perf.data.raw -o perf.data.sched
registering plugin: /usr/lib64/traceevent/plugins/plugin_kmem.so
registering plugin: /usr/lib64/traceevent/plugins/plugin_mac80211.so
registering plugin: /usr/lib64/traceevent/plugins/plugin_function.so
registering plugin: /usr/lib64/traceevent/plugins/plugin_hrtimer.so
registering plugin: /usr/lib64/traceevent/plugins/plugin_sched_switch.so
registering plugin: /usr/lib64/traceevent/plugins/plugin_jbd2.so
registering plugin: /usr/lib64/traceevent/plugins/plugin_cfg80211.so
registering plugin: /usr/lib64/traceevent/plugins/plugin_scsi.so
registering plugin: /usr/lib64/traceevent/plugins/plugin_xen.so
registering plugin: /usr/lib64/traceevent/plugins/plugin_kvm.so
overriding event (266) sched:sched_switch with new print handler
build id event received for /usr/lib/debug/lib/modules/4.1.6-200.fc22.x86_64+debug/vmlinux: c6e34bcb0ab7d65e44644ea2263e89a07744bf85
Using /root/.debug/.build-id/c6/e34bcb0ab7d65e44644ea2263e89a07744bf85 for symbols&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But it’s&amp;nbsp;really disappointing, I’ve&amp;nbsp;expanded all callchains to&amp;nbsp;see nothing:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# perf report --show-total-period -i perf.data.sched
Samples: 10  of event &amp;#39;sched:sched_switch&amp;#39;, Event count (approx.): 31403254575
  Children      Self        Period  Command       Shared Object                           Symbol                                      
-  100.00%     0.00%             0  block_hasher  libpthread-2.21.so                      [.] pthread_join                            
   - pthread_join                                                                                                                     
        0                                                                                                                             
-  100.00%     0.00%             0  block_hasher  e34bcb0ab7d65e44644ea2263e89a07744bf85  [k] system_call                             
     system_call                                                                                                                      
   - pthread_join                                                                                                                     
        0                                                                                                                             
-  100.00%     0.00%             0  block_hasher  e34bcb0ab7d65e44644ea2263e89a07744bf85  [k] sys_futex                               
     sys_futex                                                                                                                        
     system_call                                                                                                                      
   - pthread_join                                                                                                                     
        0                                                                                                                             
-  100.00%     0.00%             0  block_hasher  e34bcb0ab7d65e44644ea2263e89a07744bf85  [k] do_futex                                
     do_futex                                                                                                                         
     sys_futex                                                                                                                        
     system_call                                                                                                                      
   - pthread_join                                                                                                                     
        0                                                                                                                             
-  100.00%     0.00%             0  block_hasher  e34bcb0ab7d65e44644ea2263e89a07744bf85  [k] futex_wait                              
     futex_wait                                                                                                                       
     do_futex                                                                                                                         
     sys_futex                                                                                                                        
     system_call                                                                                                                      
   - pthread_join                                                                                                                     
        0                                                                                                                             
-  100.00%     0.00%             0  block_hasher  e34bcb0ab7d65e44644ea2263e89a07744bf85  [k] futex_wait_queue_me                     
     futex_wait_queue_me                                                                                                              
     futex_wait                                                                                                                       
     do_futex                                                                                                                         
     sys_futex                                                                                                                        
     system_call                                                                                                                      
   - pthread_join                                                                                                                     
        0                                                                                                                             
-  100.00%     0.00%             0  block_hasher  e34bcb0ab7d65e44644ea2263e89a07744bf85  [k] schedule                                
     schedule                                                                                                                         
     futex_wait_queue_me                                                                                                              
     futex_wait                                                                                                                       
     do_futex                                                                                                                         
     sys_futex                                                                                                                        
     system_call                                                                                                                      
   - pthread_join                                                                                                                     
        0                                                                                                                             
-  100.00%   100.00%   31403254575  block_hasher  e34bcb0ab7d65e44644ea2263e89a07744bf85  [k] __schedule                              
     __schedule                                                                                                                       
     schedule                                                                                                                         
     futex_wait_queue_me                                                                                                              
     futex_wait                                                                                                                       
     do_futex                                                                                                                         
     sys_futex                                                                                                                        
     system_call                                                                                                                      
   - pthread_join                                                                                                                     
        0                                                                                                                             
-   14.52%     0.00%             0  block_hasher  [unknown]                               [.] 0000000000000000                        
     0                                                                                                                &lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="perf-sched"&gt;perf sched&lt;/h3&gt;
&lt;p&gt;Let’s&amp;nbsp;see what else can we&amp;nbsp;do. There is&amp;nbsp;a&amp;nbsp;&lt;code&gt;perf sched&lt;/code&gt; command that has &lt;code&gt;latency&lt;/code&gt; subcommand to&amp;nbsp;&amp;laquo;report the per task scheduling latencies and other scheduling properties of&amp;nbsp;the workload&amp;raquo;. Why not give it&amp;nbsp;a&amp;nbsp;shot?&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# perf sched record -o perf.sched -g ./block_hasher -d /dev/md0 -b 1048576 -t 10 -n 1000
[ perf record: Woken up 6 times to write data ]
[ perf record: Captured and wrote 13.998 MB perf.sched (56914 samples) ]

# perf report -i perf.sched&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I’ve&amp;nbsp;inspected samples for &lt;code&gt;sched_switch&lt;/code&gt; and &lt;code&gt;sched_stat_runtime&lt;/code&gt; events (15K and 17K respectively) and found nothing. But then I&amp;nbsp;looked in&amp;nbsp;&lt;code&gt;sched_stat_iowait&lt;/code&gt;.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img src="/assets/img/perf-sched-stat-iowait.png" alt="perf sched_stat_iowait" /&gt;
&lt;p class="caption"&gt;perf sched_stat_iowait&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;and there I&amp;nbsp;found really suspicious thing:&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img src="/assets/img/perf-dm-delay.png" alt="perf dm-delay" /&gt;
&lt;p class="caption"&gt;perf &lt;nobr&gt;dm-delay&lt;/nobr&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;See? Almost all symbols come from &amp;laquo;kernel.vmlinux&amp;raquo; shared object, but one with strange name &amp;laquo;0&amp;times;000000005f8ccc27&amp;raquo; comes from &amp;laquo;dm_delay&amp;raquo; object. Wait, what is&amp;nbsp;&amp;laquo;dm_delay&amp;raquo;? Quick find gives us&amp;nbsp;the answer: &lt;a name="dm-delay"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; dm-delay
&amp;gt; ========
&amp;gt;
&amp;gt; Device-Mapper&amp;#39;s &amp;quot;delay&amp;quot; target delays reads and/or writes
&amp;gt; and maps them to different devices.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;WHAT?! Delays reads and/or writes? Really?&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# dmsetup info 
Name:              delayed
State:             ACTIVE
Read Ahead:        256
Tables present:    LIVE
Open count:        1
Event number:      0
Major, minor:      253, 0
Number of targets: 1

# dmsetup table
delayed: 0 1000000 delay 1:7 0 30

# udevadm info -rq name /sys/dev/block/1:7
/dev/ram7&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So, we&amp;nbsp;have block device &amp;laquo;/dev/ram7&amp;raquo; mapped to&amp;nbsp;DeviceMapper &amp;laquo;delay&amp;raquo; target to, well, delay I/O requests to&amp;nbsp;30 milliseconds. That’s&amp;nbsp;why whole RAID was slow&amp;nbsp;&amp;mdash; performance of&amp;nbsp;RAID0 is&amp;nbsp;performance of&amp;nbsp;a&amp;nbsp;slowest disk in&amp;nbsp;RAID.&lt;/p&gt;
&lt;p&gt;Of&amp;nbsp;course, I&amp;nbsp;knew it&amp;nbsp;from the beginning. I&amp;nbsp;just wanted to&amp;nbsp;see if&amp;nbsp;I’ll&amp;nbsp;be&amp;nbsp;able to&amp;nbsp;detect it&amp;nbsp;with profiling tools. And in&amp;nbsp;this case I&amp;nbsp;don’t&amp;nbsp;think it’s&amp;nbsp;fair to&amp;nbsp;say that &lt;code&gt;perf&lt;/code&gt; helped. Actually, &lt;code&gt;perf&lt;/code&gt; gives a&amp;nbsp;lot of&amp;nbsp;confusion in&amp;nbsp;the interface. Look at&amp;nbsp;the picture above. What are these couple of&amp;nbsp;dozens lines with &amp;laquo;99.67%" tell us? Which of&amp;nbsp;these symbols cause latency? How to&amp;nbsp;interpret it? If&amp;nbsp;I&amp;nbsp;wasn’t&amp;nbsp;really attentive, like after couple of&amp;nbsp;hours of&amp;nbsp;debugging and investigating, I&amp;nbsp;couldn’t&amp;nbsp;be&amp;nbsp;able to&amp;nbsp;notice it. If&amp;nbsp;I&amp;nbsp;issued the magic &lt;code&gt;perf inject&lt;/code&gt; command it&amp;nbsp;will collapse &lt;code&gt;sched_stat_iowait&lt;/code&gt; command and I’ll&amp;nbsp;not see &lt;nobr&gt;dm-delay&lt;/nobr&gt; in&amp;nbsp;top records.&lt;/p&gt;
&lt;p&gt;Again, this is&amp;nbsp;all are very confusing and it’s&amp;nbsp;just a&amp;nbsp;fortune that I’ve&amp;nbsp;noticed it.&lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Perf is&amp;nbsp;really versatile and extremely complex tool with a&amp;nbsp;little documentation. On&amp;nbsp;some simple cases it&amp;nbsp;will help you a&amp;nbsp;LOT. But a&amp;nbsp;few steps from the mainstream problems and you are left alone with unintuitive data. We&amp;nbsp;all need various documentation on&amp;nbsp;perf&amp;nbsp;&amp;mdash; tutorials, books, slides, videos&amp;nbsp;&amp;mdash; that not only scratch the surface of&amp;nbsp;it&amp;nbsp;but gives a&amp;nbsp;comprehensive overview of&amp;nbsp;how it&amp;nbsp;works, what it&amp;nbsp;can do&amp;nbsp;and what it&amp;nbsp;doesn’t. I&amp;nbsp;hope I&amp;nbsp;have contributed to&amp;nbsp;that purpose with this article (it&amp;nbsp;took me&amp;nbsp;half a&amp;nbsp;year to&amp;nbsp;write it).&lt;/p&gt;
&lt;h2 id="references"&gt;References&lt;/h2&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;&lt;a href="https://perf.wiki.kernel.org/index.php/Tutorial"&gt;Perf tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://web.eece.maine.edu/~vweaver/projects/perf_events"&gt;Vince Weaver’s&amp;nbsp;perf page&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.brendangregg.com/perf.html"&gt;Beautiful Brendan Gregg’s&amp;nbsp;&amp;laquo;perf&amp;raquo; page&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content>
  </entry>
  <entry xml:base="http://alex.dzyoba.com/feed">
    <title type="text">When memory is not enough...</title>
    <id>programming/external-sort.html</id>
    <updated>2015-04-02T00:00:00Z</updated>
    <link href="programming/external-sort.html" />
    <author>
      <name>avd</name>
    </author>
    <content type="html">&lt;h2 id="intro"&gt;Intro&lt;/h2&gt;
&lt;p&gt;&lt;a href="/programming/restrict-memory.html"&gt;The last time&lt;/a&gt; I&amp;nbsp;was wondering on&amp;nbsp;how to&amp;nbsp;restrict program memory consumption. As&amp;nbsp;a&amp;nbsp;trophy from my&amp;nbsp;previous journey I’ve&amp;nbsp;got &lt;a href="https://github.com/dzeban/restrict-memory/blob/master/memrestrict.c"&gt;libmemrestrict&lt;/a&gt;&amp;nbsp;&amp;mdash; a&amp;nbsp;library that implements wrappers over allocation functions like &lt;code&gt;malloc&lt;/code&gt; to&amp;nbsp;account memory usage&amp;nbsp;&amp;mdash; and &lt;a href="https://github.com/dzeban/restrict-memory/blob/master/ptrace-restrict.c"&gt;&lt;nobr&gt;ptrace-restrict&lt;/nobr&gt;&lt;/a&gt;&amp;nbsp;&amp;mdash; &lt;nobr&gt;ptrace-based&lt;/nobr&gt; tool that intercepts &lt;code&gt;brk&lt;/code&gt;, &lt;code&gt;sbrk&lt;/code&gt; and &lt;code&gt;mmap&lt;/code&gt; system calls to&amp;nbsp;do&amp;nbsp;the same thing.&lt;/p&gt;
&lt;p&gt;But wait, why bother trying to&amp;nbsp;work in&amp;nbsp;memory restricted environment? Is&amp;nbsp;that really such a&amp;nbsp;common problem? Can you remember the last time when OOM killer shot your application? Do&amp;nbsp;you always think about memory consumption when you’re&amp;nbsp;programming. I&amp;nbsp;believe you don’t, because memory is&amp;nbsp;cheap and if&amp;nbsp;your application is&amp;nbsp;starving&amp;nbsp;&amp;mdash; just add a&amp;nbsp;few gigs of&amp;nbsp;RAM!&lt;/p&gt;
&lt;p&gt;However, you can’t&amp;nbsp;add more and more RAM infinitely and it’s&amp;nbsp;not because you don’t&amp;nbsp;have infinite amount of&amp;nbsp;memory. Today’s&amp;nbsp;software has to&amp;nbsp;deal with things like Big Data, where you just can’t&amp;nbsp;fit your input into array. You need to&amp;nbsp;distribute data between RAM, storage and network. You need an&amp;nbsp;algorithms or&amp;nbsp;at&amp;nbsp;least techniques to&amp;nbsp;handle data in&amp;nbsp;that way.&lt;/p&gt;
&lt;p&gt;So&amp;nbsp;here I&amp;nbsp;am, trying to&amp;nbsp;get my&amp;nbsp;hands dirty on&amp;nbsp;such problems, though in&amp;nbsp;somewhat trivial fashion, with popular question&amp;nbsp;&amp;mdash; how to&amp;nbsp;sort 1 million integers (4 MiB of&amp;nbsp;data) in&amp;nbsp;2 MiB of&amp;nbsp;RAM? This could be&amp;nbsp;generalized to&amp;nbsp;the problem of&amp;nbsp;sorting data that doesn’t&amp;nbsp;fit in&amp;nbsp;RAM and this is&amp;nbsp;what I&amp;nbsp;will try solve here.&lt;/p&gt;
&lt;h2 id="agenda"&gt;Agenda&lt;/h2&gt;
&lt;p&gt;We&amp;nbsp;need to&amp;nbsp;write a&amp;nbsp;program(s) that will sort an&amp;nbsp;integers from file. To&amp;nbsp;generate such type of&amp;nbsp;file I’ve&amp;nbsp;written simple utilities &lt;a href="https://github.com/dzeban/cs/blob/master/number/randints.c"&gt;randints&lt;/a&gt; and &lt;a href="https://github.com/dzeban/cs/blob/master/number/rangeints.c"&gt;rangeints&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Program should output sorted array on&amp;nbsp;stdout in&amp;nbsp;text format.&lt;/p&gt;
&lt;p&gt;Program should measure it’s&amp;nbsp;working time and output it&amp;nbsp;to&amp;nbsp;stderr&lt;a href="#fn1" class="footnoteRef" id="fnref1"&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Program should work with amount of&amp;nbsp;memory at&amp;nbsp;least two times smaller than file size (e.g. 2MiB of&amp;nbsp;RAM for 4MiB file). To&amp;nbsp;check this, we&amp;nbsp;will use &lt;code&gt;libmemrestrict&lt;/code&gt; or&amp;nbsp;&lt;code&gt;&lt;nobr&gt;ptrace-restrict&lt;/nobr&gt;&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Despite having such nice restriction tools, we&amp;nbsp;will not use them for some methods. For example, for &lt;code&gt;mmap&lt;/code&gt; it&amp;nbsp;will be&amp;nbsp;pointless&amp;nbsp;&amp;mdash; we&amp;nbsp;need to&amp;nbsp;restrict &lt;em&gt;physical&lt;/em&gt; RAM usage, &lt;em&gt;not virtual&lt;/em&gt; (see details in&amp;nbsp;&lt;a href="#mmap"&gt;corresponding section&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Programs will be&amp;nbsp;tested to&amp;nbsp;solve original problem (sort 4 MiB in&amp;nbsp;2 MiB). Also, I&amp;nbsp;will run it&amp;nbsp;in&amp;nbsp;virtual machine with 128 MiB of&amp;nbsp;RAM to&amp;nbsp;sort 500 MB&amp;nbsp;(125 millions of&amp;nbsp;4 bytes) of&amp;nbsp;integers.&lt;/p&gt;
&lt;h2 id="naive-way"&gt;Naive way&lt;/h2&gt;
&lt;p&gt;Let’s&amp;nbsp;try to&amp;nbsp;sort it&amp;nbsp;in&amp;nbsp;naive way to&amp;nbsp;get a&amp;nbsp;baseline and see how much RAM we&amp;nbsp;will use. &lt;a href="https://github.com/dzeban/cs/blob/master/sorting/external/naive.c"&gt;Here&lt;/a&gt; is&amp;nbsp;an&amp;nbsp;implementation that simply reads whole file into array of&amp;nbsp;integers and invokes &lt;code&gt;qsort&lt;/code&gt; on&amp;nbsp;it&amp;nbsp;(as&amp;nbsp;a&amp;nbsp;bonus you can find there a&amp;nbsp;simple dynamic array implementation via &lt;code&gt;realloc&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;We’ll&amp;nbsp;try to&amp;nbsp;sort 4MB of&amp;nbsp;data with this program. With no&amp;nbsp;restrictions it&amp;nbsp;works:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ./naive 4M.bin &amp;gt; /dev/null
4000000 bytes sorted in 0.323146 seconds&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;but it’s&amp;nbsp;not interesting. When we&amp;nbsp;try to&amp;nbsp;restrict it&amp;nbsp;in&amp;nbsp;2 MiB we’ll&amp;nbsp;get segmentation fault.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ LD_PRELOAD=./libmemrestrict.so ./naive ints &amp;gt; ints.sorted 
Segmentation fault&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, if&amp;nbsp;we&amp;nbsp;increase&lt;a href="#fn2" class="footnoteRef" id="fnref2"&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; limit to&amp;nbsp;4 MiB to&amp;nbsp;hold all the data we&amp;nbsp;will still fail.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ MR_THRESHOLD=5000000 LD_PRELOAD=./libmemrestrict.so ./naive ints &amp;gt; ints.sorted 
Segmentation fault&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Apparently, something is&amp;nbsp;trying to&amp;nbsp;get even more memory and, obviously, it’s&amp;nbsp;&lt;code&gt;qsort&lt;/code&gt;. Let’s&amp;nbsp;see how much memory it&amp;nbsp;wants with &lt;a href="/linux/profiling-valgrind.html#massif"&gt;help of&amp;nbsp;Valgrind’s&amp;nbsp;massif&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ valgrind --tool=massif ./naive ints 
$ ms_print massif.out.10676&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here is&amp;nbsp;a&amp;nbsp;nice picture:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    MB
    8.819^               :::::::::::::::::::::::::::#                         
     |                   :                          #                         
     |                   :                          #                         
     |                   :                          #                         
     |                   :                          #                         
     |                   :                          #                         
     |                   :                          #                         
     |                   :                          #                         
     |                   :                          #                         
     |            :::::::@                          #:::::::::::::::::::::::: 
     |            :      @                          #                         
     |            :      @                          #                         
     |            :      @                          #                         
     |            :      @                          #                         
     |            :      @                          #                         
     |      @@@@@@:      @                          #                         
     |      @     :      @                          #                         
     |      @     :      @                          #                         
     |   :::@     :      @                          #                         
     | :::  @     :      @                          #                         
       0 +-----------------------------------------------------------------------&amp;gt;Gi
     0                                                                   1.721&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You may see a&amp;nbsp;few doubling allocations up&amp;nbsp;to&amp;nbsp;4 MiB&amp;nbsp;&amp;mdash; that’s&amp;nbsp;my&amp;nbsp;dynamic array and then four more MiB for &lt;code&gt;qsort&lt;/code&gt;. Here are some stats:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--------------------------------------------------------------------------------
  n        time(i)         total(B)   useful-heap(B) extra-heap(B)    stacks(B)
--------------------------------------------------------------------------------
 21    173,222,581        5,247,504        4,000,568     1,246,936            0
 22    173,223,802        5,246,920        4,000,000     1,246,920            0
 23    173,226,655        5,247,504        4,000,568     1,246,936            0
 24    173,229,202        5,246,920        4,000,000     1,246,920            0
 25    173,229,311        9,246,928        8,000,000     1,246,928            0
 26    869,058,772        9,246,928        8,000,000     1,246,928            0
86.52% (8,000,000B) (heap allocation functions) malloc/new/new[], --alloc-fns, etc.
-&amp;gt;43.26% (4,000,000B) 0x400A26: readfile (in /home/avd/dev/cs/sorting/external/naive)
| -&amp;gt;43.26% (4,000,000B) 0x400ACD: main (in /home/avd/dev/cs/sorting/external/naive)
|   
-&amp;gt;43.26% (4,000,000B) 0x35D40383F7: qsort_r (in /usr/lib64/libc-2.18.so)
| -&amp;gt;43.26% (4,000,000B) 0x400B3D: main (in /home/avd/dev/cs/sorting/external/naive)
|   
-&amp;gt;00.00% (0B) in 1+ places, all below ms_print&amp;#39;s threshold (01.00%)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;4 million (useful) bytes used by&amp;nbsp;me&amp;nbsp;and 4 more million bytes is&amp;nbsp;used by&amp;nbsp;&lt;code&gt;qsort_r&lt;/code&gt;. There is&amp;nbsp;also 1.2 MB&amp;nbsp;&lt;nobr&gt;extra-heap&lt;/nobr&gt; used by&amp;nbsp;massif.&lt;/p&gt;
&lt;p&gt;Looks like in&amp;nbsp;this case &lt;code&gt;qsort&lt;/code&gt; behaves as&amp;nbsp;O(n) for space complexity.&lt;a href="#fn3" class="footnoteRef" id="fnref3"&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ok, is&amp;nbsp;it&amp;nbsp;able to&amp;nbsp;sort 500 MB&amp;nbsp;in&amp;nbsp;128 MiB of&amp;nbsp;RAM?&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ./naive 500M.bin &amp;gt; /dev/null
Segmentation fault&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Of&amp;nbsp;course, not. As&amp;nbsp;for performance:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ./naive 4M.bin &amp;gt; /dev/null
4000000 bytes sorted in 0.322712 seconds&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So, naive sorting works well when not restricted, fails when restricted and &lt;code&gt;qsort&lt;/code&gt; for some strange reason requires O(n) memory&lt;a href="#fn4" class="footnoteRef" id="fnref4"&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="mmap"&gt;mmap’ed&amp;nbsp;file&lt;/h2&gt;
&lt;p&gt;Using &lt;code&gt;mmap&lt;/code&gt; is&amp;nbsp;a&amp;nbsp;nice and hacky way to&amp;nbsp;sort large amount of&amp;nbsp;data in&amp;nbsp;small amount of&amp;nbsp;RAM. By&amp;nbsp;using &lt;code&gt;mmap&lt;/code&gt; you shift the burden of&amp;nbsp;balancing data between RAM and swap space to&amp;nbsp;the operating system kernel.&lt;/p&gt;
&lt;p&gt;This is&amp;nbsp;how it&amp;nbsp;works:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;You &lt;code&gt;mmap&lt;/code&gt; whole file with data into memory.&lt;/li&gt;
&lt;li&gt;From &lt;code&gt;mmap&lt;/code&gt; you get the pointer to&amp;nbsp;your data.&lt;/li&gt;
&lt;li&gt;You invoke sorting algorithm on&amp;nbsp;data under &lt;code&gt;mmap&lt;/code&gt;ed&amp;nbsp;pointer.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;And that’s&amp;nbsp;it! From now on&amp;nbsp;you won’t&amp;nbsp;exceed physical memory limits even though you are sorting file much larger than your RAM. To&amp;nbsp;understand why is&amp;nbsp;it&amp;nbsp;working, you need a&amp;nbsp;little knowledge about memory management in&amp;nbsp;operating systems.&lt;/p&gt;
&lt;p&gt;Every program represented by&amp;nbsp;a&amp;nbsp;process has its own private and isolated from other processes &lt;strong&gt;virtual&lt;/strong&gt; address space. Length of&amp;nbsp;address space is&amp;nbsp;bound by&amp;nbsp;CPU address bus width, e.g. for 32 bit CPU it’s&amp;nbsp;2&lt;sup&gt;32&lt;/sup&gt; which is&amp;nbsp;4 GiB.&lt;/p&gt;
&lt;p&gt;All allocations that happen in&amp;nbsp;process via &lt;code&gt;malloc&lt;/code&gt;, &lt;code&gt;new&lt;/code&gt; or&amp;nbsp;whatever else is&amp;nbsp;a&amp;nbsp;&lt;strong&gt;virtual&lt;/strong&gt; memory allocations. That allocated virtual memory are mapped to&amp;nbsp;physical memory by&amp;nbsp;kernel memory management subsystem. Usually this is&amp;nbsp;done in&amp;nbsp;lazy mode. It&amp;nbsp;means that whenever process asks for some amount of&amp;nbsp;memory kernel will satisfy this request immediately, but will &lt;strong&gt;not&lt;/strong&gt; do&amp;nbsp;actual allocation&amp;nbsp;&amp;mdash; in&amp;nbsp;this case we&amp;nbsp;say that virtual memory page is&amp;nbsp;&lt;strong&gt;not mapped&lt;/strong&gt; (to&amp;nbsp;physical page frame). Whenever such unmapped page is&amp;nbsp;accessed (for example it’s&amp;nbsp;written) &lt;a href="http://en.wikipedia.org/wiki/Memory_management_unit"&gt;MMU&lt;/a&gt; will generate the &amp;laquo;page fault&amp;raquo; exception that kernel will handle by&amp;nbsp;mapping virtual memory page to&amp;nbsp;a&amp;nbsp;physical page frame. From now on&amp;nbsp;page is&amp;nbsp;&lt;strong&gt;mapped&lt;/strong&gt; and writing by&amp;nbsp;virtual address within that page will be&amp;nbsp;translated by&amp;nbsp;MMU to&amp;nbsp;physical address in&amp;nbsp;RAM.&lt;/p&gt;
&lt;p&gt;On&amp;nbsp;the other hand, if&amp;nbsp;you remember that virtual address space is&amp;nbsp;bound only by&amp;nbsp;CPU address bus size, you might get into situation where program can allocate much more memory than available in&amp;nbsp;RAM. For example, your 32 bit system has only 256 MiB of&amp;nbsp;RAM, but process can allocate and use 1 GiB of&amp;nbsp;memory. In&amp;nbsp;this case, memory pages can’t&amp;nbsp;be&amp;nbsp;held in&amp;nbsp;RAM and going to&amp;nbsp;be&amp;nbsp;&lt;strong&gt;swapped&lt;/strong&gt;, i.e. evicted from RAM to&amp;nbsp;backing storage like hard drive. Whenever process requests that swapped page, kernel will fetch it&amp;nbsp;from disk and load into RAM (possibly by&amp;nbsp;replacing some other page).&lt;/p&gt;
&lt;p&gt;As&amp;nbsp;you can see kernel can do&amp;nbsp;a&amp;nbsp;pretty good job in&amp;nbsp;distributing data between RAM and disk, so&amp;nbsp;it’s&amp;nbsp;very natural to&amp;nbsp;exploit this facility in&amp;nbsp;our task. When we&amp;nbsp;do&amp;nbsp;&lt;code&gt;mmap&lt;/code&gt; of&amp;nbsp;our file, kernel will reserve range of&amp;nbsp;virtual addresses for our file that won’t&amp;nbsp;be&amp;nbsp;mapped. Whenever we&amp;nbsp;will try to&amp;nbsp;access them by&amp;nbsp;changing bytes, moving array pivot or&amp;nbsp;anything else, kernel will fetch data from input file on&amp;nbsp;disk into the RAM. Whenever we&amp;nbsp;will exhaust &lt;strong&gt;physical&lt;/strong&gt; memory, kernel will evict some pages to&amp;nbsp;swap space. That way we&amp;nbsp;will be&amp;nbsp;able to&amp;nbsp;balance our data between original file on&amp;nbsp;disk, RAM and swap space.&lt;/p&gt;
&lt;p&gt;The only restrictions in&amp;nbsp;that method is&amp;nbsp;virtual address space, which is&amp;nbsp;not much a&amp;nbsp;restriction (4 GiB for 32bit system and 256 TiB&lt;a href="#fn5" class="footnoteRef" id="fnref5"&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt; for 64 bit system), and swap space that can be&amp;nbsp;huge because hard drives are cheap today.&lt;/p&gt;
&lt;p&gt;Also, note that because &lt;code&gt;mmap&lt;/code&gt; load whole file into &lt;strong&gt;virtual&lt;/strong&gt; memory we&amp;nbsp;can’t&amp;nbsp;use &lt;code&gt;libmemrestrict&lt;/code&gt; or&amp;nbsp;&lt;code&gt;&lt;nobr&gt;ptrace-restrict&lt;/nobr&gt;&lt;/code&gt; because they account for virtual memory itself. If&amp;nbsp;we&amp;nbsp;try to&amp;nbsp;restrict sorting 100M of&amp;nbsp;data in&amp;nbsp;10M of&amp;nbsp;virtual memory, &lt;code&gt;mmap&lt;/code&gt; program will fail:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ qemu-x86_64 -R 10M ./mmaped 100M.bin 
mmap stack: Cannot allocate memory&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That’s&amp;nbsp;not a&amp;nbsp;surprise because &lt;code&gt;mmap&lt;/code&gt; loads whole file in&amp;nbsp;&lt;strong&gt;virtual memory&lt;/strong&gt; and then kernel distribute it&amp;nbsp;between actual physical memory and swap. So, we&amp;nbsp;need at&amp;nbsp;least 100M of&amp;nbsp;virtual memory (plus some extra space for &lt;code&gt;qemu&lt;/code&gt; itself) to&amp;nbsp;map file into memory.&lt;/p&gt;
&lt;p&gt;That’s&amp;nbsp;a&amp;nbsp;why for this sorting method I&amp;nbsp;will use virtual machine with 128 MiB of&amp;nbsp;memory. Here is&amp;nbsp;&lt;a href="https://github.com/dzeban/cs/blob/master/sorting/external/mmaped.c"&gt;my&amp;nbsp;mmap sorting program&lt;/a&gt;. And, you know what? It&amp;nbsp;works like a&amp;nbsp;charm!&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ free -m
             total       used       free     shared    buffers     cached
Mem:           119         42         76          0          4         16
-/+ buffers/cache:         21         97
Swap:          382          0        382

$ ll -h 500M.bin
-rw-r--r-- 1 root root 477M Feb  3 05:39 500M.bin

$ ./mmaped 500M.bin &amp;gt; /dev/null
500000000 bytes sorted in 32.250000 seconds&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here is&amp;nbsp;the &lt;code&gt;top&lt;/code&gt; info:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;PID  USER      PR  NI  VIRT  RES  SHR S  %CPU %MEM    TIME+  COMMAND
3167 root      20   0  480m  90m  90m R  84.6 76.4   1:18.65 mmaped &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As&amp;nbsp;you can see we&amp;nbsp;use 500 MB&amp;nbsp;of&amp;nbsp;&lt;strong&gt;virtual&lt;/strong&gt; memory&lt;a href="#fn6" class="footnoteRef" id="fnref6"&gt;&lt;sup&gt;6&lt;/sup&gt;&lt;/a&gt; while actual resident memory is&amp;nbsp;only 90 MiB.&lt;/p&gt;
&lt;p&gt;If&amp;nbsp;we&amp;nbsp;look at&amp;nbsp;more detailed &lt;code&gt;vmstat&lt;/code&gt; output while sorting 500 MB&amp;nbsp;we’ll&amp;nbsp;see how kernel is&amp;nbsp;balancing between swap, disk cache, buffers and free memory:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;procs -----------memory---------- ---swap-- -----io---- -system-- ----cpu----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa
 0  0      0  77776   2120  15104    1   27   710   971   24   34  3  1 95  1
 1  1      0   2060    488  90068    1   27   785  1057   25   37  3  1 95  1
 1  0    928   3400     60  89744    1   27   799  1092   25   38  3  1 94  1
 0  2   1908   1928    212  92040    1   27   852  1174   26   40  4  1 94  1
 0  2   3436   2360    280  93056    1   27   911  1282   28   42  4  1 94  2
 0  0   5272   3688    196  94688    1   27  1066  1471   31   48  4  1 93  2
 0  0   5272   3720    204  94700    1   27  1064  1469   31   48  4  1 93  2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In&amp;nbsp;the beginning we&amp;nbsp;had ~70 MiB of&amp;nbsp;free memory, empty swap and some memory allocated for I/O buffers and disk cache. Then, we&amp;nbsp;did a&amp;nbsp;&lt;code&gt;mmap&lt;/code&gt; and all that memory had gone to&amp;nbsp;disk cache. When the free memory were exhausted, kernel had started to&amp;nbsp;use swap space and we&amp;nbsp;can see it’s&amp;nbsp;increasing along with increasing I/O load. And we&amp;nbsp;end up&amp;nbsp;in&amp;nbsp;situation where almost all of&amp;nbsp;the memory is&amp;nbsp;dedicated to&amp;nbsp;disk cache, though it’s&amp;nbsp;OK&amp;nbsp;because disk cache pages are first victims to&amp;nbsp;steal from when we&amp;nbsp;need memory for application.&lt;/p&gt;
&lt;p&gt;So, sorting with help of&amp;nbsp;&lt;code&gt;mmap&lt;/code&gt; is&amp;nbsp;a&amp;nbsp;neat hack that requires simple understanding of&amp;nbsp;memory management, but gives you quick and easy solution to&amp;nbsp;handle large amount of&amp;nbsp;data in&amp;nbsp;small amount of&amp;nbsp;RAM.&lt;/p&gt;
&lt;h2 id="generic-external-sort"&gt;Generic external sort&lt;/h2&gt;
&lt;p&gt;All right, suppose you can’t&amp;nbsp;use &lt;code&gt;mmap&lt;/code&gt;, for example, you want to&amp;nbsp;sort 5 GiB file on&amp;nbsp;&lt;nobr&gt;32-bit&lt;/nobr&gt; system. What would you do?&lt;/p&gt;
&lt;p&gt;There is&amp;nbsp;a&amp;nbsp;&lt;nobr&gt;well-known&lt;/nobr&gt; and popular way to&amp;nbsp;accomplish this named &lt;em&gt;external merge sort&lt;/em&gt;. Motivation is&amp;nbsp;simple&amp;nbsp;&amp;mdash; if&amp;nbsp;you don’t&amp;nbsp;have enough memory to&amp;nbsp;hold your data you just use some external storage like hard disk. Of&amp;nbsp;course, you have to&amp;nbsp;work with your data in&amp;nbsp;piece by&amp;nbsp;piece fashion because you still have only small amount of&amp;nbsp;main memory.&lt;/p&gt;
&lt;p&gt;External merge sort works like this:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;You split your data to&amp;nbsp;chunks of&amp;nbsp;available memory buffer size.&lt;/li&gt;
&lt;li&gt;Each chunk is&amp;nbsp;sorted in&amp;nbsp;memory buffer and written to&amp;nbsp;external storage.&lt;/li&gt;
&lt;li&gt;Now you have &lt;code&gt;filesize/buffersize&lt;/code&gt; chunks on&amp;nbsp;your storage.&lt;/li&gt;
&lt;li&gt;Finally, you read &lt;code&gt;buffersize/#chunks&lt;/code&gt; pieces from each chunk to&amp;nbsp;merge them in&amp;nbsp;buffer and output to&amp;nbsp;result file.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I&amp;nbsp;made some &lt;a href="https://github.com/dzeban/cs/blob/master/sorting/external/external-merge.c"&gt;trivial, absolutely-not-optimized-&lt;nobr&gt;in-any-sense&lt;/nobr&gt; implementation&lt;/a&gt; that simply works:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ LD_PRELOAD=./libmemrestrict.so ./external-merge 4M.bin 1048576 &amp;gt; /dev/null
4194304 bytes sorted in 0.383171 seconds&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’ve&amp;nbsp;sorted in&amp;nbsp;2 MiB of&amp;nbsp;memory using 1 MiB buffer.&lt;/p&gt;
&lt;p&gt;Now let’s&amp;nbsp;sort 500MB. First, disable swap&amp;nbsp;&amp;mdash; we’re&amp;nbsp;handling chunks swapping by&amp;nbsp;hand:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ swapoff /dev/vda5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Drop caches:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ echo 3 &amp;gt; /proc/sys/vm/drop_caches&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Check free memory:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ free -m
             total       used       free     shared    buffers     cached
Mem:           119         28         90          0          0          6
-/+ buffers/cache:         21         97
Swap:            0          0          0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’ll&amp;nbsp;use 50M as&amp;nbsp;a&amp;nbsp;buffer&amp;nbsp;&amp;mdash; 10 times smaller than file size.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ./external-merge 500M.bin 50000000 &amp;gt; /dev/null
500000000 bytes sorted in 120.115180 seconds&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Holy crap, two minutes! Why is&amp;nbsp;that? Well, the main killer of&amp;nbsp;performance here is&amp;nbsp;I/O. There are 3 things that cause lots of&amp;nbsp;I/O and slow things down. On&amp;nbsp;the split phase we’re&amp;nbsp;sequentially reading file slipping it&amp;nbsp;through a&amp;nbsp;small buffer. On&amp;nbsp;the merge phase we’re&amp;nbsp;constantly opening and closing chunk files. And last but not least is&amp;nbsp;output&amp;nbsp;&amp;mdash; on&amp;nbsp;merge phase we&amp;nbsp;output whole buffer (50 MB, 12.5 millions of&amp;nbsp;integer) to&amp;nbsp;stdout that, despite redirecting it&amp;nbsp;to&amp;nbsp;&lt;code&gt;/dev/null&lt;/code&gt;, creating a&amp;nbsp;heavy load. We&amp;nbsp;may turn it&amp;nbsp;off. All in&amp;nbsp;all, in&amp;nbsp;&lt;code&gt;mmaped&lt;/code&gt; we&amp;nbsp;output everything in&amp;nbsp;a&amp;nbsp;single pass in&amp;nbsp;the end of&amp;nbsp;program and doesn’t&amp;nbsp;account it&amp;nbsp;in&amp;nbsp;performance counters. So&amp;nbsp;if&amp;nbsp;we&amp;nbsp;turn off output &lt;strong&gt;we’ll&amp;nbsp;run in&amp;nbsp;~90 seconds&amp;nbsp;&amp;mdash; 25% faster&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ./external-merge-no-output 500M.bin 50000000 &amp;gt; /dev/null
500000000 bytes sorted in 87.140000 seconds&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As&amp;nbsp;for memory consumption&amp;nbsp;&amp;mdash; it’s&amp;nbsp;fine. If&amp;nbsp;we&amp;nbsp;try to&amp;nbsp;run it&amp;nbsp;under &lt;em&gt;massif&lt;/em&gt; we’ll&amp;nbsp;see that peak consumption is&amp;nbsp;our buffer size plus some extra heap.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--------------------------------------------------------------------------------
Command:            ./external-merge 500M.bin 50000000
Massif arguments:   (none)
ms_print arguments: massif.out.17423
--------------------------------------------------------------------------------


    MB
47.75^                                                                  ::::: 
     |#::::::@:::::::::::@:::::::::@:::@::::@::::@::::::::@::::@::::@:::@     
     |# : :  @ :  : :  : @  : :    @   @    @    @   :    @    @    @   @     
     |# : :  @ :  : :  : @  : :    @   @    @    @   :    @    @    @   @     
     |# : :  @ :  : :  : @  : :    @   @    @    @   :    @    @    @   @     
     |# : :  @ :  : :  : @  : :    @   @    @    @   :    @    @    @   @     
     |# : :  @ :  : :  : @  : :    @   @    @    @   :    @    @    @   @     
     |# : :  @ :  : :  : @  : :    @   @    @    @   :    @    @    @   @     
     |# : :  @ :  : :  : @  : :    @   @    @    @   :    @    @    @   @     
     |# : :  @ :  : :  : @  : :    @   @    @    @   :    @    @    @   @     
     |# : :  @ :  : :  : @  : :    @   @    @    @   :    @    @    @   @     
     |# : :  @ :  : :  : @  : :    @   @    @    @   :    @    @    @   @     
     |# : :  @ :  : :  : @  : :    @   @    @    @   :    @    @    @   @     
     |# : :  @ :  : :  : @  : :    @   @    @    @   :    @    @    @   @     
     |# : :  @ :  : :  : @  : :    @   @    @    @   :    @    @    @   @     
     |# : :  @ :  : :  : @  : :    @   @    @    @   :    @    @    @   @     
     |# : :  @ :  : :  : @  : :    @   @    @    @   :    @    @    @   @     
     |# : :  @ :  : :  : @  : :    @   @    @    @   :    @    @    @   @     
     |# : :  @ :  : :  : @  : :    @   @    @    @   :    @    @    @   @     
     |# : :  @ :  : :  : @  : :    @   @    @    @   :    @    @    @   @     
   0 +-----------------------------------------------------------------------&amp;gt;Gi
     0                                                                   332.5

Number of snapshots: 98
 Detailed snapshots: [4 (peak), 10, 20, 29, 32, 35, 38, 45, 48, 54, 64, 74, 84, 94]

--------------------------------------------------------------------------------
  n        time(i)         total(B)   useful-heap(B) extra-heap(B)    stacks(B)
--------------------------------------------------------------------------------
  0              0                0                0             0            0
  1        119,690              584              568            16            0
  2        123,141       50,004,496       50,000,568         3,928            0
  3      4,814,014       50,005,080       50,001,136         3,944            0
  4      4,817,234       50,005,080       50,001,136         3,944            0
99.99% (50,001,136B) (heap allocation functions) malloc/new/new[], --alloc-fns, etc.
-&amp;gt;99.99% (50,000,000B) 0x400FA2: external_merge_sort (in /root/external-merge)
| -&amp;gt;99.99% (50,000,000B) 0x40128E: main (in /root/external-merge)
|   
-&amp;gt;00.00% (1,136B) in 1+ places, all below ms_print&amp;#39;s threshold (01.00%)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If&amp;nbsp;we&amp;nbsp;restrict memory to&amp;nbsp;50 MB&lt;a href="#fn7" class="footnoteRef" id="fnref7"&gt;&lt;sup&gt;7&lt;/sup&gt;&lt;/a&gt; we’ll&amp;nbsp;see that it&amp;nbsp;works:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ LD_PRELOAD=./libmemrestrict.so MR_THRESHOLD=51000000 ./external-merge 500M.bin 50000000 &amp;gt; /dev/null
500000000 bytes sorted in 87.900000 seconds&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ok, memory consumption is&amp;nbsp;fine, but performance is&amp;nbsp;not that good. Recall that &lt;code&gt;mmaped&lt;/code&gt; has done this in&amp;nbsp;32 seconds. Let’s&amp;nbsp;see how we&amp;nbsp;can improve our 90 seconds.&lt;/p&gt;
&lt;p&gt;Lets profile this nice program with gprof. Build instrumented binary&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ gcc -pg -g -Wall -Wextra external-merge.c -o external-merge-gprof&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And invoke this program multiple times accumulating statistics. To&amp;nbsp;do&amp;nbsp;so&amp;nbsp;we’ll&amp;nbsp;use nice script from my&amp;nbsp;&lt;a href="/linux/profiling-gprof-gcov.html"&gt;article on&amp;nbsp;gprof&lt;/a&gt;. Here is&amp;nbsp;the output:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;%   cumulative   self              self     total           
time   seconds   seconds    calls  Ts/call  Ts/call  name    
81.98    432.87   432.87                             compar
18.17    528.82    95.95                             print_arr
0.00    528.82     0.00     1100     0.00     0.00  form_filename
0.00    528.82     0.00      100     0.00     0.00  merge
0.00    528.82     0.00      100     0.00     0.00  save_buf
0.00    528.82     0.00       10     0.00     0.00  external_merge_sort
0.00    528.82     0.00       10     0.00     0.00  split&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Most of&amp;nbsp;the time we&amp;nbsp;have spent in&amp;nbsp;sorting and printing. But also don’t&amp;nbsp;forget that gprof won’t&amp;nbsp;show you time spent in&amp;nbsp;syscalls and I/O.&lt;/p&gt;
&lt;p&gt;I&amp;nbsp;can think of&amp;nbsp;2 things to&amp;nbsp;improve here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tune external sorting with multithreading and I/O tricks&lt;/li&gt;
&lt;li&gt;Think about different sorting algorithm&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, generic external merge sort is&amp;nbsp;quite simple idea to&amp;nbsp;sort a&amp;nbsp;bunch of&amp;nbsp;data in&amp;nbsp;small RAM, but usually without tuning and improving it’s&amp;nbsp;slow.&lt;/p&gt;
&lt;h2 id="tuning-external-sort"&gt;Tuning external sort&lt;/h2&gt;
&lt;p&gt;One of&amp;nbsp;the things that we&amp;nbsp;can try is&amp;nbsp;to&amp;nbsp;use multiple threads on&amp;nbsp;split and merge phases of&amp;nbsp;our external sort. However, in&amp;nbsp;this case, it’s&amp;nbsp;not a&amp;nbsp;really great idea.&lt;/p&gt;
&lt;p&gt;Using multithreading on&amp;nbsp;split phase doesn’t&amp;nbsp;make sense because there is&amp;nbsp;a&amp;nbsp;single buffer that can hold the data. But we&amp;nbsp;may try to&amp;nbsp;advise kernel on&amp;nbsp;how we’ll&amp;nbsp;read data. There are 2 functions for that:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;&lt;code&gt;readahead&lt;/code&gt;, though it’s&amp;nbsp;Linux specific.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;posix_fadvise&lt;/code&gt; with &lt;code&gt;POSIX_FADV_SEQUENTIAL&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;These functions will inform memory management subsystem on&amp;nbsp;how we’ll&amp;nbsp;read the data. In&amp;nbsp;our case we&amp;nbsp;read it&amp;nbsp;sequentially and thus it&amp;nbsp;would be&amp;nbsp;nice to&amp;nbsp;see file content in&amp;nbsp;page cache.&lt;/p&gt;
&lt;p&gt;On&amp;nbsp;a&amp;nbsp;merge phase we&amp;nbsp;could avoid constant &lt;code&gt;open&lt;/code&gt;/&lt;code&gt;close&lt;/code&gt; of&amp;nbsp;chunk files by&amp;nbsp;creating dedicated thread for each of&amp;nbsp;the chunks. Each thread will keep its file open, and will fill buffer at&amp;nbsp;thread offset. When buffer is&amp;nbsp;filled it&amp;nbsp;will be&amp;nbsp;sorted&lt;a href="#fn8" class="footnoteRef" id="fnref8"&gt;&lt;sup&gt;8&lt;/sup&gt;&lt;/a&gt; and output. Also, we&amp;nbsp;will employ &lt;code&gt;readahead&lt;/code&gt; for each thread.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/dzeban/cs/blob/master/sorting/external/mt-external-merge.c"&gt;Here&lt;/a&gt; is&amp;nbsp;tuned and multithreaded version of&amp;nbsp;external merge sort.&lt;/p&gt;
&lt;p&gt;OK, so&amp;nbsp;as&amp;nbsp;I&amp;nbsp;said, multithreading here is&amp;nbsp;not a&amp;nbsp;great idea. All these threads things are nice and dandy, but for single core CPU it’s&amp;nbsp;not showing any effect:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ./mt-ext-merge 500M.bin 50000000 &amp;gt; /dev/null
500000000 bytes sorted in 117.380000 seconds&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It&amp;nbsp;is&amp;nbsp;the version with printing. And here is&amp;nbsp;the version without printing:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ./mt-ext-merge-no-output 500M.bin 50000000 &amp;gt; /dev/null
500000000 bytes sorted in 91.040000 seconds&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You may think that it’s&amp;nbsp;because we&amp;nbsp;have hard times scheduling dozen of&amp;nbsp;threads on&amp;nbsp;a&amp;nbsp;single CPU. Allright, lets compare it&amp;nbsp;with other methods on&amp;nbsp;&lt;nobr&gt;quad-core&lt;/nobr&gt; machine (Intel Core &lt;nobr&gt;i7-3612QM&lt;/nobr&gt; CPU @ 2.10GHz):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ./naive 500M.bin &amp;gt; /dev/null 
500000000 bytes sorted in 23.040499 seconds

$ ./mmaped 500M.bin &amp;gt; /dev/null
500000000 bytes sorted in 23.542076 seconds

$ ./external-merge 500M.bin 50000000 &amp;gt; /dev/null 
500000000 bytes sorted in 39.228695 seconds

$ ./mt-external-merge 500M.bin 50000000 &amp;gt; /dev/null 
500000000 bytes sorted in 41.062793 seconds

$ ./external-merge-no-output 500M.bin 50000000 &amp;gt; /dev/null
500000000 bytes sorted in 28.893745 seconds

$ ./mt-external-merge-no-output 500M.bin 50000000 &amp;gt; /dev/null
500000000 bytes sorted in 28.368976 seconds&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now with a&amp;nbsp;100 chunks (100 threads):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ./external-merge-no-output 500M.bin 5000000 &amp;gt; /dev/null
500000000 bytes sorted in 27.107728 seconds

$ ./mt-external-merge-no-output 500M.bin 5000000 &amp;gt; /dev/null
500000000 bytes sorted in 28.558468 seconds&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can see no&amp;nbsp;changes in&amp;nbsp;performance between &lt;code&gt;&lt;nobr&gt;external-merge&lt;/nobr&gt;&lt;/code&gt; and &lt;code&gt;&lt;nobr&gt;mt-external-merge&lt;/nobr&gt;&lt;/code&gt;. Why is&amp;nbsp;that? Because &lt;strong&gt;for most cases multithreading is&amp;nbsp;not a&amp;nbsp;solution for &lt;span style="text-decoration:underline"&gt;I/O bound&lt;/span&gt; applications&lt;/strong&gt;. Still, there are situations when spawning some threads will speed up&amp;nbsp;things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Your execution threads are independent&lt;/li&gt;
&lt;li&gt;Your I/O resource can work in&amp;nbsp;parallel, e.g. it’s&amp;nbsp;RAID&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Examples here are some graphic application that renders image in&amp;nbsp;independent areas, or&amp;nbsp;scientific application that makes some heavy calculations for multiple results.&lt;/p&gt;
&lt;p&gt;In&amp;nbsp;multithreaded external sort threads are dependant&amp;nbsp;&amp;mdash; you have to&amp;nbsp;wait for main thread to&amp;nbsp;sort buffer before you can do&amp;nbsp;further reading from the chunk. Also, reading for slice is&amp;nbsp;done much faster that sorting whole buffer, so&amp;nbsp;most of&amp;nbsp;the time threads are waiting for main thread to&amp;nbsp;finish.&lt;/p&gt;
&lt;p&gt;That’s&amp;nbsp;why multithreading won’t&amp;nbsp;help us, so&amp;nbsp;we&amp;nbsp;need to&amp;nbsp;look for other ways to&amp;nbsp;improve.&lt;/p&gt;
&lt;h2 id="special-sorting-algorithms"&gt;Special sorting algorithms&lt;/h2&gt;
&lt;p&gt;Now, let’s&amp;nbsp;try to&amp;nbsp;use some sorting algorithm that would perform better than QuickSort assuming we&amp;nbsp;know distribution of&amp;nbsp;data. Like we&amp;nbsp;know that we’re&amp;nbsp;sorting integers, so&amp;nbsp;why not play around this? There are few sorting algorithms designed specifically for special type of&amp;nbsp;data can fall in&amp;nbsp;either of&amp;nbsp;2 groups:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;Don’t&amp;nbsp;use compares.&lt;/li&gt;
&lt;li&gt;Don’t&amp;nbsp;even require to&amp;nbsp;load input array in&amp;nbsp;memory.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Such algorithms are known to&amp;nbsp;work better than O(n&amp;nbsp;log(n))&amp;nbsp;&amp;mdash; a&amp;nbsp;lower bound for comparison based sort like QuickSort. Of&amp;nbsp;course, not every algorithm will work for us&amp;nbsp;because we&amp;nbsp;have memory restriction. For example, radix sort and other kinds of&amp;nbsp;bucket sorting won’t&amp;nbsp;help us&amp;nbsp;because it&amp;nbsp;requires additional memory for buckets, though there are implementations of&amp;nbsp;&lt;a href="http://www.drdobbs.com/architecture-and-design/algorithm-improvement-through-performanc/220300654"&gt;&lt;nobr&gt;in-place&lt;/nobr&gt; Radix sort&lt;/a&gt;. Anyway, such implementations require reading whole data set multiple times for each radix&amp;nbsp;&amp;mdash; 32 times for &lt;nobr&gt;binary-radix&lt;/nobr&gt; sort and that’s&amp;nbsp;way too much. Also, deep recursion that arise from MSD radix sort is&amp;nbsp;a&amp;nbsp;memory consumption itself. That’s&amp;nbsp;why I&amp;nbsp;came up&amp;nbsp;to&amp;nbsp;using counting sort.&lt;/p&gt;
&lt;h2 id="counting-sort"&gt;Counting sort&lt;/h2&gt;
&lt;p&gt;If&amp;nbsp;we&amp;nbsp;know that our data are big, but it’s&amp;nbsp;range is&amp;nbsp;small, then we&amp;nbsp;can use counting sort. The idea is&amp;nbsp;dead simple&amp;nbsp;&amp;mdash; instead of&amp;nbsp;holding data in&amp;nbsp;memory we&amp;nbsp;will hold array of&amp;nbsp;counters. We’ll&amp;nbsp;read our data sequentially and then increment relevant counter. The most important is&amp;nbsp;that counting sort time complexity is&amp;nbsp;&lt;strong&gt;linear&lt;/strong&gt; and space complexity is&amp;nbsp;proportional to&amp;nbsp;range that is&amp;nbsp;usually small.&lt;/p&gt;
&lt;p&gt;A&amp;nbsp;simple implementation works with consecutive range of&amp;nbsp;integers from 0 to&amp;nbsp;some &lt;code&gt;N&lt;/code&gt;. There is&amp;nbsp;an&amp;nbsp;array size of&amp;nbsp;range, where integers correspond to&amp;nbsp;array indices. Here is&amp;nbsp;my&amp;nbsp;implementation &lt;a href="https://github.com/dzeban/cs/blob/master/sorting/counting-array.c"&gt;on&amp;nbsp;github&lt;/a&gt; performing really well without any tuning&lt;a href="#fn9" class="footnoteRef" id="fnref9"&gt;&lt;sup&gt;9&lt;/sup&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ./counting-array 500M-range.bin 1000000 &amp;gt; /dev/null
Range is 1000000
500000000 bytes sorted in 3.240000 seconds&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Yep, half gig of&amp;nbsp;data sorted in&amp;nbsp;3 and a&amp;nbsp;half seconds on&amp;nbsp;128 MiB machine with single CPU. Compare it&amp;nbsp;with &lt;code&gt;qsort&lt;/code&gt; on&amp;nbsp;&lt;code&gt;mmap&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ./mmaped 500M-range.bin &amp;gt; /dev/null
500000000 bytes sorted in 76.150000 seconds&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;23 times faster!&lt;/p&gt;
&lt;p&gt;But anyway you should be&amp;nbsp;aware of&amp;nbsp;restrictions that counting sort implies: only integers (or&amp;nbsp;equivalent) from small and consecutive range. I’ve&amp;nbsp;also tried to&amp;nbsp;develop counting sort for &lt;nobr&gt;non-consecutive&lt;/nobr&gt; range with hash tables and binary search trees&amp;nbsp;&amp;mdash; &lt;a href="https://github.com/dzeban/cs/blob/master/sorting/counting.c"&gt;here is&amp;nbsp;the code&lt;/a&gt;. However, its performance is&amp;nbsp;pretty bad and, unfortunately, I&amp;nbsp;still can’t&amp;nbsp;explain this.&lt;/p&gt;
&lt;p&gt;Anyway, we&amp;nbsp;can go&amp;nbsp;even further and assume that numbers in&amp;nbsp;our range is&amp;nbsp;unique. Then, counter for value might be&amp;nbsp;only in&amp;nbsp;2 states&amp;nbsp;&amp;mdash; present or&amp;nbsp;not, so&amp;nbsp;we&amp;nbsp;could use a&amp;nbsp;single bit for counter. This will enormously compact our array, although in&amp;nbsp;that case we&amp;nbsp;don’t&amp;nbsp;even need any array. We&amp;nbsp;could store each number as&amp;nbsp;a&amp;nbsp;single bit, thus transforming our data into a&amp;nbsp;bit vector&amp;nbsp;&amp;mdash; while reading a&amp;nbsp;file, set Nth bit if&amp;nbsp;there is&amp;nbsp;an&amp;nbsp;integer N&amp;nbsp;in&amp;nbsp;file. After bit vector is&amp;nbsp;formed, read it&amp;nbsp;and write to&amp;nbsp;output file numbers that correspond to&amp;nbsp;bits that are set.&lt;/p&gt;
&lt;p&gt;Bit vector solution requires even more attention because, despite its seem compactness, you might violate your restrictions, for example to&amp;nbsp;sort array of&amp;nbsp;numbers from whole integers range (2&lt;sup&gt;32&lt;/sup&gt;) you would need a&amp;nbsp;1 bit for every integer, which is&amp;nbsp;4294967296 bits = 536870912 bytes = 512 MiB. In&amp;nbsp;my&amp;nbsp;case I&amp;nbsp;have only 128 MiB, so&amp;nbsp;it&amp;nbsp;won’t&amp;nbsp;work for me. But there are cases where you &lt;em&gt;will&lt;/em&gt; benefit like a&amp;nbsp;boss&amp;nbsp;&amp;mdash; read &lt;a href="http://www.cs.bell-labs.com/cm/cs/pearls/cto.html"&gt;a&amp;nbsp;great story from &amp;laquo;Programming Pearls&amp;raquo; by&amp;nbsp;Jon Bentley&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;A&amp;nbsp;moral here is&amp;nbsp;&amp;laquo;knowing your data is&amp;nbsp;extremely useful&amp;raquo;.&lt;/p&gt;
&lt;h2 id="recap"&gt;Recap&lt;/h2&gt;
&lt;p&gt;For the last 5 months of&amp;nbsp;writing this article I&amp;nbsp;did a&amp;nbsp;lot of&amp;nbsp;things&amp;nbsp;&amp;mdash; I’ve&amp;nbsp;implemented a&amp;nbsp;dozen of&amp;nbsp;programs, come up&amp;nbsp;with a&amp;nbsp;few good ideas, failed with many more and still I&amp;nbsp;have things to&amp;nbsp;try and/or fix. Now it’s&amp;nbsp;time for conclusions.&lt;/p&gt;
&lt;p&gt;The simple problem of&amp;nbsp;sorting data in&amp;nbsp;small memory revealed a&amp;nbsp;whole class of&amp;nbsp;peculiarities we&amp;nbsp;don’t&amp;nbsp;usually think of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Common widely used algorithms are not suitable for any problems.&lt;/li&gt;
&lt;li&gt;Dynamic debugging and profiling are extremely useful and demonstrative.&lt;/li&gt;
&lt;li&gt;I/O is&amp;nbsp;a&amp;nbsp;bitch, unless you fully rely on&amp;nbsp;kernel.&lt;/li&gt;
&lt;li&gt;Multithreading is&amp;nbsp;not a&amp;nbsp;silver bullet for performance.&lt;/li&gt;
&lt;li&gt;Know your data, know your environment.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As&amp;nbsp;for sorting here is&amp;nbsp;a&amp;nbsp;result table:&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col width="14%" /&gt;
&lt;col width="14%" /&gt;
&lt;col width="14%" /&gt;
&lt;col width="16%" /&gt;
&lt;col width="28%" /&gt;
&lt;col width="10%" /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class="header"&gt;
&lt;th align="left"&gt;Test case&lt;/th&gt;
&lt;th align="left"&gt;Naive QuickSort&lt;/th&gt;
&lt;th align="left"&gt;mmap and QuickSort&lt;/th&gt;
&lt;th align="left"&gt;External merge sort&lt;/th&gt;
&lt;th align="left"&gt;Multithreaded external merge sort&lt;/th&gt;
&lt;th align="left"&gt;Counting sort&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class="odd"&gt;
&lt;td align="left"&gt;4 MiB in&amp;nbsp;2 MiB&lt;/td&gt;
&lt;td align="left"&gt;Segfault&lt;/td&gt;
&lt;td align="left"&gt;N/A&lt;/td&gt;
&lt;td align="left"&gt;0.38s&lt;/td&gt;
&lt;td align="left"&gt;0.41s&lt;/td&gt;
&lt;td align="left"&gt;0.01&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class="even"&gt;
&lt;td align="left"&gt;500 MB&amp;nbsp;in&amp;nbsp;128 MiB&lt;/td&gt;
&lt;td align="left"&gt;Segfault&lt;/td&gt;
&lt;td align="left"&gt;32.25s&lt;/td&gt;
&lt;td align="left"&gt;87.14s&lt;/td&gt;
&lt;td align="left"&gt;91.04&lt;/td&gt;
&lt;td align="left"&gt;3.24&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The bottom line is&amp;nbsp;&lt;strong&gt;&amp;laquo;Know your data and develop a&amp;nbsp;simple algorithm for it&amp;raquo;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Thank you for your attention.&lt;/p&gt;
&lt;h2 id="references"&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="http://neopythonic.blogspot.ru/2008/10/sorting-million-32-bit-integers-in-2mb.html"&gt;Sorting a&amp;nbsp;million &lt;nobr&gt;32-bit&lt;/nobr&gt; integers in&amp;nbsp;2MB of&amp;nbsp;RAM using Python&lt;/a&gt;&amp;nbsp;&amp;mdash; simple external sort in&amp;nbsp;pythonic way with generators, &lt;code&gt;array&lt;/code&gt; module and &lt;code&gt;heapq&lt;/code&gt;. Also, has nice explanation of&amp;nbsp;buffering advantages.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="http://www.umbrant.com/blog/2011/external_sorting.html"&gt;External sorting of&amp;nbsp;large datasets&lt;/a&gt;&amp;nbsp;&amp;mdash; External sort implementation by&amp;nbsp;Andrew Wang with performance measurements.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="http://www.reddit.com/r/programming/comments/grrrr/efficiently_sorting_datasets_bigger_than_memory_c/"&gt;Efficiently sorting datasets bigger than memory&lt;/a&gt;&amp;nbsp;&amp;mdash; Nice reddit thread regarding Andrew Wang’s&amp;nbsp;article showing some different methods along with pros and cons.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="http://www.cs.bell-labs.com/cm/cs/pearls/cto.html"&gt;Cracking the Oyster (Column 1 of&amp;nbsp;Programming Pearls)&lt;/a&gt;&amp;nbsp;&amp;mdash; Amazingly written story on&amp;nbsp;doing large sorting. Discussed the bit vector idea in&amp;nbsp;great details.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="http://www.drdobbs.com/parallel/multithreaded-file-io/220300055"&gt;Multithreaded File I/O&lt;/a&gt;&amp;nbsp;&amp;mdash; How multithreaded I/O behaves on&amp;nbsp;single disk and RAID5 array.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="http://www.drdobbs.com/architecture-and-design/algorithm-improvement-through-performanc/220300654"&gt;Algorithm Improvement through Performance Measurement: Part 2&lt;/a&gt; presents &lt;nobr&gt;in-place&lt;/nobr&gt; radix sort implementation.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="http://stackoverflow.com/questions/3969813/which-parallel-sorting-algorithm-has-the-best-average-case-performance"&gt;Parallel sorting algorithms&lt;/a&gt;&amp;nbsp;&amp;mdash; comprehensive list of&amp;nbsp;resources regarding sorting on&amp;nbsp;multinode computer systems.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="footnotes"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn1"&gt;&lt;p&gt;We&amp;nbsp;can’t&amp;nbsp;simply launch program under &lt;code&gt;time&lt;/code&gt; utility because it&amp;nbsp;will include time for reading file into memory and time for outputting to&amp;nbsp;console.&lt;a href="#fnref1"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn2"&gt;&lt;p&gt;libmemrestrict gets a&amp;nbsp;configuration from environment. Common practice for libraries, for example &lt;code&gt;LD_PRELOAD&lt;/code&gt; and &lt;code&gt;LD_LIBRARY_PATH&lt;/code&gt; are &lt;nobr&gt;well-known&lt;/nobr&gt; environment variables for &lt;nobr&gt;ld-linux&lt;/nobr&gt;.so, and there is&amp;nbsp;also less known, but extremely useful &lt;code&gt;LD_DEBUG&lt;/code&gt; environment variable for &lt;a href="http://www.bnikolic.co.uk/blog/linux-ld-debug.html"&gt;linkage debugging&lt;/a&gt;.&lt;a href="#fnref2"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn3"&gt;&lt;p&gt;It’s&amp;nbsp;strange because qsort is&amp;nbsp;&lt;nobr&gt;in-place&lt;/nobr&gt; and uses optimizations suggested by&amp;nbsp;Robert Sedgewick to, among others, guarantee O(log n) space complexity. You can dive into &lt;a href="https://sourceware.org/git/?p=glibc.git;a=blob;f=stdlib/qsort.c;h=04c25b984f74a8f738233cc6da8a738b6437833c;hb=b8079dd0d360648e4e8de48656c5c38972621072"&gt;glibc qsort implementation.&lt;/a&gt;&lt;a href="#fnref3"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn4"&gt;&lt;p&gt;There is&amp;nbsp;a&amp;nbsp;strange behaviour though. For example, if&amp;nbsp;I&amp;nbsp;restrict memory for 5.3 MB&amp;nbsp;it&amp;nbsp;will work and &lt;em&gt;not&lt;/em&gt; require O(n) memory. I’m&amp;nbsp;still investigating on&amp;nbsp;this.&lt;a href="#fnref4"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn5"&gt;&lt;p&gt;&lt;a href="http://en.wikipedia.org/wiki/X86-64#Virtual_address_space_details" class="uri"&gt;http://en.wikipedia.org/wiki/&lt;nobr&gt;X86-64&lt;/nobr&gt;#Virtual_address_space_details&lt;/a&gt;&lt;a href="#fnref5"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn6"&gt;&lt;p&gt;Note that &lt;strong&gt;MiB&lt;/strong&gt; is&amp;nbsp;2&lt;sup&gt;20&lt;/sup&gt; and &lt;strong&gt;MB&lt;/strong&gt; is&amp;nbsp;10&lt;sup&gt;6&lt;/sup&gt; = 1 million. So&amp;nbsp;500 MB&amp;nbsp;= 500&amp;nbsp;000&amp;nbsp;000 bytes which is&amp;nbsp;500&amp;nbsp;000&amp;nbsp;000 &amp;gt;&amp;gt; 20 = 476 MiB.&lt;a href="#fnref6"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn7"&gt;&lt;p&gt;Plus extra 500 KB&amp;nbsp;for temporary strings holding chunks paths.&lt;a href="#fnref7"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn8"&gt;&lt;p&gt;In&amp;nbsp;this way it’s&amp;nbsp;kind of&amp;nbsp;&lt;nobr&gt;N-way&lt;/nobr&gt; merge.&lt;a href="#fnref8"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn9"&gt;&lt;p&gt;Second argument is&amp;nbsp;a&amp;nbsp;buffer size in&amp;nbsp;elements. Buffering improves performance drastically because it&amp;nbsp;doesn’t&amp;nbsp;read from file by&amp;nbsp;4 bytes.&lt;a href="#fnref9"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content>
  </entry>
  <entry xml:base="http://alex.dzyoba.com/feed">
    <title type="text">Restricting program memory</title>
    <id>programming/restrict-memory.html</id>
    <updated>2014-11-25T00:00:00Z</updated>
    <link href="programming/restrict-memory.html" />
    <author>
      <name>avd</name>
    </author>
    <content type="html">&lt;p&gt;On&amp;nbsp;the other day I’ve&amp;nbsp;decided to&amp;nbsp;solve popular problem: &lt;a href="/programming/external-sort.html"&gt;how to&amp;nbsp;sort 1 million of&amp;nbsp;integers in&amp;nbsp;1 MiB?&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;But before I’ve&amp;nbsp;even started to&amp;nbsp;do&amp;nbsp;anything I&amp;nbsp;thought&amp;nbsp;&amp;mdash; how can I&amp;nbsp;restrict process memory to&amp;nbsp;1 MiB? Will it&amp;nbsp;work? So, here is&amp;nbsp;the answers.&lt;/p&gt;
&lt;h2 id="process-virtual-memory"&gt;Process virtual memory&lt;/h2&gt;
&lt;p&gt;What you have to&amp;nbsp;know before diving in&amp;nbsp;various methods is&amp;nbsp;how process’s&amp;nbsp;virtual memory is&amp;nbsp;structured. There is&amp;nbsp;a, hands down, the best article you could ever find about that is&amp;nbsp;&lt;a href="http://duartes.org/gustavo/blog/post/anatomy-of-a-program-in-memory/"&gt;Gustavo Duarte’s&amp;nbsp;&amp;laquo;Anatomy of&amp;nbsp;a&amp;nbsp;Program in&amp;nbsp;Memory&amp;raquo;&lt;/a&gt;. His whole blog is&amp;nbsp;a&amp;nbsp;treasure.&lt;/p&gt;
&lt;p&gt;After reading Gustavo’s&amp;nbsp;article I&amp;nbsp;can propose 2 possible options for restricting memory&amp;nbsp;&amp;mdash; reduce virtual address space and restict heap size.&lt;/p&gt;
&lt;p&gt;First is&amp;nbsp;to&amp;nbsp;limit whole virtual address space for process. This is&amp;nbsp;nice and easy but not fully correct. We&amp;nbsp;can’t&amp;nbsp;limit whole virtual address space of&amp;nbsp;process to&amp;nbsp;1 MB&amp;nbsp;&amp;mdash; we&amp;nbsp;won’t&amp;nbsp;be&amp;nbsp;able to&amp;nbsp;map kernel and libs.&lt;/p&gt;
&lt;p&gt;Second is&amp;nbsp;to&amp;nbsp;limit &lt;em&gt;heap&lt;/em&gt; size. This is&amp;nbsp;not so&amp;nbsp;easy and seems like nobody tries to&amp;nbsp;do&amp;nbsp;this because the only reasonable way to&amp;nbsp;do&amp;nbsp;this is&amp;nbsp;playing with linker. But for limiting available memory to&amp;nbsp;such small values like 1 MiB it&amp;nbsp;will be&amp;nbsp;absolutely correct.&lt;/p&gt;
&lt;p&gt;Also, I&amp;nbsp;will look at&amp;nbsp;other methods like monitoring memory consumption with intercepting library and system calls related to&amp;nbsp;memory management and changing program environment with emulation and sandboxing.&lt;/p&gt;
&lt;p&gt;For testing and illustrating I&amp;nbsp;will use this little program &lt;code&gt;big_alloc&lt;/code&gt; that allocates (and frees) 100 MiB.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;string.h&amp;gt;
#include &amp;lt;stdbool.h&amp;gt;

// 1000 allocation per 100 KiB = 100 000 KiB = 100 MiB
#define NALLOCS 1000
#define ALLOC_SIZE 1024*100 // 100 KiB

int main(int argc, const char *argv[])
{
    int i = 0;
    int **pp;
    bool failed = false;

    pp = malloc(NALLOCS * sizeof(int *));
    for(i = 0; i &amp;lt; NALLOCS; i++)
    {
        pp[i] = malloc(ALLOC_SIZE);
        if (!pp[i])
        {
            perror(&amp;quot;malloc&amp;quot;);
            printf(&amp;quot;Failed after %d allocations\n&amp;quot;, i);
            failed = true;
            break;
        }
        // Touch some bytes in memory to trick copy-on-write.
        memset(pp[i], 0xA, 100);
        printf(&amp;quot;pp[%d] = %p\n&amp;quot;, i, pp[i]);
    }

    if (!failed)
        printf(&amp;quot;Successfully allocated %d bytes\n&amp;quot;, NALLOCS * ALLOC_SIZE);

    for(i = 0; i &amp;lt; NALLOCS; i++)
    {
        if (pp[i])
            free(pp[i]);
    }
    free(pp);

    return 0;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;All the sources are &lt;a href="https://github.com/dzeban/restrict-memory"&gt;on&amp;nbsp;github&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="ulimit"&gt;ulimit&lt;/h2&gt;
&lt;p&gt;It’s&amp;nbsp;first thing that old unix hacker can think of&amp;nbsp;when asked to&amp;nbsp;limit program memory. &lt;code&gt;ulimit&lt;/code&gt; is&amp;nbsp;bash utility that allows you to&amp;nbsp;restrict program resources, and is&amp;nbsp;just interface for &lt;a href="http://linux.die.net/man/2/setrlimit"&gt;&lt;code&gt;setrlimit&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We&amp;nbsp;can set the limit to&amp;nbsp;resident memory size.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ulimit -m 1024&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now check:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ulimit -a
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 7802
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) 1024
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 1024
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We&amp;nbsp;set limit to&amp;nbsp;1024 kbytes (-m) thus 1 MiB. But when we&amp;nbsp;try to&amp;nbsp;run our program it&amp;nbsp;won’t&amp;nbsp;fail. Setting limit to&amp;nbsp;something more reasonable like 30 MiB will anyway let our program allocate 100 MB. &lt;code&gt;ulimit&lt;/code&gt; simply doesn’t&amp;nbsp;work. Despite setting resident set size to&amp;nbsp;1024 kbytes, I&amp;nbsp;can see in&amp;nbsp;top that resident memory for my&amp;nbsp;program is&amp;nbsp;4872.&lt;/p&gt;
&lt;p&gt;The reason is&amp;nbsp;that Linux doesn’t&amp;nbsp;respect this and &lt;code&gt;man ulimit&lt;/code&gt; tells it&amp;nbsp;directly:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ulimit [-HSTabcdefilmnpqrstuvx [limit]]
    ...
    -m     The maximum resident set size (many systems do not honor this limit)
    ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is&amp;nbsp;also &lt;code&gt;ulimit -d&lt;/code&gt; that is&amp;nbsp;respected &lt;a href="http://lxr.free-electrons.com/source/mm/mmap.c?v=3.16#L290"&gt;according to&amp;nbsp;kernel&lt;/a&gt;, but it’s&amp;nbsp;still work because of&amp;nbsp;mmap (see &lt;a href="#Linker"&gt;Linker&lt;/a&gt; chapter).&lt;/p&gt;
&lt;h2 id="qemu"&gt;QEMU&lt;/h2&gt;
&lt;p&gt;When you want to&amp;nbsp;modify program environment QEMU is&amp;nbsp;the natural way for this kind of&amp;nbsp;tasks. It&amp;nbsp;has &lt;code&gt;-R&lt;/code&gt; option to&amp;nbsp;limit virtual address space. But like I&amp;nbsp;said earlier you can’t&amp;nbsp;restrict address space to&amp;nbsp;small values&amp;nbsp;&amp;mdash; there will be&amp;nbsp;no&amp;nbsp;space to&amp;nbsp;map libc and kernel.&lt;/p&gt;
&lt;p&gt;Look:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ qemu-i386 -R 1048576 ./big_alloc
big_alloc: error while loading shared libraries: libc.so.6: failed to map segment from shared object: Cannot allocate memory&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here, &lt;code&gt;-R 1048576&lt;/code&gt; reserves 1 MiB for guest virtual address space.&lt;/p&gt;
&lt;p&gt;For whole virtual address space we&amp;nbsp;have to&amp;nbsp;set something more reasonable like 20 MB. Look:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ qemu-i386 -R 20M ./big_alloc
malloc: Cannot allocate memory
Failed after 100 allocations&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It&amp;nbsp;successfully fails&lt;a href="#fn1" class="footnoteRef" id="fnref1"&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; after 100 allocations (10 MB).&lt;/p&gt;
&lt;p&gt;So, QEMU is&amp;nbsp;the first winner in&amp;nbsp;restricting program’s&amp;nbsp;memory size though you have to&amp;nbsp;play with &lt;code&gt;-R&lt;/code&gt; value to&amp;nbsp;get correct limit.&lt;/p&gt;
&lt;h2 id="container"&gt;Container&lt;/h2&gt;
&lt;p&gt;Another option after QEMU is&amp;nbsp;to&amp;nbsp;launch application in&amp;nbsp;container, restricting it’s&amp;nbsp;resources. To&amp;nbsp;do&amp;nbsp;this you have several options:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;Use fancy &lt;nobr&gt;high-level&lt;/nobr&gt; &lt;em&gt;docker&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Use regular usermode tools from &lt;em&gt;lxc&lt;/em&gt; package.&lt;/li&gt;
&lt;li&gt;Go&amp;nbsp;hardcore and write your own script with &lt;em&gt;libvirt&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Name it&amp;hellip;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;But after all resources will be&amp;nbsp;restricted with native Linux subsystem called &lt;em&gt;cgroups&lt;/em&gt;. You can try to&amp;nbsp;poke it&amp;nbsp;directly but I&amp;nbsp;suggest using &lt;em&gt;lxc&lt;/em&gt;. I&amp;nbsp;would like to&amp;nbsp;use docker but it&amp;nbsp;works only on&amp;nbsp;&lt;nobr&gt;64-bit&lt;/nobr&gt; machines and my&amp;nbsp;box is&amp;nbsp;small Intel Atom netbook which is&amp;nbsp;i386.&lt;/p&gt;
&lt;p&gt;Ok, quick info. &lt;em&gt;LXC&lt;/em&gt; is&amp;nbsp;&lt;em&gt;LinuX Containers&lt;/em&gt;. It’s&amp;nbsp;a&amp;nbsp;collection of&amp;nbsp;userspace tools and libs for managing kernel facilities to&amp;nbsp;create containers&amp;nbsp;&amp;mdash; isolated and secure environment for application or&amp;nbsp;whole system.&lt;/p&gt;
&lt;p&gt;Kernel facilities that provides such environment are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Control groups (cgroups)&lt;/li&gt;
&lt;li&gt;Kernel namespaces&lt;/li&gt;
&lt;li&gt;chroot&lt;/li&gt;
&lt;li&gt;Kernel capabilities&lt;/li&gt;
&lt;li&gt;SELinux, AppArmor&lt;/li&gt;
&lt;li&gt;Seccomp policies&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can find nice documentation on&amp;nbsp;&lt;a href="https://linuxcontainers.org/"&gt;official site&lt;/a&gt;, on&amp;nbsp;&lt;a href="https://www.stgraber.org/2013/12/20/lxc-1-0-blog-post-series/"&gt;author’s&amp;nbsp;blog&lt;/a&gt; and all over the internet.&lt;/p&gt;
&lt;p&gt;To&amp;nbsp;simply run application in&amp;nbsp;container you have to&amp;nbsp;provide config to&amp;nbsp;&lt;code&gt;&lt;nobr&gt;lxc-execute&lt;/nobr&gt;&lt;/code&gt; where you will configure your container. Every sane person should start from examples in&amp;nbsp;&lt;code&gt;/usr/share/doc/lxc/examples&lt;/code&gt;. Man pages recommends to&amp;nbsp;start with &lt;code&gt;&lt;nobr&gt;lxc-macvlan&lt;/nobr&gt;.conf&lt;/code&gt;. Ok, let’s&amp;nbsp;do&amp;nbsp;this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# cp /usr/share/doc/lxc/examples/lxc-macvlan.conf lxc-my.conf
# lxc-execute -n foo -f ./lxc-my.conf ./big_alloc
Successfully allocated 102400000 bytes&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It&amp;nbsp;works!&lt;/p&gt;
&lt;p&gt;Now lets limit memory. This is&amp;nbsp;what cgroup for. LXC allows you to&amp;nbsp;configure memory subsystem for container’s&amp;nbsp;cgroup by&amp;nbsp;setting memory limits.&lt;/p&gt;
&lt;p&gt;You can find available tunable parameters for memory subsystem in&amp;nbsp;this &lt;a href="https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Resource_Management_Guide/sec-memory.html"&gt;fine RedHat manual&lt;/a&gt;. I’ve&amp;nbsp;found 2:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;memory.limit_in_bytes&lt;/code&gt;&amp;nbsp;&amp;mdash; sets the maximum amount of&amp;nbsp;user memory (including file cache)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;memory.memsw.limit_in_bytes&lt;/code&gt;&amp;nbsp;&amp;mdash; sets the maximum amount for the sum of&amp;nbsp;memory and swap usage&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here is&amp;nbsp;what I&amp;nbsp;added to&amp;nbsp;&lt;em&gt;&lt;nobr&gt;lxc-my&lt;/nobr&gt;.conf&lt;/em&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;lxc.cgroup.memory.limit_in_bytes = 2M
lxc.cgroup.memory.memsw.limit_in_bytes = 2M&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Launch again:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# lxc-execute -n foo -f ./lxc-my.conf ./big_alloc
#&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Nothing happened, looks like it’s&amp;nbsp;way to&amp;nbsp;small memory. Lets try to&amp;nbsp;launch it&amp;nbsp;from shell in&amp;nbsp;container.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# lxc-execute -n foo -f ./lxc-my.conf /bin/bash
#&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Looks like bash failed to&amp;nbsp;launch. Lets try &lt;code&gt;/bin/sh&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# lxc-execute -n foo -f ./lxc-my.conf -l DEBUG -o log /bin/sh
sh-4.2# ./dev/big_alloc/big_alloc 
Killed&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Yay! We&amp;nbsp;can see this nice act of&amp;nbsp;killing in&amp;nbsp;&lt;code&gt;dmesg&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[15447.035569] big_alloc invoked oom-killer: gfp_mask=0xd0, order=0, oom_score_adj=0
...
[15447.035779] Task in /lxc/foo
[15447.035785]  killed as a result of limit of 
[15447.035789] /lxc/foo

[15447.035795] memory: usage 3072kB, limit 3072kB, failcnt 127
[15447.035800] memory+swap: usage 3072kB, limit 3072kB, failcnt 0
[15447.035805] kmem: usage 0kB, limit 18014398509481983kB, failcnt 0
[15447.035808] Memory cgroup stats for /lxc/foo: cache:32KB rss:3040KB rss_huge:0KB mapped_file:0KB writeback:0KB swap:0KB inactive_anon:1588KB active_anon:1448KB inactive_file:16KB active_file:16KB unevictable:0KB
[15447.035836] [ pid ]   uid  tgid total_vm      rss nr_ptes swapents oom_score_adj name
[15447.035963] [ 9225]     0  9225      942      308      10        0 0 init.lxc
[15447.035971] [ 9228]     0  9228      833      698       6        0 0 sh
[15447.035978] [ 9252]     0  9252    16106      843      36        0 0 big_alloc
[15447.035983] Memory cgroup out of memory: Kill process 9252 (big_alloc) score 1110 or sacrifice child
[15447.035990] Killed process 9252 (big_alloc) total-vm:64424kB, anon-rss:2396kB, file-rss:976kB&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Though we&amp;nbsp;haven’t&amp;nbsp;seen error message from &lt;code&gt;big_alloc&lt;/code&gt; about malloc failure and how much memory we&amp;nbsp;were able to&amp;nbsp;get, I&amp;nbsp;think we’ve&amp;nbsp;successfully restricted memory via container technology and can stop with it&amp;nbsp;for now.&lt;/p&gt;
&lt;h2 id="Linker"&gt;Linker&lt;/h2&gt;
&lt;p&gt;Now lets try to&amp;nbsp;modify binary image limiting space available for heap.&lt;/p&gt;
&lt;p&gt;Linking is&amp;nbsp;the final part of&amp;nbsp;building program and it&amp;nbsp;implies using linker and linker script. Linker script is&amp;nbsp;description of&amp;nbsp;program sections in&amp;nbsp;memory along with it’s&amp;nbsp;attributes and stuff.&lt;/p&gt;
&lt;p&gt;Here is&amp;nbsp;a&amp;nbsp;simple linker script:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ENTRY(main)

SECTIONS
{
  . = 0x10000;
  .text : { *(.text) }
  . = 0x8000000;
  .data : { *(.data) }
  .bss : { *(.bss) }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Dot is&amp;nbsp;&lt;em&gt;current&lt;/em&gt; location. What that script tells us&amp;nbsp;is&amp;nbsp;that &lt;code&gt;.text&lt;/code&gt; section starts at&amp;nbsp;address 0&amp;times;10000, and then starting from 0&amp;times;8000000 we&amp;nbsp;have 2 subsequent sections &lt;code&gt;.data&lt;/code&gt; and &lt;code&gt;.bss&lt;/code&gt;. Entry point is&amp;nbsp;&lt;code&gt;main&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Nice and sweet but it&amp;nbsp;will not work for any useful applications. And the reason is&amp;nbsp;that &lt;code&gt;main&lt;/code&gt; function that you write in&amp;nbsp;C&amp;nbsp;programs is&amp;nbsp;not actually first function being called. There is&amp;nbsp;a&amp;nbsp;whole lot of&amp;nbsp;initialization and cleanup code. That code is&amp;nbsp;provided with C&amp;nbsp;runtime (also shorthanded to&amp;nbsp;&lt;em&gt;crt&lt;/em&gt;) and spread into &lt;em&gt;crt#.o&lt;/em&gt; libraries in&amp;nbsp;&lt;code&gt;/usr/lib&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;You can see exact details if&amp;nbsp;you launch &lt;code&gt;gcc&lt;/code&gt; with &lt;code&gt;-v&lt;/code&gt; option. You’ll&amp;nbsp;see that at&amp;nbsp;first it&amp;nbsp;invokes &lt;code&gt;cc1&lt;/code&gt; and creates assembly, then translate it&amp;nbsp;to&amp;nbsp;object file with &lt;code&gt;as&lt;/code&gt; and finally combines everything in&amp;nbsp;ELF file with &lt;code&gt;collect2&lt;/code&gt;. That &lt;code&gt;collect2&lt;/code&gt; is&amp;nbsp;&lt;code&gt;ld&lt;/code&gt; wrapper. It&amp;nbsp;takes your object file and 5 additional libs to&amp;nbsp;create final binary image:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;/usr/lib/gcc/&lt;nobr&gt;i686-redhat-linux&lt;/nobr&gt;/4.8.3/./././crt1.o&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/usr/lib/gcc/&lt;nobr&gt;i686-redhat-linux&lt;/nobr&gt;/4.8.3/./././crti.o&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/usr/lib/gcc/&lt;nobr&gt;i686-redhat-linux&lt;/nobr&gt;/4.8.3/crtbegin.o&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/tmp/ccEZwSgF.o&lt;/code&gt; &lt;code&gt;&amp;lt;-&lt;/code&gt; This one is&amp;nbsp;our program object file&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/usr/lib/gcc/&lt;nobr&gt;i686-redhat-linux&lt;/nobr&gt;/4.8.3/crtend.o&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/usr/lib/gcc/&lt;nobr&gt;i686-redhat-linux&lt;/nobr&gt;/4.8.3/./././crtn.o&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It’s&amp;nbsp;&lt;strong&gt;really&lt;/strong&gt; complicated so&amp;nbsp;instead of&amp;nbsp;writing my&amp;nbsp;own script I’ll&amp;nbsp;modify default linker script. Get default linker script passing &lt;code&gt;-Wl,-verbose&lt;/code&gt; to&amp;nbsp;&lt;code&gt;gcc&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gcc big_alloc.c -o big_alloc -Wl,-verbose&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now let’s&amp;nbsp;figure out how to&amp;nbsp;modify it. Lets see how our binary is&amp;nbsp;built by&amp;nbsp;default. Compile it&amp;nbsp;and look for &lt;code&gt;.data&lt;/code&gt; section address. Here is&amp;nbsp;&lt;code&gt;objdump -h big_alloc&lt;/code&gt; output&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Sections:
Idx Name          Size      VMA       LMA       File off  Algn
...
12 .text         000002e4  080483e0  080483e0  000003e0  2**4
                 CONTENTS, ALLOC, LOAD, READONLY, CODE
...
23 .data         00000004  0804a028  0804a028  00001028  2**2
                 CONTENTS, ALLOC, LOAD, DATA
24 .bss          00000004  0804a02c  0804a02c  0000102c  2**2
                 ALLOC&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;.text&lt;/code&gt;, &lt;code&gt;.data&lt;/code&gt; and &lt;code&gt;.bss&lt;/code&gt; sections are located near 128 MiB.&lt;/p&gt;
&lt;p&gt;Now lets see where is&amp;nbsp;the stack with help of&amp;nbsp;&lt;em&gt;gdb&lt;/em&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[restrict-memory]$ gdb big_alloc 
...
Reading symbols from big_alloc...done.
(gdb) break main
Breakpoint 1 at 0x80484fa: file big_alloc.c, line 12.
(gdb) r
Starting program: /home/avd/dev/restrict-memory/big_alloc 

Breakpoint 1, main (argc=1, argv=0xbffff164) at big_alloc.c:12
12              int i = 0;
Missing separate debuginfos, use: debuginfo-install glibc-2.18-16.fc20.i686
(gdb) info registers 
eax            0x1      1
ecx            0x9a8fc98f       -1701852785
edx            0xbffff0f4       -1073745676
ebx            0x42427000       1111650304
esp            0xbffff0a0       0xbffff0a0
ebp            0xbffff0c8       0xbffff0c8
esi            0x0      0
edi            0x0      0
eip            0x80484fa        0x80484fa &amp;lt;main+10&amp;gt;
eflags         0x286    [ PF SF IF ]
cs             0x73     115
ss             0x7b     123
ds             0x7b     123
es             0x7b     123
fs             0x0      0
gs             0x33     51&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;esp&lt;/code&gt; points to&amp;nbsp;&lt;code&gt;0xbffff0a0&lt;/code&gt; which is&amp;nbsp;near 3 GiB. So&amp;nbsp;we&amp;nbsp;have ~2.9 GiB for heap.&lt;/p&gt;
&lt;p&gt;In&amp;nbsp;real world, stack top address is&amp;nbsp;randomized, e.g. you can see it&amp;nbsp;in&amp;nbsp;output of&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# cat /proc/self/maps&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As&amp;nbsp;we&amp;nbsp;all know, heap grows up&amp;nbsp;from the end of&amp;nbsp;&lt;code&gt;.data&lt;/code&gt; towards the stack. &lt;strong&gt;What if&amp;nbsp;we&amp;nbsp;move &lt;code&gt;.data&lt;/code&gt; section to&amp;nbsp;highest possible address?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Lets put data segment 2 MiB before stack. Take stack top, subtract 2 MiB:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;0xbffff0a0 - 0x200000 = 0xbfdff0a0 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now shift all sections starting with &lt;code&gt;.data&lt;/code&gt; to&amp;nbsp;that address:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;. =     0xbfdff0a0
.data           :
{
  *(.data .data.* .gnu.linkonce.d.*)
  SORT(CONSTRUCTORS)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Compile it:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ gcc big_alloc.c -o big_alloc -Wl,-T hack.lst&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;-Wl&lt;/code&gt; is&amp;nbsp;an&amp;nbsp;option to&amp;nbsp;linker and &lt;code&gt;-T hack.lst&lt;/code&gt; is&amp;nbsp;a&amp;nbsp;linker option itself. It&amp;nbsp;tells linker to&amp;nbsp;use &lt;code&gt;hack.lst&lt;/code&gt; as&amp;nbsp;a&amp;nbsp;linker script.&lt;/p&gt;
&lt;p&gt;Now, if&amp;nbsp;we&amp;nbsp;look at&amp;nbsp;header we’ll&amp;nbsp;see that:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Sections:
Idx Name          Size      VMA       LMA       File off  Algn

 ...

 23 .data         00000004  bfdff0a0  bfdff0a0  000010a0  2**2
                  CONTENTS, ALLOC, LOAD, DATA
 24 .bss          00000004  bfdff0a4  bfdff0a4  000010a4  2**2
                  ALLOC&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But nevertheless it&amp;nbsp;successfully allocates. How? That’s&amp;nbsp;really neat. When I&amp;nbsp;tried to&amp;nbsp;look at&amp;nbsp;pointer values that malloc returns I&amp;nbsp;saw that allocation is&amp;nbsp;starting somewhere over the end of&amp;nbsp;&lt;code&gt;.data&lt;/code&gt; section like &lt;code&gt;0xbf8b7000&lt;/code&gt;, continues for some time with increasing pointers and then resets pointers to&amp;nbsp;&lt;em&gt;lower&lt;/em&gt; address like &lt;code&gt;0xb7676000&lt;/code&gt;. From that address it&amp;nbsp;will allocate for some time with pointers increasing and then resets pointers again to&amp;nbsp;even lower address like &lt;code&gt;0xb5e76000&lt;/code&gt;. Eventually it&amp;nbsp;looks like heap growing down!&lt;/p&gt;
&lt;p&gt;But if&amp;nbsp;you think for a&amp;nbsp;minute it&amp;nbsp;doesn’t&amp;nbsp;really that strange. I’ve&amp;nbsp;examined some &lt;a href="http://code.metager.de/source/xref/gnu/glibc/malloc/malloc.c#sysmalloc"&gt;glibc sources&lt;/a&gt; and found out that when &lt;code&gt;brk&lt;/code&gt; fails it&amp;nbsp;will use &lt;code&gt;mmap&lt;/code&gt; instead. So&amp;nbsp;glibc asks kernel to&amp;nbsp;map some pages, kernel sees that process has lots of&amp;nbsp;holes in&amp;nbsp;virtual memory space and map page from that space for glibc, and finally glibc returns pointer from that page.&lt;/p&gt;
&lt;p&gt;Running &lt;code&gt;big_alloc&lt;/code&gt; under &lt;code&gt;strace&lt;/code&gt; confirmed theory. Just look at&amp;nbsp;normal binary:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;brk(0)                                  = 0x8135000
mmap2(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb77df000
mmap2(NULL, 95800, PROT_READ, MAP_PRIVATE, 3, 0) = 0xb77c7000
mmap2(0x4226d000, 1825436, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x4226d000
mmap2(0x42425000, 12288, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x1b8000) = 0x42425000
mmap2(0x42428000, 10908, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x42428000
mmap2(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb77c6000
mprotect(0x42425000, 8192, PROT_READ)   = 0
mprotect(0x8049000, 4096, PROT_READ)    = 0
mprotect(0x42269000, 4096, PROT_READ)   = 0
munmap(0xb77c7000, 95800)               = 0
brk(0)                                  = 0x8135000
brk(0x8156000)                          = 0x8156000
brk(0)                                  = 0x8156000
mmap2(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb77de000
brk(0)                                  = 0x8156000
brk(0x8188000)                          = 0x8188000
brk(0)                                  = 0x8188000
brk(0x81ba000)                          = 0x81ba000
brk(0)                                  = 0x81ba000
brk(0x81ec000)                          = 0x81ec000
...
brk(0)                                  = 0x9c19000
brk(0x9c4b000)                          = 0x9c4b000
brk(0)                                  = 0x9c4b000
brk(0x9c7d000)                          = 0x9c7d000
brk(0)                                  = 0x9c7d000
brk(0x9caf000)                          = 0x9caf000
...
brk(0)                                  = 0xe29c000
brk(0xe2ce000)                          = 0xe2ce000
brk(0)                                  = 0xe2ce000
brk(0xe300000)                          = 0xe300000
brk(0)                                  = 0xe300000
brk(0)                                  = 0xe300000
brk(0x8156000)                          = 0x8156000
brk(0)                                  = 0x8156000
+++ exited with 0 +++&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and now the modified binary&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;brk(0)                                  = 0xbf896000
mmap2(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb778f000
mmap2(NULL, 95800, PROT_READ, MAP_PRIVATE, 3, 0) = 0xb7777000
mmap2(0x4226d000, 1825436, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x4226d000
mmap2(0x42425000, 12288, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x1b8000) = 0x42425000
mmap2(0x42428000, 10908, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x42428000
mmap2(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb7776000
mprotect(0x42425000, 8192, PROT_READ)   = 0
mprotect(0x8049000, 4096, PROT_READ)    = 0
mprotect(0x42269000, 4096, PROT_READ)   = 0
munmap(0xb7777000, 95800)               = 0
brk(0)                                  = 0xbf896000
brk(0xbf8b7000)                         = 0xbf8b7000
brk(0)                                  = 0xbf8b7000
mmap2(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb778e000
brk(0)                                  = 0xbf8b7000
brk(0xbf8e9000)                         = 0xbf8e9000
brk(0)                                  = 0xbf8e9000
brk(0xbf91b000)                         = 0xbf91b000
brk(0)                                  = 0xbf91b000
brk(0xbf94d000)                         = 0xbf94d000
brk(0)                                  = 0xbf94d000
brk(0xbf97f000)                         = 0xbf97f000
...
brk(0)                                  = 0xbff8e000
brk(0xbffc0000)                         = 0xbffc0000
brk(0)                                  = 0xbffc0000
brk(0xbfff2000)                         = 0xbffc0000
mmap2(NULL, 1048576, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb7676000
brk(0)                                  = 0xbffc0000
brk(0xbfffa000)                         = 0xbffc0000
mmap2(NULL, 1048576, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb7576000
brk(0)                                  = 0xbffc0000
brk(0xbfffa000)                         = 0xbffc0000
mmap2(NULL, 1048576, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb7476000
brk(0)                                  = 0xbffc0000
brk(0xbfffa000)                         = 0xbffc0000
mmap2(NULL, 1048576, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb7376000
...
brk(0)                                  = 0xbffc0000
brk(0xbfffa000)                         = 0xbffc0000
mmap2(NULL, 1048576, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb1c76000
brk(0)                                  = 0xbffc0000
brk(0xbfffa000)                         = 0xbffc0000
mmap2(NULL, 1048576, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb1b76000
brk(0)                                  = 0xbffc0000
brk(0xbfffa000)                         = 0xbffc0000
mmap2(NULL, 1048576, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb1a76000
brk(0)                                  = 0xbffc0000
brk(0)                                  = 0xbffc0000
brk(0)                                  = 0xbffc0000
...
brk(0)                                  = 0xbffc0000
brk(0)                                  = 0xbffc0000
brk(0)                                  = 0xbffc0000
+++ exited with 0 +++&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That being said, shifting &lt;code&gt;.data&lt;/code&gt; section up&amp;nbsp;to&amp;nbsp;stack (thus reducing space for heap) is&amp;nbsp;pointless because kernel will map page for malloc from virtual memory empty area.&lt;/p&gt;
&lt;h2 id="sandbox"&gt;Sandbox&lt;/h2&gt;
&lt;p&gt;The other way to&amp;nbsp;restrict program memory is&amp;nbsp;sandboxing. The difference from emulation is&amp;nbsp;that we’re&amp;nbsp;not really emulating anything but instead we&amp;nbsp;track and control certain things in&amp;nbsp;program behaviour. Usually sandboxing is&amp;nbsp;used for security research when you have some kind of&amp;nbsp;malware and need to&amp;nbsp;analyze it&amp;nbsp;without harming your system.&lt;/p&gt;
&lt;p&gt;I’ve&amp;nbsp;come up&amp;nbsp;with several sanboxing methods and implemented most promising.&lt;/p&gt;
&lt;h3 id="ld_preload-trick"&gt;LD_PRELOAD trick&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;LD_PRELOAD&lt;/code&gt; is&amp;nbsp;special environment variable that when set will make dynamic linker use &amp;laquo;preloaded&amp;raquo; library before any other, including libc, library. It’s&amp;nbsp;used in&amp;nbsp;a&amp;nbsp;lot of&amp;nbsp;scenarios from debugging to, well, sanboxing.&lt;/p&gt;
&lt;p&gt;This trick is&amp;nbsp;also infamously &lt;a href="http://blog.malwaremustdie.org/2014/05/elf-shared-so-dynamic-library-malware.html"&gt;used by&amp;nbsp;some malware&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I&amp;nbsp;have written simple memory management sandbox that intercepts &lt;code&gt;malloc&lt;/code&gt;/&lt;code&gt;free&lt;/code&gt; calls, do&amp;nbsp;memory usage accounting and returns &lt;code&gt;ENOMEM&lt;/code&gt; if&amp;nbsp;memory limit is&amp;nbsp;exceeded.&lt;/p&gt;
&lt;p&gt;To&amp;nbsp;do&amp;nbsp;this I&amp;nbsp;have written a&amp;nbsp;shared library with my&amp;nbsp;own &lt;code&gt;malloc&lt;/code&gt;/&lt;code&gt;free&lt;/code&gt; wrappers that will increment counter by&amp;nbsp;&lt;code&gt;malloc&lt;/code&gt; size and decrement when &lt;code&gt;free&lt;/code&gt; is&amp;nbsp;called. This library is&amp;nbsp;being preloaded with &lt;code&gt;LD_PRELOAD&lt;/code&gt; when running application under test.&lt;/p&gt;
&lt;p&gt;Here is&amp;nbsp;my&amp;nbsp;malloc implementation.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;void *malloc(size_t size)
{
    void *p = NULL;

    if (libc_malloc == NULL) 
        save_libc_malloc();

    if (mem_allocated &amp;lt;= MEM_THRESHOLD)
    {
        p = libc_malloc(size);
    }
    else
    {
        errno = ENOMEM;
        return NULL;
    }

    if (!no_hook) 
    {
        no_hook = 1;
        account(p, size);
        no_hook = 0;
    }

    return p;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;libc_malloc&lt;/code&gt; is&amp;nbsp;pointer to&amp;nbsp;original &lt;code&gt;malloc&lt;/code&gt; from libc. &lt;code&gt;no_hook&lt;/code&gt; is&amp;nbsp;a&amp;nbsp;&lt;nobr&gt;thread-local&lt;/nobr&gt; flag. It’s&amp;nbsp;is&amp;nbsp;used to&amp;nbsp;be&amp;nbsp;able to&amp;nbsp;use malloc in&amp;nbsp;malloc hooks and avoid recursive calls&amp;nbsp;&amp;mdash; idea taken from &lt;a href="http://www.slideshare.net/tetsu.koba/tips-of-malloc-free"&gt;Tetsuyuki Kobayashi presentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;malloc&lt;/code&gt; is&amp;nbsp;used implicitly in&amp;nbsp;&lt;code&gt;account&lt;/code&gt; function by&amp;nbsp;&lt;a href="http://troydhanson.github.io/uthash/"&gt;uthash&lt;/a&gt; hash table library. Why use hash table? It’s&amp;nbsp;because when you call &lt;code&gt;free&lt;/code&gt; you pass to&amp;nbsp;it&amp;nbsp;only the pointer and in&amp;nbsp;&lt;code&gt;free&lt;/code&gt; you don’t&amp;nbsp;know how much memory has been allocated. So&amp;nbsp;I&amp;nbsp;have hash table with pointer as&amp;nbsp;a&amp;nbsp;key and allocated size as&amp;nbsp;a&amp;nbsp;value. Here is&amp;nbsp;what I&amp;nbsp;do&amp;nbsp;on&amp;nbsp;malloc:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;struct malloc_item *item, *out;

item = malloc(sizeof(*item));
item-&amp;gt;p = ptr;
item-&amp;gt;size = size;

HASH_ADD_PTR(HT, p, item);

mem_allocated += size;

fprintf(stderr, &amp;quot;Alloc: %p -&amp;gt; %zu\n&amp;quot;, ptr, size);&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;mem_allocated&lt;/code&gt; is&amp;nbsp;that static variable that is&amp;nbsp;compared against threshold in&amp;nbsp;&lt;code&gt;malloc&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Now when &lt;code&gt;free&lt;/code&gt; is&amp;nbsp;called here is&amp;nbsp;what happened:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;struct malloc_item *found;

HASH_FIND_PTR(HT, &amp;amp;ptr, found);
if (found)
{
    mem_allocated -= found-&amp;gt;size;
    fprintf(stderr, &amp;quot;Free: %p -&amp;gt; %zu\n&amp;quot;, found-&amp;gt;p, found-&amp;gt;size);
    HASH_DEL(HT, found);
    free(found);
}
else
{
    fprintf(stderr, &amp;quot;Freeing unaccounted allocation %p\n&amp;quot;, ptr);
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Yep, just decrement &lt;code&gt;mem_allocated&lt;/code&gt;. It’s&amp;nbsp;that simple.&lt;/p&gt;
&lt;p&gt;But the really cool thing is&amp;nbsp;that it&amp;nbsp;works rock solid&lt;a href="#fn2" class="footnoteRef" id="fnref2"&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[restrict-memory]$ LD_PRELOAD=./libmemrestrict.so ./big_alloc
pp[0] = 0x25ac210
pp[1] = 0x25c5270
pp[2] = 0x25de2d0
pp[3] = 0x25f7330
pp[4] = 0x2610390
pp[5] = 0x26293f0
pp[6] = 0x2642450
pp[7] = 0x265b4b0
pp[8] = 0x2674510
pp[9] = 0x268d570
pp[10] = 0x26a65d0
pp[11] = 0x26bf630
pp[12] = 0x26d8690
pp[13] = 0x26f16f0
pp[14] = 0x270a750
pp[15] = 0x27237b0
pp[16] = 0x273c810
pp[17] = 0x2755870
pp[18] = 0x276e8d0
pp[19] = 0x2787930
pp[20] = 0x27a0990
malloc: Cannot allocate memory
Failed after 21 allocations&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Full source code for library is&amp;nbsp;&lt;a href="https://github.com/dzeban/restrict-memory/blob/master/memrestrict.c"&gt;on&amp;nbsp;github&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;So, LD_PRELOAD is&amp;nbsp;a&amp;nbsp;great way to&amp;nbsp;restrict memory!&lt;/p&gt;
&lt;h3 id="ptrace"&gt;ptrace&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;ptrace&lt;/code&gt; is&amp;nbsp;another feature that can be&amp;nbsp;use to&amp;nbsp;build memory sandboxing. &lt;code&gt;ptrace&lt;/code&gt; is&amp;nbsp;a&amp;nbsp;system call that allows you to&amp;nbsp;control the execution of&amp;nbsp;another process. It’s&amp;nbsp;built into various POSIX operating system including, of&amp;nbsp;course, Linux.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ptrace&lt;/code&gt; is&amp;nbsp;the foundation of&amp;nbsp;tracers like &lt;a href="http://sourceforge.net/p/strace/code/ci/master/tree/strace.c#l343"&gt;&lt;em&gt;strace&lt;/em&gt;&lt;/a&gt;, &lt;a href="http://anonscm.debian.org/cgit/collab-maint/ltrace.git/tree/sysdeps/linux-gnu/trace.c#n78"&gt;&lt;em&gt;ltrace&lt;/em&gt;&lt;/a&gt;, almost every sandboxing software like &lt;a href="http://www.citi.umich.edu/u/provos/systrace/"&gt;&lt;em&gt;systrace&lt;/em&gt;&lt;/a&gt;, &lt;a href="https://github.com/psychoschlumpf/sydbox"&gt;&lt;em&gt;sydbox&lt;/em&gt;&lt;/a&gt;, &lt;a href="http://pdos.csail.mit.edu/mbox/"&gt;&lt;em&gt;mbox&lt;/em&gt;&lt;/a&gt; and all debuggers including &lt;a href="https://sourceware.org/git/gitweb.cgi?p=binutils-gdb.git;a=blob;f=gdb/inf-ptrace.c;h=6eb8080242349296e43dcc19df4a0896e6093fa8;hb=HEAD"&gt;&lt;em&gt;gdb&lt;/em&gt;&lt;/a&gt; itself.&lt;/p&gt;
&lt;p&gt;I&amp;nbsp;have built custom tool with &lt;code&gt;ptrace&lt;/code&gt;. It&amp;nbsp;traces &lt;code&gt;brk&lt;/code&gt; calls and look for distance between initial program break value and new value set by&amp;nbsp;the next &lt;code&gt;brk&lt;/code&gt; call.&lt;/p&gt;
&lt;p&gt;This tool forks and becomes 2 processes. Parent process is&amp;nbsp;tracer and child process is&amp;nbsp;tracee. In&amp;nbsp;child process I&amp;nbsp;call &lt;code&gt;ptrace(PTRACE_TRACEME)&lt;/code&gt; and then &lt;code&gt;execv&lt;/code&gt;. In&amp;nbsp;parent I&amp;nbsp;use &lt;code&gt;ptrace(PTRACE_SYSCALL)&lt;/code&gt; to&amp;nbsp;stop on&amp;nbsp;syscall and filter &lt;code&gt;brk&lt;/code&gt; calls from child and then another &lt;code&gt;ptrace(PTRACE_SYSCALL)&lt;/code&gt; to&amp;nbsp;get &lt;code&gt;brk&lt;/code&gt; return value.&lt;/p&gt;
&lt;p&gt;When &lt;code&gt;brk&lt;/code&gt; exceeded threshold I&amp;nbsp;set &lt;code&gt;-ENOMEM&lt;/code&gt; as&amp;nbsp;&lt;code&gt;brk&lt;/code&gt; return value. This is&amp;nbsp;set in&amp;nbsp;&lt;code&gt;eax&lt;/code&gt; register so&amp;nbsp;I&amp;nbsp;just overwrite it&amp;nbsp;with &lt;code&gt;ptrace(PTRACE_SETREGS)&lt;/code&gt;. Here is&amp;nbsp;meaty part:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Get return value
if (!syscall_trace(pid, &amp;amp;state))
{
    dbg(&amp;quot;brk return: 0x%08X, brk_start 0x%08X\n&amp;quot;, state.eax, brk_start);

    if (brk_start) // We have start of brk
    {
        diff = state.eax - brk_start;

        // If child process exceeded threshold 
        // replace brk return value with -ENOMEM
        if (diff &amp;gt; THRESHOLD || threshold) 
        {
            dbg(&amp;quot;THRESHOLD!\n&amp;quot;);
            threshold = true;
            state.eax = -ENOMEM;
            ptrace(PTRACE_SETREGS, pid, 0, &amp;amp;state);
        }
        else
        {
            dbg(&amp;quot;diff 0x%08X\n&amp;quot;, diff);
        }
    }
    else
    {
        dbg(&amp;quot;Assigning 0x%08X to brk_start\n&amp;quot;, state.eax);
        brk_start = state.eax;
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Also, I&amp;nbsp;intercept &lt;code&gt;mmap&lt;/code&gt;/&lt;code&gt;mmap2&lt;/code&gt; calls because libc is&amp;nbsp;smart enough to&amp;nbsp;call it&amp;nbsp;when &lt;code&gt;brk&lt;/code&gt; failed. So&amp;nbsp;when I&amp;nbsp;have threshold exceeded and see &lt;code&gt;mmap&lt;/code&gt; calls I&amp;nbsp;just fail it&amp;nbsp;with &lt;code&gt;ENOMEM&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;It&amp;nbsp;works!&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[restrict-memory]$ ./ptrace-restrict ./big_alloc
pp[0] = 0x8958fb0
pp[1] = 0x8971fb8
pp[2] = 0x898afc0
pp[3] = 0x89a3fc8
pp[4] = 0x89bcfd0
pp[5] = 0x89d5fd8
pp[6] = 0x89eefe0
pp[7] = 0x8a07fe8
pp[8] = 0x8a20ff0
pp[9] = 0x8a39ff8
pp[10] = 0x8a53000
pp[11] = 0x8a6c008
pp[12] = 0x8a85010
pp[13] = 0x8a9e018
pp[14] = 0x8ab7020
pp[15] = 0x8ad0028
pp[16] = 0x8ae9030
pp[17] = 0x8b02038
pp[18] = 0x8b1b040
pp[19] = 0x8b34048
pp[20] = 0x8b4d050
malloc: Cannot allocate memory
Failed after 21 allocations&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But&amp;hellip; I&amp;nbsp;don’t&amp;nbsp;really like it. It’s&amp;nbsp;ABI specific, i.e. it&amp;nbsp;has to&amp;nbsp;use &lt;code&gt;rax&lt;/code&gt; instead of&amp;nbsp;&lt;code&gt;eax&lt;/code&gt; on&amp;nbsp;&lt;nobr&gt;64-bit&lt;/nobr&gt; machine, so&amp;nbsp;either I&amp;nbsp;make different version of&amp;nbsp;that tool or&amp;nbsp;use &lt;code&gt;#ifdef&lt;/code&gt; to&amp;nbsp;cope with ABI differences or&amp;nbsp;make you build it&amp;nbsp;with &lt;code&gt;-m32&lt;/code&gt; option. But that’s&amp;nbsp;not usable. Also it&amp;nbsp;probably won’t&amp;nbsp;work on&amp;nbsp;other POSIX like systems, because they might have different ABI.&lt;/p&gt;
&lt;h3 id="other"&gt;Other&lt;/h3&gt;
&lt;p&gt;There are also other things one may try which I&amp;nbsp;rejected for different reasons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.gnu.org/software/libc/manual/html_node/Hooks-for-Malloc.html"&gt;&lt;strong&gt;malloc hooks&lt;/strong&gt;&lt;/a&gt;. Deprecated as&amp;nbsp;said man page so&amp;nbsp;I&amp;nbsp;didn’t&amp;nbsp;bother trying it.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://man7.org/linux/man-pages/man2/prctl.2.html"&gt;&lt;strong&gt;Seccomp and &lt;code&gt;prctl&lt;/code&gt; with &lt;code&gt;PR_SET_MM_START_BRK&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;. This might work but as&amp;nbsp;said in&amp;nbsp;&lt;a href="http://lxr.free-electrons.com/source/Documentation/prctl/seccomp_filter.txt"&gt;seccomp filtering kernel documentation&lt;/a&gt; it’s&amp;nbsp;not a&amp;nbsp;sandboxing but a&amp;nbsp;&amp;laquo;mechanism for minimizing the exposed kernel surface&amp;raquo;. So&amp;nbsp;I&amp;nbsp;guess it&amp;nbsp;will be&amp;nbsp;even more awkward than using ptrace by&amp;nbsp;hand. Though I&amp;nbsp;might look at&amp;nbsp;it&amp;nbsp;sometime.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://sandbox.libvirt.org/quickstart/"&gt;&lt;strong&gt;&lt;nobr&gt;libvirt-sandbox&lt;/nobr&gt;&lt;/strong&gt;&lt;/a&gt;. Nope, it’s&amp;nbsp;just a&amp;nbsp;wrapper over lxc and qemu.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://linux.die.net/man/8/sandbox"&gt;&lt;strong&gt;SELinux sandbox&lt;/strong&gt;&lt;/a&gt;. Nope. Just doesn’t&amp;nbsp;work though it&amp;nbsp;uses cgroup.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="recap"&gt;Recap&lt;/h2&gt;
&lt;p&gt;In&amp;nbsp;the end I’d&amp;nbsp;like to&amp;nbsp;recap:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;There are lot of&amp;nbsp;ways to&amp;nbsp;restricting memory:
&lt;ul&gt;
&lt;li&gt;Resource limiting with ulimit and cgroup&lt;/li&gt;
&lt;li&gt;Running under emulator like QEMU&lt;/li&gt;
&lt;li&gt;Sandboxing with LD_PRELOAD and ptrace&lt;/li&gt;
&lt;li&gt;Modifying segments in&amp;nbsp;binary image.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;But not all of&amp;nbsp;them are working
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ulimit&lt;/code&gt; doesn’t&amp;nbsp;work.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cgroup&lt;/code&gt; kinda works&amp;nbsp;&amp;mdash; crashing application&lt;/li&gt;
&lt;li&gt;Emulating works&amp;nbsp;&amp;mdash; crashing application&lt;/li&gt;
&lt;li&gt;&lt;code&gt;LD_PRELOAD&lt;/code&gt; works amazing!&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ptrace&lt;/code&gt; works good enough but ABI dependant&lt;/li&gt;
&lt;li&gt;Linker magic doesn’t&amp;nbsp;work because ingenious libc calls &lt;code&gt;mmap&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="references"&gt;References&lt;/h2&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;&lt;a href="http://duartes.org/gustavo/blog/post/anatomy-of-a-program-in-memory/"&gt;Gustavo Duarte’s&amp;nbsp;article again.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://coldattic.info/shvedsky/pro/blogs/a-foo-walks-into-a-bar/posts/40"&gt;Limiting time and memory consumption of&amp;nbsp;a&amp;nbsp;program in&amp;nbsp;Linux.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/4249063/run-an-untrusted-c-program-in-a-sandbox-in-linux-that-prevents-it-from-opening-f"&gt;Linux sandboxing&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="footnotes"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn1"&gt;&lt;p&gt;I&amp;nbsp;think I’ve&amp;nbsp;just invented new term for QA&amp;nbsp;guys.&lt;a href="#fnref1"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn2"&gt;&lt;p&gt;Unless application itself uses LD_PRELOAD:-\&lt;a href="#fnref2"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content>
  </entry>
  <entry xml:base="http://alex.dzyoba.com/feed">
    <title type="text">Linux profiling. Ftrace</title>
    <id>linux/profiling-ftrace.html</id>
    <updated>2014-10-27T00:00:00Z</updated>
    <link href="linux/profiling-ftrace.html" />
    <author>
      <name>Alex Dzyoba</name>
    </author>
    <content type="html">&lt;p&gt;TOC:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;&lt;a href="/linux/profiling-intro.html"&gt;Intro&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/linux/profiling-gprof-gcov.html"&gt;Userspace profiling: gprof, gcov&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/linux/profiling-valgrind.html"&gt;Userspace profiling: Valgrind&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/linux/profiling-kernel.html"&gt;Kernel profiling: Intro&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Kernel profiling: ftrace&lt;/li&gt;
&lt;li&gt;&lt;a href="/linux/profiling-perf.html"&gt;Kernel profiling: perf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/linux/profiling-systemtap.html"&gt;Kernel profiling: SystemTap&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Various tools&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="ftrace"&gt;ftrace&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Ftrace&lt;/strong&gt; is&amp;nbsp;a&amp;nbsp;framework for tracing and profiling Linux kernel with features like that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Kernel functions tracing&lt;/li&gt;
&lt;li&gt;Call graph tracing&lt;/li&gt;
&lt;li&gt;Tracepoints support&lt;/li&gt;
&lt;li&gt;Dynamic tracing via kprobes&lt;/li&gt;
&lt;li&gt;Statistics for kernel functions&lt;/li&gt;
&lt;li&gt;Statistics for kernel events&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Essentially, &lt;em&gt;ftrace&lt;/em&gt; built around smart lockless ring buffer implementation (see &lt;a href="http://lxr.free-electrons.com/source/Documentation/trace/ring-buffer-design.txt?v=3.15"&gt;Documentation/trace/&lt;nobr&gt;ring-buffer-design&lt;/nobr&gt;.txt/&lt;/a&gt;). That buffer stores all &lt;em&gt;ftrace&lt;/em&gt; info and imported via debugfs&lt;a href="#fn1" class="footnoteRef" id="fnref1"&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; in&amp;nbsp;&lt;code&gt;/sys/kernel/debug/tracing/&lt;/code&gt;. All maninpulations are done with simple manipulations with files in&amp;nbsp;this directory.&lt;/p&gt;
&lt;h2 id="how-ftrace-works"&gt;How ftrace works&lt;/h2&gt;
&lt;p&gt;As&amp;nbsp;I’ve&amp;nbsp;just said, &lt;em&gt;ftrace&lt;/em&gt; is&amp;nbsp;a&amp;nbsp;framework meaning that it&amp;nbsp;provides only ring buffer, all real work is&amp;nbsp;done by&amp;nbsp;so&amp;nbsp;called &lt;strong&gt;tracers&lt;/strong&gt;. Currently, &lt;em&gt;ftrace&lt;/em&gt; includes next tracers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;function&lt;/em&gt;&amp;nbsp;&amp;mdash; default tracer;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;function_graph&lt;/em&gt;&amp;nbsp;&amp;mdash; constructs call graph;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;irqsoff&lt;/em&gt;, &lt;em&gt;preempoff&lt;/em&gt;, &lt;em&gt;preemptirqsoff&lt;/em&gt;, &lt;em&gt;wakeup&lt;/em&gt;, &lt;em&gt;wakeup_rt&lt;/em&gt;&amp;nbsp;&amp;mdash; latency tracers. These are origins of&amp;nbsp;&lt;em&gt;ftrace&lt;/em&gt;, they were presented in&amp;nbsp;-rt kernel. I&amp;nbsp;won’t&amp;nbsp;give you lot of&amp;nbsp;info on&amp;nbsp;this topic cause it’s&amp;nbsp;more about realtime, scheduling and hardware stuff;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;nop&lt;/em&gt;&amp;nbsp;&amp;mdash; you guess.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Also, as&amp;nbsp;additional features you’ll&amp;nbsp;get:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;kernel tracepoints support;&lt;/li&gt;
&lt;li&gt;kprobes support;&lt;/li&gt;
&lt;li&gt;blktrace support, though it’s&amp;nbsp;going to&amp;nbsp;be&amp;nbsp;deleted.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now let’s&amp;nbsp;look at&amp;nbsp;specific tracers.&lt;/p&gt;
&lt;h3 id="function-tracing"&gt;Function tracing&lt;/h3&gt;
&lt;p&gt;Main &lt;em&gt;ftrace&lt;/em&gt; function is, well, functions tracing (&lt;code&gt;function&lt;/code&gt; and &lt;code&gt;function_graph&lt;/code&gt; tracers). To&amp;nbsp;archieve this, kernel function instrumented with &lt;code&gt;mcount&lt;/code&gt; calls, just like with &lt;a href="/linux/profiling-gprof-gcov.html"&gt;&lt;em&gt;gcov&lt;/em&gt;&lt;/a&gt;. But kernel &lt;code&gt;mcount&lt;/code&gt;, of&amp;nbsp;course, totally differs from userspace, because it’s&amp;nbsp;architecture dependent. This dependency is&amp;nbsp;required to&amp;nbsp;be&amp;nbsp;able to&amp;nbsp;build call graphs, and more specific to&amp;nbsp;get caller address from previous stack frame.&lt;/p&gt;
&lt;p&gt;This &lt;code&gt;mcount&lt;/code&gt; is&amp;nbsp;inserted in&amp;nbsp;function prologue and if&amp;nbsp;it’s&amp;nbsp;turned off it’s&amp;nbsp;doing nothing. But if&amp;nbsp;it’s&amp;nbsp;turned on&amp;nbsp;then it’s&amp;nbsp;calling &lt;em&gt;ftrace&lt;/em&gt; function that depending on&amp;nbsp;current tracer writes different data to&amp;nbsp;ring buffer.&lt;/p&gt;
&lt;h3 id="events-tracing"&gt;Events tracing&lt;/h3&gt;
&lt;p&gt;Events tracing is&amp;nbsp;done with help of&amp;nbsp;&lt;a href="http://lxr.free-electrons.com/source/Documentation/trace/events.txt?v=3.15"&gt;tracepoints&lt;/a&gt;. You set event via &lt;code&gt;set_event&lt;/code&gt; file in&amp;nbsp;&lt;code&gt;/sys/kernel/debug/tracing&lt;/code&gt; and then it&amp;nbsp;will be&amp;nbsp;traced in&amp;nbsp;ring buffer. For example, to&amp;nbsp;trace &lt;code&gt;kmalloc&lt;/code&gt;, just issue&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;echo kmalloc &amp;gt; /sys/kernel/debug/tracing/set_event&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and now you can see in&amp;nbsp;&lt;code&gt;trace&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tail-7747  [000] .... 12584.876544: kmalloc: call_site=c06c56da ptr=e9cf9eb0 bytes_req=4 bytes_alloc=8 gfp_flags=GFP_KERNEL|GFP_ZERO&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and it’s&amp;nbsp;the same as&amp;nbsp;in&amp;nbsp;&lt;code&gt;include/trace/events/kmem.h&lt;/code&gt;, meaining it’s&amp;nbsp;just a&amp;nbsp;&lt;em&gt;tracepoint&lt;/em&gt;.&lt;/p&gt;
&lt;h3 id="kprobes-tracing"&gt;kprobes tracing&lt;/h3&gt;
&lt;p&gt;In&amp;nbsp;kernel 3.10 there was added support for &lt;a href="http://lwn.net/Articles/343766/"&gt;kprobes and kretprobes&lt;/a&gt; for &lt;em&gt;ftrace&lt;/em&gt;. Now you can do&amp;nbsp;dynamic tracing without writing your own kernel module. But, unfortunately, there is&amp;nbsp;nothing much to&amp;nbsp;do&amp;nbsp;with it, just&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Registers values&lt;/li&gt;
&lt;li&gt;Memory dumps&lt;/li&gt;
&lt;li&gt;Symbols values&lt;/li&gt;
&lt;li&gt;Stack values&lt;/li&gt;
&lt;li&gt;Return values (kretprobes)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And again, this output is&amp;nbsp;written to&amp;nbsp;ring buffer. Also, you can calculate some statistic over it.&lt;/p&gt;
&lt;p&gt;Let’s&amp;nbsp;trace something that doesn’t&amp;nbsp;have tracepoint like something not from kernel but from kernel module.&lt;/p&gt;
&lt;p&gt;On&amp;nbsp;my&amp;nbsp;Samsung N210 laptop I&amp;nbsp;have &lt;em&gt;ath9k&lt;/em&gt; WiFi module that’s&amp;nbsp;most likely doesn’t&amp;nbsp;have any tracepoints. To&amp;nbsp;check this just grep &lt;em&gt;available_events&lt;/em&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[tracing]# grep ath available_events 
cfg80211:rdev_del_mpath
cfg80211:rdev_add_mpath
cfg80211:rdev_change_mpath
cfg80211:rdev_get_mpath
cfg80211:rdev_dump_mpath
cfg80211:rdev_return_int_mpath_info
ext4:ext4_ext_convert_to_initialized_fastpath&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Lets see what functions can we&amp;nbsp;put probe on:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[tracing]# grep &amp;quot;\[ath9k\]&amp;quot; /proc/kallsyms | grep &amp;#39; t &amp;#39; | grep rx
f82e6ed0 t ath_rx_remove_buffer [ath9k]
f82e6f60 t ath_rx_buf_link.isra.25  [ath9k]
f82e6ff0 t ath_get_next_rx_buf  [ath9k]
f82e7130 t ath_rx_edma_buf_link [ath9k]
f82e7200 t ath_rx_addbuffer_edma    [ath9k]
f82e7250 t ath_rx_edma_cleanup  [ath9k]
f82f3720 t ath_debug_stat_rx    [ath9k]
f82e7a70 t ath_rx_tasklet   [ath9k]
f82e7310 t ath_rx_cleanup   [ath9k]
f82e7800 t ath_calcrxfilter [ath9k]
f82e73e0 t ath_rx_init  [ath9k]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(First grep filters symbols from &lt;em&gt;ath9k&lt;/em&gt; module, second grep filters functions which resides in&amp;nbsp;text section and last grep filters receiver functions).&lt;/p&gt;
&lt;p&gt;For example, we&amp;nbsp;will trace &lt;a href="http://lxr.free-electrons.com/source/drivers/net/wireless/ath/ath9k/recv.c#L678"&gt;&lt;code&gt;ath_get_next_rx_buf&lt;/code&gt;&lt;/a&gt; function.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[tracing]# echo &amp;#39;r:ath_probe ath9k:ath_get_next_rx_buf $retval&amp;#39; &amp;gt;&amp;gt; kprobe_events&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This command is&amp;nbsp;not from top of&amp;nbsp;my&amp;nbsp;head&amp;nbsp;&amp;mdash; check Documentation/tracing/kprobetrace.txt&lt;/p&gt;
&lt;p&gt;This puts retprobe on&amp;nbsp;our function and fetches return value (it’s&amp;nbsp;just a&amp;nbsp;pointer).&lt;/p&gt;
&lt;p&gt;After we’ve&amp;nbsp;put probe we&amp;nbsp;must enable it:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[tracing]# echo 1 &amp;gt; events/kprobes/enable &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And then we&amp;nbsp;can look for output in&amp;nbsp;&lt;code&gt;trace&lt;/code&gt; file and here it&amp;nbsp;is:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;midori-6741  [000] d.s.  3011.304724: ath_probe: (ath_rx_tasklet+0x35a/0xc30 [ath9k] &amp;lt;- ath_get_next_rx_buf) arg1=0xf6ae39f4&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="profiling-block_hasher"&gt;Profiling block_hasher&lt;/h2&gt;
&lt;p&gt;Now we&amp;nbsp;gonna apply our &lt;em&gt;ftrace&lt;/em&gt; knowledge to&amp;nbsp;solve mysterious performance problem. If&amp;nbsp;you need to&amp;nbsp;refresh, refer to&amp;nbsp;&lt;a href="/linux/profiling-intro.html"&gt;introductionary article&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As&amp;nbsp;we&amp;nbsp;already know, &lt;a href="/linux/profiling-gprof-gcov.html#not-application"&gt;it’s&amp;nbsp;not a&amp;nbsp;application problem&lt;/a&gt;. So&amp;nbsp;now we’ll&amp;nbsp;try to&amp;nbsp;see what’s&amp;nbsp;happening after &lt;code&gt;pread&lt;/code&gt; syscall.&lt;/p&gt;
&lt;p&gt;By&amp;nbsp;default, &lt;em&gt;ftrace&lt;/em&gt; is&amp;nbsp;collecting info about all kernel functions and that’s&amp;nbsp;huge. But, being a&amp;nbsp;sophisticated kernel mechanism, &lt;em&gt;ftrace&lt;/em&gt; has a&amp;nbsp;lot of&amp;nbsp;features, many kinds of&amp;nbsp;options, tunable params and so&amp;nbsp;on&amp;nbsp;for which I&amp;nbsp;don’t&amp;nbsp;have a&amp;nbsp;feeling to&amp;nbsp;talk about because there are plenty of&amp;nbsp;manuals and articles on&amp;nbsp;lwn (see &lt;a href="#ref"&gt;To&amp;nbsp;read&lt;/a&gt; section). Hence, it’s&amp;nbsp;no&amp;nbsp;wonder that we&amp;nbsp;can, for example, filter by&amp;nbsp;PID. Here is&amp;nbsp;the script:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#!/bin/sh

DEBUGFS=`grep debugfs /proc/mounts | awk &amp;#39;{ print $2; }&amp;#39;`

# Reset trace stat
echo 0 &amp;gt; $DEBUGFS/tracing/function_profile_enabled
echo 1 &amp;gt; $DEBUGFS/tracing/function_profile_enabled

echo $$ &amp;gt; $DEBUGFS/tracing/set_ftrace_pid
echo function &amp;gt; $DEBUGFS/tracing/current_tracer

exec $*&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;function_profile_enabled&lt;/code&gt; configures collecting statistical info.&lt;/p&gt;
&lt;p&gt;Launch our magic script&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./ftrace-me ./block_hasher -d /dev/md127 -b 1048576 -t10 -n10000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;get &lt;nobr&gt;per-processor&lt;/nobr&gt; statistics from files in&amp;nbsp;&lt;code&gt;tracing/trace_stat/&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;head -n50 tracing/trace_stat/function* &amp;gt; ~/trace_stat&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and see top 5&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;==&amp;gt; function0 &amp;lt;==
  Function                               Hit    Time            Avg
  --------                               ---    ----            ---
  schedule                            444425    8653900277 us     19472.12 us 
  schedule_timeout                     36019    813403521 us     22582.62 us 
  do_IRQ                             8161576    796860573 us     97.635 us
  do_softirq                          486268    791706643 us     1628.128 us 
  __do_softirq                        486251    790968923 us     1626.667 us 

==&amp;gt; function1 &amp;lt;==
  Function                               Hit    Time            Avg
  --------                               ---    ----            ---
  schedule                           1352233    13378644495 us     9893.742 us 
  schedule_hrtimeout_range             11853    2708879282 us     228539.5 us 
  poll_schedule_timeout                 7733    2366753802 us     306058.9 us 
  schedule_timeout                    176343    1857637026 us     10534.22 us 
  schedule_timeout_interruptible          95    1637633935 us     17238251 us 

==&amp;gt; function2 &amp;lt;==
  Function                               Hit    Time            Avg
  --------                               ---    ----            ---
  schedule                           1260239    9324003483 us     7398.599 us 
  vfs_read                            215859    884716012 us     4098.582 us 
  do_sync_read                        214950    851281498 us     3960.369 us 
  sys_pread64                          13136    830103896 us     63193.04 us 
  generic_file_aio_read                14955    830034649 us     55502.14 us &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(Don’t&amp;nbsp;pay attention to&amp;nbsp;&lt;code&gt;schedule&lt;/code&gt;&amp;nbsp;&amp;mdash; it’s&amp;nbsp;just calls of&amp;nbsp;scheduler).&lt;/p&gt;
&lt;p&gt;Most of&amp;nbsp;the time we&amp;nbsp;are spending in&amp;nbsp;&lt;code&gt;schedule&lt;/code&gt;, &lt;code&gt;do_IRQ&lt;/code&gt;, &lt;code&gt;schedule_hrimeout_range&lt;/code&gt; and &lt;code&gt;vfs_read&lt;/code&gt; meaning that we&amp;nbsp;either waiting for reading (Screw me&amp;nbsp;dead!) or&amp;nbsp;waiting for some timeout. Now that’s&amp;nbsp;a&amp;nbsp;strange! To&amp;nbsp;make it&amp;nbsp;clearer we&amp;nbsp;can disable so&amp;nbsp;called graph time so&amp;nbsp;that child functions wouldn’t&amp;nbsp;be&amp;nbsp;counted. Let me&amp;nbsp;explain, by&amp;nbsp;default &lt;em&gt;ftrace&lt;/em&gt; counting function time as&amp;nbsp;a&amp;nbsp;time of&amp;nbsp;function itself plus all subroutines calls. That’s&amp;nbsp;and &lt;code&gt;graph_time&lt;/code&gt; option in&amp;nbsp;&lt;em&gt;ftrace&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Tell&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;echo 0 &amp;gt; options/graph_time&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And collect profile againg&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;==&amp;gt; function0 &amp;lt;==
  Function                               Hit    Time            Avg
  --------                               ---    ----            ---
  schedule                             34129    6762529800 us     198146.1 us 
  mwait_idle                           50428    235821243 us     4676.394 us 
  mempool_free                      59292718    27764202 us     0.468 us    
  mempool_free_slab                 59292717    26628794 us     0.449 us    
  bio_endio                         49761249    24374630 us     0.489 us    

==&amp;gt; function1 &amp;lt;==
  Function                               Hit    Time            Avg
  --------                               ---    ----            ---
  schedule                            958708    9075670846 us     9466.564 us 
  mwait_idle                          406700    391923605 us     963.667 us  
  _spin_lock_irq                    22164884    15064205 us     0.679 us    
  __make_request                     3890969    14825567 us     3.810 us    
  get_page_from_freelist             7165243    14063386 us     1.962 us    &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we&amp;nbsp;see amusing &lt;code&gt;mwait_idle&lt;/code&gt; that somebody is&amp;nbsp;somehow calling. We&amp;nbsp;can’t&amp;nbsp;say how does it&amp;nbsp;happen.&lt;/p&gt;
&lt;p&gt;Maybe, we&amp;nbsp;should get a&amp;nbsp;function graph! We&amp;nbsp;know that it&amp;nbsp;all starts with &lt;code&gt;pread&lt;/code&gt; so&amp;nbsp;lets try to&amp;nbsp;trace down function calls from &lt;code&gt;pread&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;By&amp;nbsp;that moment, I&amp;nbsp;had tired to&amp;nbsp;read/write to&amp;nbsp;debugfs files and started to&amp;nbsp;use CLI interface to&amp;nbsp;&lt;em&gt;ftrace&lt;/em&gt; which is&amp;nbsp;&lt;a href="http://git.kernel.org/cgit/linux/kernel/git/rostedt/trace-cmd.git"&gt;&lt;code&gt;&lt;nobr&gt;trace-cmd&lt;/nobr&gt;&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Using &lt;code&gt;&lt;nobr&gt;trace-cmd&lt;/nobr&gt;&lt;/code&gt; is&amp;nbsp;dead simple&amp;nbsp;&amp;mdash; first, you’re&amp;nbsp;recording with &lt;code&gt;&lt;nobr&gt;trace-cmd&lt;/nobr&gt; record&lt;/code&gt; and then analyze it&amp;nbsp;with &lt;code&gt;&lt;nobr&gt;trace-cmd&lt;/nobr&gt; report&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Record:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;trace-cmd record -p function_graph -o graph_pread.dat -g sys_pread64 \
        ./block_hasher -d /dev/md127 -b 1048576 -t10 -n100&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Look:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;trace-cmd report -i graph_pread.dat | less&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And it’s&amp;nbsp;disappointing.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;block_hasher-4102  [001]  2764.516562: funcgraph_entry:                   |                  __page_cache_alloc() {
block_hasher-4102  [001]  2764.516562: funcgraph_entry:                   |                    alloc_pages_current() {
block_hasher-4102  [001]  2764.516562: funcgraph_entry:        0.052 us   |                      policy_nodemask();
block_hasher-4102  [001]  2764.516563: funcgraph_entry:        0.058 us   |                      policy_zonelist();
block_hasher-4102  [001]  2764.516563: funcgraph_entry:                   |                      __alloc_pages_nodemask() {
block_hasher-4102  [001]  2764.516564: funcgraph_entry:        0.054 us   |                        _cond_resched();
block_hasher-4102  [001]  2764.516564: funcgraph_entry:        0.063 us   |                        next_zones_zonelist();
block_hasher-4109  [000]  2764.516564: funcgraph_entry:                   |  SyS_pread64() {
block_hasher-4102  [001]  2764.516564: funcgraph_entry:                   |                        get_page_from_freelist() {
block_hasher-4109  [000]  2764.516564: funcgraph_entry:                   |    __fdget() {
block_hasher-4102  [001]  2764.516565: funcgraph_entry:        0.052 us   |                          next_zones_zonelist();
block_hasher-4109  [000]  2764.516565: funcgraph_entry:                   |      __fget_light() {
block_hasher-4109  [000]  2764.516565: funcgraph_entry:        0.217 us   |        __fget();
block_hasher-4102  [001]  2764.516565: funcgraph_entry:        0.046 us   |                          __zone_watermark_ok();
block_hasher-4102  [001]  2764.516566: funcgraph_entry:        0.057 us   |                          __mod_zone_page_state();
block_hasher-4109  [000]  2764.516566: funcgraph_exit:         0.745 us   |      }
block_hasher-4109  [000]  2764.516566: funcgraph_exit:         1.229 us   |    }
block_hasher-4102  [001]  2764.516566: funcgraph_entry:                   |                          zone_statistics() {
block_hasher-4109  [000]  2764.516566: funcgraph_entry:                   |    vfs_read() {
block_hasher-4102  [001]  2764.516566: funcgraph_entry:        0.064 us   |                            __inc_zone_state();
block_hasher-4109  [000]  2764.516566: funcgraph_entry:                   |      rw_verify_area() {
block_hasher-4109  [000]  2764.516567: funcgraph_entry:                   |        security_file_permission() {
block_hasher-4102  [001]  2764.516567: funcgraph_entry:        0.057 us   |                            __inc_zone_state();
block_hasher-4109  [000]  2764.516567: funcgraph_entry:        0.048 us   |          cap_file_permission();
block_hasher-4102  [001]  2764.516567: funcgraph_exit:         0.907 us   |                          }
block_hasher-4102  [001]  2764.516567: funcgraph_entry:        0.056 us   |                          bad_range();
block_hasher-4109  [000]  2764.516567: funcgraph_entry:        0.115 us   |          __fsnotify_parent();
block_hasher-4109  [000]  2764.516568: funcgraph_entry:        0.159 us   |          fsnotify();
block_hasher-4102  [001]  2764.516568: funcgraph_entry:                   |                          mem_cgroup_bad_page_check() {
block_hasher-4102  [001]  2764.516568: funcgraph_entry:                   |                            lookup_page_cgroup_used() {
block_hasher-4102  [001]  2764.516568: funcgraph_entry:        0.052 us   |                              lookup_page_cgroup();
block_hasher-4109  [000]  2764.516569: funcgraph_exit:         1.958 us   |        }
block_hasher-4102  [001]  2764.516569: funcgraph_exit:         0.435 us   |                            }
block_hasher-4109  [000]  2764.516569: funcgraph_exit:         2.487 us   |      }
block_hasher-4102  [001]  2764.516569: funcgraph_exit:         0.813 us   |                          }
block_hasher-4102  [001]  2764.516569: funcgraph_exit:         4.666 us   |                        }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First of&amp;nbsp;all, there is&amp;nbsp;no&amp;nbsp;straight function call chain, it’s&amp;nbsp;constantly interrupted and transfered to&amp;nbsp;another CPU. Secondly, there are a&amp;nbsp;lot of&amp;nbsp;noise e.g. &lt;code&gt;inc_zone_state&lt;/code&gt; and &lt;code&gt;__page_cache_alloc&lt;/code&gt; calls. And finally, there are neither &lt;em&gt;mdraid&lt;/em&gt; function nor &lt;code&gt;mwait_idle&lt;/code&gt; calls!&lt;/p&gt;
&lt;p&gt;And the reasons are &lt;em&gt;ftrace&lt;/em&gt; default sources (tracepoints) and async/callback nature of&amp;nbsp;kernel code. You won’t&amp;nbsp;see direct functions call chain from &lt;code&gt;sys_pread64&lt;/code&gt;, kernel doesn’t&amp;nbsp;work this way.&lt;/p&gt;
&lt;p&gt;But what if&amp;nbsp;we&amp;nbsp;setup kprobes on&amp;nbsp;mdraid functions? No&amp;nbsp;problem! Just add return probes for &lt;code&gt;mwait_idle&lt;/code&gt; and &lt;code&gt;md_make_request&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# echo &amp;#39;r:md_make_request_probe md_make_request $retval&amp;#39; &amp;gt;&amp;gt; kprobe_events 
# echo &amp;#39;r:mwait_probe mwait_idle $retval&amp;#39; &amp;gt;&amp;gt; kprobe_events&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Repeat the routine with &lt;code&gt;&lt;nobr&gt;trace-cmd&lt;/nobr&gt;&lt;/code&gt; to&amp;nbsp;get function graph:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# trace-cmd record -p function_graph -o graph_md.dat -g md_make_request -e md_make_request_probe -e mwait_probe -F \
            ./block_hasher -d /dev/md0 -b 1048576 -t10 -n100&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;-e&lt;/code&gt; enables particular event. Now, look at&amp;nbsp;function graph:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;block_hasher-28990 [000] 10235.125319: funcgraph_entry:                   |  md_make_request() {
block_hasher-28990 [000] 10235.125321: funcgraph_entry:                   |    make_request() {
block_hasher-28990 [000] 10235.125322: funcgraph_entry:        0.367 us   |      md_write_start();
block_hasher-28990 [000] 10235.125323: funcgraph_entry:                   |      bio_clone_mddev() {
block_hasher-28990 [000] 10235.125323: funcgraph_entry:                   |        bio_alloc_bioset() {
block_hasher-28990 [000] 10235.125323: funcgraph_entry:                   |          mempool_alloc() {
block_hasher-28990 [000] 10235.125323: funcgraph_entry:        0.178 us   |            _cond_resched();
block_hasher-28990 [000] 10235.125324: funcgraph_entry:                   |            mempool_alloc_slab() {
block_hasher-28990 [000] 10235.125324: funcgraph_entry:                   |              kmem_cache_alloc() {
block_hasher-28990 [000] 10235.125324: funcgraph_entry:                   |                cache_alloc_refill() {
block_hasher-28990 [000] 10235.125325: funcgraph_entry:        0.275 us   |                  _spin_lock();
block_hasher-28990 [000] 10235.125326: funcgraph_exit:         1.072 us   |                }
block_hasher-28990 [000] 10235.125326: funcgraph_exit:         1.721 us   |              }
block_hasher-28990 [000] 10235.125326: funcgraph_exit:         2.085 us   |            }
block_hasher-28990 [000] 10235.125326: funcgraph_exit:         2.865 us   |          }
block_hasher-28990 [000] 10235.125326: funcgraph_entry:        0.187 us   |          bio_init();
block_hasher-28990 [000] 10235.125327: funcgraph_exit:         3.665 us   |        }
block_hasher-28990 [000] 10235.125327: funcgraph_entry:        0.229 us   |        __bio_clone();
block_hasher-28990 [000] 10235.125327: funcgraph_exit:         4.584 us   |      }
block_hasher-28990 [000] 10235.125328: funcgraph_entry:        1.093 us   |      raid5_compute_sector();
block_hasher-28990 [000] 10235.125330: funcgraph_entry:                   |      blk_recount_segments() {
block_hasher-28990 [000] 10235.125330: funcgraph_entry:        0.340 us   |        __blk_recalc_rq_segments();
block_hasher-28990 [000] 10235.125331: funcgraph_exit:         0.769 us   |      }
block_hasher-28990 [000] 10235.125331: funcgraph_entry:        0.202 us   |      _spin_lock_irq();
block_hasher-28990 [000] 10235.125331: funcgraph_entry:        0.194 us   |      generic_make_request();
block_hasher-28990 [000] 10235.125332: funcgraph_exit:       + 10.613 us  |    }
block_hasher-28990 [000] 10235.125332: funcgraph_exit:       + 13.638 us  |  }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Much better! But for some reason it&amp;nbsp;doesn’t&amp;nbsp;have &lt;code&gt;mwait_idle&lt;/code&gt; calls. And it&amp;nbsp;just calls &lt;code&gt;generic_make_request&lt;/code&gt;. I’ve&amp;nbsp;tried and record function graph for &lt;code&gt;generic_make_request&lt;/code&gt; (&lt;code&gt;-g&lt;/code&gt; option). Still no&amp;nbsp;luck. I’ve&amp;nbsp;extracted all function containing &lt;em&gt;wait&lt;/em&gt; and here is&amp;nbsp;the result:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# grep &amp;#39;wait&amp;#39; graph_md.graph | cut -f 2 -d&amp;#39;|&amp;#39; | awk &amp;#39;{print $1}&amp;#39; | sort -n | uniq -c
     18 add_wait_queue()
   2064 bit_waitqueue()
      1 bit_waitqueue();
   1194 finish_wait()
     28 page_waitqueue()
   2033 page_waitqueue();
   1222 prepare_to_wait()
     25 remove_wait_queue()
      4 update_stats_wait_end()
    213 update_stats_wait_end();&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(&lt;code&gt;cut&lt;/code&gt; will separate function names, &lt;code&gt;awk&lt;/code&gt; will print only function names, &lt;code&gt;uniq&lt;/code&gt; with &lt;code&gt;sort&lt;/code&gt; will reduce it&amp;nbsp;to&amp;nbsp;unique names)&lt;/p&gt;
&lt;p&gt;Nothing related to&amp;nbsp;timeouts. I’ve&amp;nbsp;tried to&amp;nbsp;grep for &lt;em&gt;timeout&lt;/em&gt; and, damn, nothing suspicious.&lt;/p&gt;
&lt;p&gt;So, right now I’m&amp;nbsp;going to&amp;nbsp;stop because it’s&amp;nbsp;not going anywhere.&lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Well, it&amp;nbsp;was really fun! &lt;em&gt;ftrace&lt;/em&gt; is&amp;nbsp;such a&amp;nbsp;powerful tool but it’s&amp;nbsp;made for debugging, not profiling. I&amp;nbsp;was able to&amp;nbsp;get kernel function call graph, get statistics for kernel execution on&amp;nbsp;source code level (can you beleive it?), trace some unknown function and all that happened thanks to&amp;nbsp;&lt;em&gt;ftrace&lt;/em&gt;. Bless it!&lt;/p&gt;
&lt;h2 id="ref"&gt;To&amp;nbsp;read&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Debugging the kernel using Ftrace&amp;nbsp;&amp;mdash; &lt;a href="http://lwn.net/Articles/365835/"&gt;part 1&lt;/a&gt;, &lt;a href="http://lwn.net/Articles/366796/"&gt;part 2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://lwn.net/Articles/370423/"&gt;Secrets of&amp;nbsp;the Ftrace function tracer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://lwn.net/Articles/410200/"&gt;&lt;code&gt;&lt;nobr&gt;trace-cmd&lt;/nobr&gt;&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://lwn.net/Articles/343766/"&gt;Dynamic probes with ftrace&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://events.linuxfoundation.org/slides/lfcs2010_hiramatsu.pdf"&gt;Dynamic event tracing in&amp;nbsp;Linux kernel&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="footnotes"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn1"&gt;&lt;p&gt;This is&amp;nbsp;how debugfs mounted: &lt;code&gt;mount -t debugfs none /sys/kernel/debug&lt;/code&gt;&lt;a href="#fnref1"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content>
  </entry>
  <entry xml:base="http://alex.dzyoba.com/feed">
    <title type="text">Linux profiling. Kernel</title>
    <id>linux/profiling-kernel.html</id>
    <updated>2014-05-12T00:00:00Z</updated>
    <link href="linux/profiling-kernel.html" />
    <author>
      <name>Alex Dzyoba</name>
    </author>
    <content type="html">&lt;p&gt;TOC:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;&lt;a href="/linux/profiling-intro.html"&gt;Intro&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/linux/profiling-gprof-gcov.html"&gt;Userspace profiling: gprof, gcov&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/linux/profiling-valgrind.html"&gt;Userspace profiling: Valgrind&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Kernel profiling: Intro&lt;/li&gt;
&lt;li&gt;&lt;a href="/linux/profiling-ftrace.html"&gt;Kernel profiling: ftrace&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/linux/profiling-perf.html"&gt;Kernel profiling: perf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/linux/profiling-systemtap.html"&gt;Kernel profiling: SystemTap&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Various tools&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Quick reminder. I’m&amp;nbsp;trying to&amp;nbsp;understand why my&amp;nbsp;nice little program is&amp;nbsp;reading from RAID so&amp;nbsp;slow. I’m&amp;nbsp;using various profiling tools to&amp;nbsp;inspect my&amp;nbsp;&lt;code&gt;block_hasher&lt;/code&gt; and get a&amp;nbsp;&lt;nobr&gt;hands-on&lt;/nobr&gt; experience with profilers.&lt;/p&gt;
&lt;p&gt;So, we&amp;nbsp;reviewed userspace profiling and arrived to&amp;nbsp;main theme of&amp;nbsp;my&amp;nbsp;article series which is&amp;nbsp;kernel profiling: tools, profilers, facilities and methods of&amp;nbsp;profiling.&lt;/p&gt;
&lt;p&gt;In&amp;nbsp;this article I’ll&amp;nbsp;tell you about facilities that kernel provides to&amp;nbsp;profile it.&lt;/p&gt;
&lt;h2 id="intro"&gt;Intro&lt;/h2&gt;
&lt;p&gt;Sometimes when you’re&amp;nbsp;facing really hard performance problem it’s&amp;nbsp;not always enough to&amp;nbsp;profile your applicatiion. As&amp;nbsp;we&amp;nbsp;saw while profiling our application with &lt;a href="/linux/profiling-intro.html"&gt;gprof, gcov&lt;/a&gt; and &lt;a href="/linux/profiling-valgrind.html"&gt;Valgrind&lt;/a&gt; problem is&amp;nbsp;somewhere underneath our application&amp;nbsp;&amp;mdash; something is&amp;nbsp;holding &lt;code&gt;pread&lt;/code&gt; in&amp;nbsp;long I/O wait cycles.&lt;/p&gt;
&lt;p&gt;How to&amp;nbsp;trace system call is&amp;nbsp;not clear at&amp;nbsp;first sight&amp;nbsp;&amp;mdash; there are various kernel profilers, all of&amp;nbsp;them works in&amp;nbsp;it’s&amp;nbsp;own way, requires unique configuration, methods, analyzis and so&amp;nbsp;on. Yes, it’s&amp;nbsp;really hard to&amp;nbsp;figure it&amp;nbsp;out. Being the biggest &lt;nobr&gt;open-source&lt;/nobr&gt; project developed by&amp;nbsp;massive community, Linux absorbed several different and sometimes conflicting profiling facilities. And it’s&amp;nbsp;in&amp;nbsp;some sense getting even worse&amp;nbsp;&amp;mdash; while some profiles tend to&amp;nbsp;merge (&lt;em&gt;ftrace&lt;/em&gt; and &lt;em&gt;perf&lt;/em&gt;) other tools emerge&amp;nbsp;&amp;mdash; last example is&amp;nbsp;&lt;em&gt;ktap&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;To&amp;nbsp;undertand that &lt;a href="https://en.wikipedia.org/wiki/The_Cathedral_and_the_Bazaar"&gt;bazaar&lt;/a&gt; lets start from the bottom&amp;nbsp;&amp;mdash; what does kernel have that makes it&amp;nbsp;able profile it? Basically there are only 3 kernel facilities that enable profiling:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Kernel tracepoints&lt;/li&gt;
&lt;li&gt;Kernel probes&lt;/li&gt;
&lt;li&gt;Perf events&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It’s&amp;nbsp;features that gives us&amp;nbsp;access to&amp;nbsp;kernel internals. By&amp;nbsp;using them we&amp;nbsp;can measure kernel functions execution, trace access to&amp;nbsp;devices, analyze CPU states and so&amp;nbsp;on.&lt;/p&gt;
&lt;p&gt;This very features are really awkward for direct use and accessible only from kernel. Well, if&amp;nbsp;you really want you can write your own Linux kernel module that will utilize these facilities for your custom use, but it’s&amp;nbsp;pretty much pointless. That’s&amp;nbsp;why people have created a&amp;nbsp;few really good general purpose profilers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ftrace&lt;/li&gt;
&lt;li&gt;perf&lt;/li&gt;
&lt;li&gt;SystemTap&lt;/li&gt;
&lt;li&gt;ktap&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All of&amp;nbsp;them are based on&amp;nbsp;that features and will be&amp;nbsp;discussed later more thoroughly, but now let’s&amp;nbsp;review features itself.&lt;/p&gt;
&lt;h2 id="kernel-tracepoints"&gt;Kernel tracepoints&lt;/h2&gt;
&lt;p&gt;Kernel Tracepoints&amp;nbsp;&amp;mdash; it’s&amp;nbsp;framework for tracing kernel function via static instrumenting&lt;a href="#fn1" class="footnoteRef" id="fnref1"&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Tracepoint&amp;nbsp;&amp;mdash; it’s&amp;nbsp;a&amp;nbsp;place in&amp;nbsp;code where you can bind your callback. &lt;em&gt;Tracepoints&lt;/em&gt; can be&amp;nbsp;disabled (no&amp;nbsp;callback) and enabled (has callback). There might be&amp;nbsp;several callbacks though it’s&amp;nbsp;still lightweight&amp;nbsp;&amp;mdash; when callback disabled it’s&amp;nbsp;actually looks like &lt;code&gt;if&amp;nbsp;(unlikely(tracepoint.enabled))&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Tracepoint&lt;/em&gt; output is&amp;nbsp;written in&amp;nbsp;ring buffer that is&amp;nbsp;export through &lt;em&gt;debugfs&lt;/em&gt; at&amp;nbsp;&lt;code&gt;/sys/kernel/debug/tracing/trace&lt;/code&gt;. There are also whole tree of&amp;nbsp;traceable events at&amp;nbsp;&lt;code&gt;/sys/kernel/debug/tracing/events&lt;/code&gt; that exports control files to&amp;nbsp;enable/disable particular event.&lt;/p&gt;
&lt;p&gt;Despite of&amp;nbsp;it’s&amp;nbsp;name &lt;em&gt;tracepoints&lt;/em&gt; are base for &lt;nobr&gt;event-based&lt;/nobr&gt; profiling because besides traceing you can do&amp;nbsp;anything in&amp;nbsp;callback, e.g. timestamping and measuring resource usage. Linux kernel is&amp;nbsp;already (since &lt;nobr&gt;2.6.28&lt;/nobr&gt;) instrumented with that tracepoints in&amp;nbsp;many places. For example, &lt;a href="http://lxr.free-electrons.com/source/mm/slab.c?v=3.12#L3714"&gt;&lt;code&gt;__do_kmalloc&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;pre class="sourceCode c"&gt;&lt;code class="sourceCode c"&gt;&lt;span class="co"&gt;/**&lt;/span&gt;
&lt;span class="co"&gt; * __do_kmalloc - allocate memory&lt;/span&gt;
&lt;span class="co"&gt; * &lt;/span&gt;@size:&lt;span class="co"&gt; how many bytes of memory are required.&lt;/span&gt;
&lt;span class="co"&gt; * &lt;/span&gt;@flags:&lt;span class="co"&gt; the type of memory to allocate (see kmalloc).&lt;/span&gt;
&lt;span class="co"&gt; * &lt;/span&gt;@caller:&lt;span class="co"&gt; function caller for debug tracking of the caller&lt;/span&gt;
&lt;span class="co"&gt; */&lt;/span&gt;
&lt;span class="dt"&gt;static&lt;/span&gt; __always_inline &lt;span class="dt"&gt;void&lt;/span&gt; *__do_kmalloc(size_t size, gfp_t flags,
                                          &lt;span class="dt"&gt;unsigned&lt;/span&gt; &lt;span class="dt"&gt;long&lt;/span&gt; caller)
{
        &lt;span class="kw"&gt;struct&lt;/span&gt; kmem_cache *cachep;
        &lt;span class="dt"&gt;void&lt;/span&gt; *ret;

        &lt;span class="co"&gt;/* If you want to save a few bytes .text space: replace&lt;/span&gt;
&lt;span class="co"&gt;         * __ with kmem_.&lt;/span&gt;
&lt;span class="co"&gt;         * Then kmalloc uses the uninlined functions instead of the inline&lt;/span&gt;
&lt;span class="co"&gt;         * functions.&lt;/span&gt;
&lt;span class="co"&gt;         */&lt;/span&gt;
        cachep = kmalloc_slab(size, flags);
        &lt;span class="kw"&gt;if&lt;/span&gt; (unlikely(ZERO_OR_NULL_PTR(cachep)))
                &lt;span class="kw"&gt;return&lt;/span&gt; cachep;
        ret = slab_alloc(cachep, flags, caller);

        trace_kmalloc(caller, ret,
                      size, cachep-&amp;gt;size, flags);

        &lt;span class="kw"&gt;return&lt;/span&gt; ret;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;trace_kmalloc&lt;/code&gt; is&amp;nbsp;&lt;em&gt;tracepoint&lt;/em&gt;. There are many others in&amp;nbsp;other critical parts of&amp;nbsp;kernel such as&amp;nbsp;schedulers, block I/O, networking and even interrupt handlers. All of&amp;nbsp;them are used by&amp;nbsp;most profilers because they have minimal overhead, fires by&amp;nbsp;event and saves you from modifying kernel.&lt;/p&gt;
&lt;p&gt;Ok, so&amp;nbsp;by&amp;nbsp;now you may be&amp;nbsp;eager to&amp;nbsp;insert in&amp;nbsp;all of&amp;nbsp;your kernel modules and profile it&amp;nbsp;to&amp;nbsp;hell, but BEWARE. If&amp;nbsp;you want to&amp;nbsp;add &lt;em&gt;tracepoints&lt;/em&gt; you must have a&amp;nbsp;lot of&amp;nbsp;patience and skills because writing your own tracepoints is&amp;nbsp;really ugly and awkward. You can see examples at&amp;nbsp;&lt;a href="http://lxr.free-electrons.com/source/samples/trace_events/?v=3.13"&gt;&lt;em&gt;samples/trace_events/&lt;/em&gt;&lt;/a&gt;. Under the hood &lt;em&gt;tracepoints&lt;/em&gt; are C&amp;nbsp;macros black magic that only bold and fearless persons could understand.&lt;/p&gt;
&lt;p&gt;And even if&amp;nbsp;you do&amp;nbsp;all that crazy macro declarations and struct definitions it&amp;nbsp;might just simply not work at&amp;nbsp;all if&amp;nbsp;you have &lt;code&gt;CONFIG_MODULE_SIG=y&lt;/code&gt; and don’t&amp;nbsp;sign module. It&amp;nbsp;might seem kinda strange configuration but in&amp;nbsp;reality it’s&amp;nbsp;a&amp;nbsp;default for all major distributions including Fedora and Ubuntu. That said, after 9 circles of&amp;nbsp;hell, you will end up&amp;nbsp;with nothing.&lt;/p&gt;
&lt;p&gt;So, just remember:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;USE ONLY EXISTING TRACEPOINTS IN&amp;nbsp;KERNEL, DO&amp;nbsp;NOT CREATE YOUR OWN.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Now I’m&amp;nbsp;gonna explain why it’s&amp;nbsp;happening. So&amp;nbsp;if&amp;nbsp;you tired of&amp;nbsp;&lt;em&gt;tracepoints&lt;/em&gt; just skip to&amp;nbsp;read about &lt;a href="#kprobes"&gt;&lt;em&gt;kprobes&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Ok, so&amp;nbsp;some time ago while preparing kernel 3.1&lt;a href="#fn2" class="footnoteRef" id="fnref2"&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; these code was added:&lt;/p&gt;
&lt;pre class="sourceCode c"&gt;&lt;code class="sourceCode c"&gt;&lt;span class="dt"&gt;static&lt;/span&gt; &lt;span class="dt"&gt;int&lt;/span&gt; tracepoint_module_coming(&lt;span class="kw"&gt;struct&lt;/span&gt; module *mod)
{
          &lt;span class="kw"&gt;struct&lt;/span&gt; tp_module *tp_mod, *iter;
          &lt;span class="dt"&gt;int&lt;/span&gt; ret = &lt;span class="dv"&gt;0&lt;/span&gt;;

          &lt;span class="co"&gt;/*&lt;/span&gt;
&lt;span class="co"&gt;           * We skip modules that tain the kernel, especially those with different&lt;/span&gt;
&lt;span class="co"&gt;           * module header (for forced load), to make sure we don&amp;#39;t cause a crash.&lt;/span&gt;
&lt;span class="co"&gt;           */&lt;/span&gt;
          &lt;span class="kw"&gt;if&lt;/span&gt; (mod-&amp;gt;taints)
                  &lt;span class="kw"&gt;return&lt;/span&gt; &lt;span class="dv"&gt;0&lt;/span&gt;;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If&amp;nbsp;module is&amp;nbsp;tainted we&amp;nbsp;will NOT write ANY tracepoints. Later it&amp;nbsp;became more adequate&lt;/p&gt;
&lt;pre class="sourceCode c"&gt;&lt;code class="sourceCode c"&gt;&lt;span class="co"&gt;/*&lt;/span&gt;
&lt;span class="co"&gt; * We skip modules that taint the kernel, especially those with different&lt;/span&gt;
&lt;span class="co"&gt; * module headers (for forced load), to make sure we don&amp;#39;t cause a crash.&lt;/span&gt;
&lt;span class="co"&gt; * Staging and out-of-tree GPL modules are fine.&lt;/span&gt;
&lt;span class="co"&gt; */&lt;/span&gt;
&lt;span class="kw"&gt;if&lt;/span&gt; (mod-&amp;gt;taints &amp;amp; ~((&lt;span class="dv"&gt;1&lt;/span&gt; &amp;lt;&amp;lt; TAINT_OOT_MODULE) | (&lt;span class="dv"&gt;1&lt;/span&gt; &amp;lt;&amp;lt; TAINT_CRAP)))
        &lt;span class="kw"&gt;return&lt;/span&gt; &lt;span class="dv"&gt;0&lt;/span&gt;;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Like, ok&amp;nbsp;it&amp;nbsp;may be&amp;nbsp;&lt;nobr&gt;out-of-tree&lt;/nobr&gt; (&lt;code&gt;TAINT_OOT_MODULE&lt;/code&gt;) or&amp;nbsp;staginig(&lt;code&gt;TAINT_CRAP&lt;/code&gt;) but any others are &lt;nobr&gt;no-no&lt;/nobr&gt;.&lt;/p&gt;
&lt;p&gt;Seems legit, right? Now what whould you think will be&amp;nbsp;if&amp;nbsp;your kernel is&amp;nbsp;compiled with &lt;code&gt;CONFIG_MODULE_SIG&lt;/code&gt; enabled and your pretty module is&amp;nbsp;not signed? Well, module loader will set &lt;code&gt;TAINT_FORCES_MODULE&lt;/code&gt; flag for it. And now your pretty module will never pass the condition in&amp;nbsp;&lt;code&gt;tracepoint_module_coming&lt;/code&gt; and never show you any tracepoints output. And as&amp;nbsp;I&amp;nbsp;said earlier this stupid option is&amp;nbsp;set for all major distributions including Fedora and Ubuntu since kernel version 3.1.&lt;/p&gt;
&lt;p&gt;If&amp;nbsp;you think&amp;nbsp;&amp;mdash; &amp;laquo;Well, lets sign goddamn module!&amp;raquo;&amp;nbsp;&amp;mdash; you’re&amp;nbsp;wrong. Modules must be&amp;nbsp;signed with kernel &lt;strong&gt;private&lt;/strong&gt; key that are held by&amp;nbsp;your Linux distro vendor and, of&amp;nbsp;course, not available for you.&lt;/p&gt;
&lt;p&gt;The whole terrifying story is&amp;nbsp;available in&amp;nbsp;lkml &lt;a href="https://lkml.org/lkml/2014/2/13/488"&gt;1&lt;/a&gt;, &lt;a href="https://lkml.org/lkml/2014/3/4/925"&gt;2&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As&amp;nbsp;for me&amp;nbsp;I&amp;nbsp;just cite my&amp;nbsp;favorite thing from Steven Rostedt (ftrace maintainer and one of&amp;nbsp;the tracepoints developer):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; OK, this IS a major bug and needs to be fixed. This explains a couple
&amp;gt; of reports I received about tracepoints not working, and I never
&amp;gt; figured out why. Basically, they even did this:
&amp;gt; 
&amp;gt; 
&amp;gt;    trace_printk(&amp;quot;before tracepoint\n&amp;quot;);
&amp;gt;    trace_some_trace_point();
&amp;gt;    trace_printk(&amp;quot;after tracepoint\n&amp;quot;);
&amp;gt;
&amp;gt; Enabled the tracepoint (it shows up as enabled and working in the
&amp;gt; tools, but not the trace), but in the trace they would get:
&amp;gt;
&amp;gt;    before tracepoint
&amp;gt;    after tracepoint
&amp;gt;
&amp;gt; and never get the actual tracepoint. But as they were debugging
&amp;gt; something else, it was just thought that this was their bug. But it
&amp;gt; baffled me to why that tracepoint wasn&amp;#39;t working even though nothing in
&amp;gt; the dmesg had any errors about tracepoints.
&amp;gt; 
&amp;gt; Well, this now explains it. If you compile a kernel with the following
&amp;gt; options:
&amp;gt; 
&amp;gt; CONFIG_MODULE_SIG=y
&amp;gt; # CONFIG_MODULE_SIG_FORCE is not set
&amp;gt; # CONFIG_MODULE_SIG_ALL is not set
&amp;gt; 
&amp;gt; You now just disabled (silently) all tracepoints in modules. WITH NO
&amp;gt; FREAKING ERROR MESSAGE!!!
&amp;gt; 
&amp;gt; The tracepoints will show up in /sys/kernel/debug/tracing/events, they
&amp;gt; will show up in perf list, you can enable them in either perf or the
&amp;gt; debugfs, but they will never actually be executed. You will just get
&amp;gt; silence even though everything appeared to be working just fine.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Recap:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Kernel tracepoints is&amp;nbsp;a&amp;nbsp;lightweight tracing and profiling facility.&lt;/li&gt;
&lt;li&gt;Linux kernel is&amp;nbsp;heavy instrumented with &lt;em&gt;tracepoints&lt;/em&gt; that are used by&amp;nbsp;the most profilers and especially by&amp;nbsp;&lt;em&gt;perf&lt;/em&gt; and &lt;em&gt;ftrace&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Tracepoints are C&amp;nbsp;marcos black magic and almost impossible for usage in&amp;nbsp;kernel modules.&lt;/li&gt;
&lt;li&gt;It&amp;nbsp;will NOT work in&amp;nbsp;your LKM if:
&lt;ul&gt;
&lt;li&gt;Kernel version &amp;gt;=3.1 (might be&amp;nbsp;fixed in&amp;nbsp;3.15)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;CONFIG_MODULE_SIG=y&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Your module is&amp;nbsp;not signed with kernel private key.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="kprobes"&gt;Kernel probes&lt;/h2&gt;
&lt;p&gt;Kernel probes is&amp;nbsp;a&amp;nbsp;dynamic debugging and profiling mechanism that allows you to&amp;nbsp;break into kernel code, invoke your custom function called &lt;strong&gt;probe&lt;/strong&gt; and return everything back.&lt;/p&gt;
&lt;p&gt;Basically its done by&amp;nbsp;writing kernel module where you register handler for some address or&amp;nbsp;symbol in&amp;nbsp;kernel code. Also according to&amp;nbsp;&lt;a href="http://lxr.free-electrons.com/source/include/linux/kprobes.h?v=3.13#L73"&gt;definition of&amp;nbsp;&lt;code&gt;struct kprobe&lt;/code&gt;&lt;/a&gt; you can pass offset from address but I’m&amp;nbsp;not sure about that. In&amp;nbsp;your registered handler you can do&amp;nbsp;really anything&amp;nbsp;&amp;mdash; write to&amp;nbsp;log, to&amp;nbsp;some buffer exported via sysfs, measure time and infinite amount of&amp;nbsp;possibilities to&amp;nbsp;do. And that’s&amp;nbsp;really nifty contrary to&amp;nbsp;&lt;em&gt;tracepoints&lt;/em&gt; where you can only read logs from debugfs.&lt;/p&gt;
&lt;p&gt;There are 3 types of&amp;nbsp;probes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;kprobes&lt;/em&gt;&amp;nbsp;&amp;mdash; basic probe that allows you to&amp;nbsp;break into any kernel address.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;jprobes&lt;/em&gt;&amp;nbsp;&amp;mdash; jump probes that inserted in&amp;nbsp;the start of&amp;nbsp;function and gives you handy access to&amp;nbsp;function arguments; it’s&amp;nbsp;something like &lt;nobr&gt;proxy-function&lt;/nobr&gt;.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;kretprobes&lt;/em&gt;&amp;nbsp;&amp;mdash; return probes that inserted in&amp;nbsp;the return point of&amp;nbsp;function.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Last 2 types are based on&amp;nbsp;basic &lt;em&gt;kprobes&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;All of&amp;nbsp;this generally works like this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We&amp;nbsp;register probe on&amp;nbsp;some address A.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;kprobe&lt;/em&gt; subsystem finds A.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;kprobe&lt;/em&gt; copies instruction at&amp;nbsp;address A.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;kprobe&lt;/em&gt; replaces instruction at&amp;nbsp;A&amp;nbsp;for breakpoint (&lt;code&gt;int 3&lt;/code&gt; in&amp;nbsp;case of&amp;nbsp;x86).&lt;/li&gt;
&lt;li&gt;Now when execution hits probed address A, CPU trap occurs.&lt;/li&gt;
&lt;li&gt;Registers are saved.&lt;/li&gt;
&lt;li&gt;CPU transfers control to&amp;nbsp;&lt;em&gt;kprobes&lt;/em&gt; via &lt;code&gt;notifier_call_chain&lt;/code&gt; mechanism.&lt;/li&gt;
&lt;li&gt;And finally &lt;em&gt;kprobes&lt;/em&gt; invokes our handler.&lt;/li&gt;
&lt;li&gt;After all we&amp;nbsp;restore registers, copies back instruction at&amp;nbsp;A&amp;nbsp;and continues execution.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Our handler usually gets as&amp;nbsp;an&amp;nbsp;argument adress where breakpoint happened and registers values in&amp;nbsp;&lt;code&gt;pt_args&lt;/code&gt; structures. &lt;em&gt;kprobes&lt;/em&gt; handler prototype:&lt;/p&gt;
&lt;pre class="sourceCode c"&gt;&lt;code class="sourceCode c"&gt;    &lt;span class="kw"&gt;typedef&lt;/span&gt; &lt;span class="dt"&gt;int&lt;/span&gt; (*kprobe_break_handler_t) (&lt;span class="kw"&gt;struct&lt;/span&gt; kprobe *, &lt;span class="kw"&gt;struct&lt;/span&gt; pt_regs *);&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In&amp;nbsp;most cases except debugging this info is&amp;nbsp;useless because we&amp;nbsp;have &lt;em&gt;jprobes&lt;/em&gt;. &lt;em&gt;jprobes&lt;/em&gt; handler has exactly the same prototype as&amp;nbsp;and intercepting function. For example, this is&amp;nbsp;handler for &lt;code&gt;do_fork&lt;/code&gt;:&lt;/p&gt;
&lt;pre class="sourceCode c"&gt;&lt;code class="sourceCode c"&gt;    &lt;span class="co"&gt;/* Proxy routine having the same arguments as actual do_fork() routine */&lt;/span&gt;
    &lt;span class="dt"&gt;static&lt;/span&gt; &lt;span class="dt"&gt;long&lt;/span&gt; jdo_fork(&lt;span class="dt"&gt;unsigned&lt;/span&gt; &lt;span class="dt"&gt;long&lt;/span&gt; clone_flags, &lt;span class="dt"&gt;unsigned&lt;/span&gt; &lt;span class="dt"&gt;long&lt;/span&gt; stack_start,
              &lt;span class="kw"&gt;struct&lt;/span&gt; pt_regs *regs, &lt;span class="dt"&gt;unsigned&lt;/span&gt; &lt;span class="dt"&gt;long&lt;/span&gt; stack_size,
              &lt;span class="dt"&gt;int&lt;/span&gt; __user *parent_tidptr, &lt;span class="dt"&gt;int&lt;/span&gt; __user *child_tidptr)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Also &lt;em&gt;jprobes&lt;/em&gt; doesn’t&amp;nbsp;causes interrupts because it&amp;nbsp;works with help of&amp;nbsp;&lt;code&gt;setjmp/longjmp&lt;/code&gt; that are much more lightweight.&lt;/p&gt;
&lt;p&gt;And finally the most convenient tool for profiling are &lt;em&gt;kretprobes&lt;/em&gt;. It&amp;nbsp;allows you to&amp;nbsp;register 2 handlers&amp;nbsp;&amp;mdash; one to&amp;nbsp;invoke on&amp;nbsp;function start and the other to&amp;nbsp;invoke in&amp;nbsp;the end. But really cool feature is&amp;nbsp;that it&amp;nbsp;allows you to&amp;nbsp;save state between those 2 calls, like timestamp or&amp;nbsp;counters.&lt;/p&gt;
&lt;p&gt;Instead of&amp;nbsp;thousand words&amp;nbsp;&amp;mdash; look at&amp;nbsp;absolutely astonishing samples at&amp;nbsp;&lt;a href="http://lxr.free-electrons.com/source/samples/kprobes/?v=3.13"&gt;&lt;em&gt;samples/kprobes&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Recap:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;kprobes&lt;/em&gt; is&amp;nbsp;a&amp;nbsp;beatiful hack for dynamic debugging, tracing and profiling.&lt;/li&gt;
&lt;li&gt;It’s&amp;nbsp;a&amp;nbsp;fundamental kernel feature for &lt;nobr&gt;non-invasive&lt;/nobr&gt; profiling.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="perf-events"&gt;Perf events&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;perf_events&lt;/em&gt; is&amp;nbsp;an&amp;nbsp;interface for hardware metrics implemented in&amp;nbsp;PMU (Performance Monitoring Unit) which is&amp;nbsp;part of&amp;nbsp;CPU.&lt;/p&gt;
&lt;p&gt;Thanks to&amp;nbsp;&lt;em&gt;perf_events&lt;/em&gt; you can easily ask kernel to&amp;nbsp;show you L1 cache misses count regardless of&amp;nbsp;what architecture you are on&amp;nbsp;&amp;mdash; x86 or&amp;nbsp;ARM. What CPUs are supported by&amp;nbsp;perf are listed &lt;a href="http://web.eece.maine.edu/~vweaver/projects/perf_events/support.html"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In&amp;nbsp;addition to&amp;nbsp;that perf included various kernel metrics like software context swithes count (&lt;code&gt;PERF_COUNT_SW_CONTEXT_SWITCHES&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;And in&amp;nbsp;addition to&amp;nbsp;that perf included &lt;em&gt;tracepoint&lt;/em&gt; support via &lt;code&gt;ftrace&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;To&amp;nbsp;access &lt;em&gt;perf_events&lt;/em&gt; there is&amp;nbsp;a&amp;nbsp;special syscall &lt;a href="http://web.eece.maine.edu/~vweaver/projects/perf_events/perf_event_open.html"&gt;&lt;code&gt;perf_event_open&lt;/code&gt;&lt;/a&gt;. You are passing the type of&amp;nbsp;event (hardware, kernel, tracepoint) and so&amp;nbsp;called config, where you specifies what exactly you want depending on&amp;nbsp;type. It’s&amp;nbsp;gonna be&amp;nbsp;function name in&amp;nbsp;case of&amp;nbsp;tracepoint, some CPU metric in&amp;nbsp;case of&amp;nbsp;hardware and so&amp;nbsp;on.&lt;/p&gt;
&lt;p&gt;And on&amp;nbsp;top of&amp;nbsp;that there are a&amp;nbsp;whole lot of&amp;nbsp;stuff like event groups, filters, sampling, various output formats and others. And all of&amp;nbsp;that are &lt;a href="http://web.eece.maine.edu/~vweaver/projects/perf_events/abi_breakage.html"&gt;constantly breaking&lt;/a&gt;&lt;a href="#fn3" class="footnoteRef" id="fnref3"&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;, that’s&amp;nbsp;why the only thing you can ask for perf_events is&amp;nbsp;special &lt;code&gt;perf&lt;/code&gt; utility&amp;nbsp;&amp;mdash; the only userspace utility that is&amp;nbsp;a&amp;nbsp;part of&amp;nbsp;kernel tree.&lt;/p&gt;
&lt;p&gt;_perf_events and all things related to&amp;nbsp;it&amp;nbsp;spreads as&amp;nbsp;a&amp;nbsp;plague in&amp;nbsp;kernel and now &lt;code&gt;ftrace&lt;/code&gt; is&amp;nbsp;going to&amp;nbsp;be&amp;nbsp;part of&amp;nbsp;&lt;code&gt;perf&lt;/code&gt; (&lt;a href="http://thread.gmane.org/gmane.linux.kernel/1136520"&gt;1&lt;/a&gt;, &lt;a href="https://lkml.org/lkml/2013/10/16/15"&gt;2&lt;/a&gt;). Some people overreacting on&amp;nbsp;&lt;em&gt;perf&lt;/em&gt; related things though it’s&amp;nbsp;useless because &lt;em&gt;perf&lt;/em&gt; is&amp;nbsp;developed by&amp;nbsp;kernel big fishes&amp;nbsp;&amp;mdash; Info Molnar&lt;a href="#fn4" class="footnoteRef" id="fnref4"&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt; and Peter Zijlstra.&lt;/p&gt;
&lt;p&gt;I&amp;nbsp;really can’t&amp;nbsp;tell anything more about &lt;em&gt;perf_events&lt;/em&gt; in&amp;nbsp;isolation of&amp;nbsp;&lt;code&gt;perf&lt;/code&gt;, so&amp;nbsp;here I&amp;nbsp;finish.&lt;/p&gt;
&lt;h2 id="summary"&gt;Summary&lt;/h2&gt;
&lt;p&gt;There are a&amp;nbsp;few Linux kernel features that enables profiling:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;&lt;em&gt;tracepoints&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;kprobes&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;perf_events&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;All Linux kernel profilers uses combinations of&amp;nbsp;that features, read details in&amp;nbsp;article for particular profiler.&lt;/p&gt;
&lt;h2 id="to-read"&gt;To&amp;nbsp;read&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://events.linuxfoundation.org/sites/events/files/slides/kernel_profiling_debugging_tools_0.pdf" class="uri"&gt;https://events.linuxfoundation.org/sites/events/files/slides/kernel_profiling_debugging_tools_0.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://events.linuxfoundation.org/sites/events/files/lcjp13_zannoni.pdf" class="uri"&gt;http://events.linuxfoundation.org/sites/events/files/lcjp13_zannoni.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;tracepoints&lt;/em&gt;: &lt;ul&gt;
&lt;li&gt;&lt;a href="http://lxr.free-electrons.com/source/Documentation/trace/tracepoints.txt?v=3.13"&gt;Documentation/trace/tracepoints.txt&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://lttng.org/files/thesis/desnoyers-dissertation-2009-12-v27.pdf" class="uri"&gt;http://lttng.org/files/thesis/desnoyers-dissertation-&lt;nobr&gt;2009-12-v27&lt;/nobr&gt;.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://lwn.net/Articles/379903/" class="uri"&gt;http://lwn.net/Articles/379903/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://lwn.net/Articles/381064/" class="uri"&gt;http://lwn.net/Articles/381064/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://lwn.net/Articles/383362/" class="uri"&gt;http://lwn.net/Articles/383362/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;kprobes&lt;/em&gt;: &lt;ul&gt;
&lt;li&gt;&lt;a href="http://lxr.free-electrons.com/source/Documentation/kprobes.txt?v=3.13"&gt;Documentation/kprobes.txt&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://lwn.net/Articles/132196/" class="uri"&gt;https://lwn.net/Articles/132196/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;perf_events&lt;/em&gt;: &lt;ul&gt;
&lt;li&gt;&lt;a href="http://web.eece.maine.edu/~vweaver/projects/perf_events/" class="uri"&gt;http://web.eece.maine.edu/~vweaver/projects/perf_events/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://lwn.net/Articles/441209/" class="uri"&gt;https://lwn.net/Articles/441209/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="footnotes"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn1"&gt;&lt;p&gt;Tracepoints are improvement of&amp;nbsp;early feature called kernel markers.&lt;a href="#fnref1"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn2"&gt;&lt;p&gt;Namely in&amp;nbsp;commit &lt;a href="https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=b75ef8b44b1cb95f5a26484b0e2fe37a63b12b44"&gt;b75ef8b44b1cb95f5a26484b0e2fe37a63b12b44&lt;/a&gt;&lt;a href="#fnref2"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn3"&gt;&lt;p&gt;And that’s&amp;nbsp;indended behaviour. Kernel &lt;strong&gt;ABI&lt;/strong&gt; in&amp;nbsp;no&amp;nbsp;sense stable, &lt;acronym title="Application programming interface" lang="en"&gt;API&lt;/acronym&gt; is.&lt;a href="#fnref3"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn4"&gt;&lt;p&gt;Author of&amp;nbsp;current default O(1) process scheduler CFS&amp;nbsp;&amp;mdash; Completely Fair Scheduler.&lt;a href="#fnref4"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content>
  </entry>
  <entry xml:base="http://alex.dzyoba.com/feed">
    <title type="text">Profiling in Linux. Valgrind</title>
    <id>linux/profiling-valgrind.html</id>
    <updated>2014-03-15T00:00:00Z</updated>
    <link href="linux/profiling-valgrind.html" />
    <author>
      <name>Alex Dzyoba</name>
    </author>
    <content type="html">&lt;p&gt;TOC:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;&lt;a href="/linux/profiling-intro.html"&gt;Intro&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/linux/profiling-gprof-gcov.html"&gt;Userspace profiling: gprof, gcov&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Userspace profiling: Valgrind&lt;/li&gt;
&lt;li&gt;&lt;a href="/linux/profiling-kernel.html"&gt;Kernel profiling: Intro&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/linux/profiling-ftrace.html"&gt;Kernel profiling: ftrace&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/linux/profiling-perf.html"&gt;Kernel profiling: perf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/linux/profiling-systemtap.html"&gt;Kernel profiling: SystemTap&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Various tools&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Quick reminder. I’m&amp;nbsp;trying to&amp;nbsp;understand why my&amp;nbsp;nice little program is&amp;nbsp;doing reading from RAID so&amp;nbsp;slow. I’m&amp;nbsp;using various profiling tools to&amp;nbsp;inspect my&amp;nbsp;&lt;code&gt;block_hasher&lt;/code&gt; and get a&amp;nbsp;&lt;nobr&gt;hands-on&lt;/nobr&gt; experience with profilers.&lt;/p&gt;
&lt;h2 id="valgrind"&gt;Valgrind&lt;/h2&gt;
&lt;p&gt;Countrary to&amp;nbsp;popular belief, _Valgrind is&amp;nbsp;not a&amp;nbsp;single tool, but a&amp;nbsp;suite of&amp;nbsp;such tools, with &lt;em&gt;Memcheck&lt;/em&gt; as&amp;nbsp;default. By&amp;nbsp;the time of&amp;nbsp;writing &lt;em&gt;Valgrind&lt;/em&gt; consists of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Memcheck&amp;nbsp;&amp;mdash; memory management errors detection.&lt;/li&gt;
&lt;li&gt;Cachegrind&amp;nbsp;&amp;mdash; CPU cache access profiling tool.&lt;/li&gt;
&lt;li&gt;Massif&amp;nbsp;&amp;mdash; sampling heap profiler.&lt;/li&gt;
&lt;li&gt;Helgrind&amp;nbsp;&amp;mdash; race condition detector.&lt;/li&gt;
&lt;li&gt;DRD&amp;nbsp;&amp;mdash; tool to&amp;nbsp;detect error in&amp;nbsp;multithreading applications.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Plus there are unofficial tools not included in&amp;nbsp;&lt;em&gt;Valgrind&lt;/em&gt; and distributed as&amp;nbsp;&lt;a href="http://valgrind.org/downloads/variants.html"&gt;patches&lt;/a&gt; .&lt;/p&gt;
&lt;p&gt;Despite some of&amp;nbsp;the tools are not profilers per se&amp;nbsp;(e.g. &lt;em&gt;Memcheck&lt;/em&gt; is&amp;nbsp;more like debugger) I&amp;nbsp;will use all of&amp;nbsp;them just because it’s&amp;nbsp;incredibly useful for every single programmer.&lt;/p&gt;
&lt;p&gt;We&amp;nbsp;don’t&amp;nbsp;need to&amp;nbsp;recompile or&amp;nbsp;modify our program in&amp;nbsp;any way because &lt;em&gt;Valgrind&lt;/em&gt; tools use emulation as&amp;nbsp;a&amp;nbsp;method of&amp;nbsp;profiling. All of&amp;nbsp;that tools are using common infrastructure that emulates application runtime&amp;nbsp;&amp;mdash; memory management function, CPU caches, threading primitives, etc. That’s&amp;nbsp;where our program is&amp;nbsp;executing and being analyzed by&amp;nbsp;&lt;em&gt;Valgrind&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Now let’s&amp;nbsp;look at&amp;nbsp;what &lt;em&gt;Valgrind&lt;/em&gt; can do.&lt;/p&gt;
&lt;h2 id="memcheck"&gt;Memcheck&lt;/h2&gt;
&lt;p&gt;Ok, so&amp;nbsp;&lt;em&gt;Memcheck&lt;/em&gt; is&amp;nbsp;memory errors detector. Though it’s&amp;nbsp;not profile it’s&amp;nbsp;one of&amp;nbsp;most useful tools in&amp;nbsp;programmer’s&amp;nbsp;toolbox.&lt;/p&gt;
&lt;p&gt;Let’s&amp;nbsp;launch our hasher under &lt;em&gt;Memcheck&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@simplex block_hasher]# valgrind --leak-check=full ./block_hasher -d /dev/md126 -b 1048576 -t 10 -n 1000
==4323== Memcheck, a memory error detector
==4323== Copyright (C) 2002-2010, and GNU GPL&amp;#39;d, by Julian Seward et al.
==4323== Using Valgrind-3.6.0 and LibVEX; rerun with -h for copyright info
==4323== Command: ./block_hasher -d /dev/md126 -b 1048576 -t 10 -n 1000
==4323== 
==4323== 
==4323== HEAP SUMMARY:
==4323==     in use at exit: 16 bytes in 1 blocks
==4323==   total heap usage: 43 allocs, 42 frees, 10,491,624 bytes allocated
==4323== 
==4323== LEAK SUMMARY:
==4323==    definitely lost: 0 bytes in 0 blocks
==4323==    indirectly lost: 0 bytes in 0 blocks
==4323==      possibly lost: 0 bytes in 0 blocks
==4323==    still reachable: 16 bytes in 1 blocks
==4323==         suppressed: 0 bytes in 0 blocks
==4323== Reachable blocks (those to which a pointer was found) are not shown.
==4323== To see them, rerun with: --leak-check=full --show-reachable=yes
==4323== 
==4323== For counts of detected and suppressed errors, rerun with: -v
==4323== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 6 from 6)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I&amp;nbsp;won’t&amp;nbsp;explain what is&amp;nbsp;&lt;em&gt;definitely lost&lt;/em&gt;, &lt;em&gt;indirectly lost&lt;/em&gt; and other&amp;nbsp;&amp;mdash; that’s&amp;nbsp;what is&amp;nbsp;&lt;a href="http://valgrind.org/docs/manual/mc-manual.html"&gt;documentaion&lt;/a&gt; for.&lt;/p&gt;
&lt;p&gt;From &lt;em&gt;Memcheck&lt;/em&gt; profile we&amp;nbsp;can say that there are no&amp;nbsp;errors except little leak, 1 block is&amp;nbsp;&lt;em&gt;still reachable&lt;/em&gt;. From the message&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;total heap usage: 43 allocs, 42 frees, 10,491,624 bytes allocated&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I&amp;nbsp;have somewhere forgotten to&amp;nbsp;call &lt;code&gt;free&lt;/code&gt;. And that’s&amp;nbsp;true, in&amp;nbsp;&lt;code&gt;bdev_open&lt;/code&gt; I’m&amp;nbsp;allocating struct for &lt;code&gt;block_device&lt;/code&gt; but in&amp;nbsp;&lt;code&gt;bdev_close&lt;/code&gt; it’s&amp;nbsp;not freeing. By&amp;nbsp;the way, it’s&amp;nbsp;interesting that &lt;em&gt;Memcheck&lt;/em&gt; reports about 16 bytes loss, while &lt;code&gt;block_device&lt;/code&gt; is&amp;nbsp;&lt;code&gt;int&lt;/code&gt; and &lt;code&gt;off_t&lt;/code&gt; that should occupy &lt;code&gt;4 + 8 = 12&lt;/code&gt; bytes. Where are 4 more bytes? Structs are 8 byte aligned (for 64 bit system), that’s&amp;nbsp;why &lt;code&gt;int&lt;/code&gt; field are padded with 4 bytes.&lt;/p&gt;
&lt;p&gt;Anyway, I’ve&amp;nbsp;&lt;a href="https://github.com/dzeban/block_hasher/commit/f86fa71c45c3a59ced99b74b44a30cb8d94ba72d"&gt;fixed&lt;/a&gt; memory leak:&lt;/p&gt;
&lt;pre class="sourceCode diff"&gt;&lt;code class="sourceCode diff"&gt;&lt;span class="dt"&gt;@@ -240,6 +241,9 @@ void bdev_close( struct block_device *dev )&lt;/span&gt;
         perror(&amp;quot;close&amp;quot;);
     }
 
&lt;span class="ot"&gt;+    free(dev);&lt;/span&gt;
&lt;span class="ot"&gt;+    dev = NULL;&lt;/span&gt;
&lt;span class="ot"&gt;+&lt;/span&gt;
     return;
 }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Check:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@simplex block_hasher]# valgrind --leak-check=full ./block_hasher -d /dev/md126 -b 1048576 -t 10 -n 1000
==15178== Memcheck, a memory error detector
==15178== Copyright (C) 2002-2010, and GNU GPL&amp;#39;d, by Julian Seward et al.
==15178== Using Valgrind-3.6.0 and LibVEX; rerun with -h for copyright info
==15178== Command: ./block_hasher -d /dev/md0 -b 1048576 -t 10 -n 1000
==15178== 
==15178== 
==15178== HEAP SUMMARY:
==15178==     in use at exit: 0 bytes in 0 blocks
==15178==   total heap usage: 43 allocs, 43 frees, 10,491,624 bytes allocated
==15178== 
==15178== All heap blocks were freed -- no leaks are possible
==15178== 
==15178== For counts of detected and suppressed errors, rerun with: -v
==15178== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 6 from 6)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Real pleasure to&amp;nbsp;see.&lt;/p&gt;
&lt;p&gt;As&amp;nbsp;a&amp;nbsp;resume I’d&amp;nbsp;like to&amp;nbsp;say that &lt;em&gt;Memcheck&lt;/em&gt; can do&amp;nbsp;a&amp;nbsp;lot. Not only in&amp;nbsp;detection of&amp;nbsp;memory errors, but also in&amp;nbsp;explaining. It’s&amp;nbsp;understatement to&amp;nbsp;say &amp;laquo;Hey, you’ve&amp;nbsp;got some error here!&amp;raquo;&amp;nbsp;&amp;mdash; to&amp;nbsp;fix error it’s&amp;nbsp;better to&amp;nbsp;know what is&amp;nbsp;the reason. And &lt;em&gt;Memcheck&lt;/em&gt; does it. It’s&amp;nbsp;so&amp;nbsp;good that it’s&amp;nbsp;even listed as&amp;nbsp;a&amp;nbsp;skill for system programmers positions.&lt;/p&gt;
&lt;h2 id="cachegrind"&gt;CacheGrind&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Cachegrind&lt;/em&gt;&amp;nbsp;&amp;mdash; CPU cache access profiler. What amazed me&amp;nbsp;is&amp;nbsp;that how it&amp;nbsp;trace cache accesses&amp;nbsp;&amp;mdash; &lt;em&gt;Cachegrind&lt;/em&gt; simulates it, see excerpt from documentation:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;It&amp;nbsp;performs detailed simulation of&amp;nbsp;the I1, D1 and L2 caches in&amp;nbsp;your CPU and so&amp;nbsp;can accurately pinpoint the sources of&amp;nbsp;cache misses in&amp;nbsp;your code.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;If&amp;nbsp;you think it’s&amp;nbsp;easy, please spend 90 minutes to&amp;nbsp;read &lt;a href="http://www.lighterra.com/papers/modernmicroprocessors/"&gt;this great article&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Let’s&amp;nbsp;collect profile!&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@simplex block_hasher]# valgrind --tool=cachegrind ./block_hasher -d /dev/md126 -b 1048576 -t 10 -n 1000
==9408== Cachegrind, a cache and branch-prediction profiler
==9408== Copyright (C) 2002-2010, and GNU GPL&amp;#39;d, by Nicholas Nethercote et al.
==9408== Using Valgrind-3.6.0 and LibVEX; rerun with -h for copyright info
==9408== Command: ./block_hasher -d /dev/md126 -b 1048576 -t 10 -n 1000
==9408== 
--9408-- warning: Unknown Intel cache config value (0xff), ignoring
--9408-- warning: L2 cache not installed, ignore LL results.
==9408== 
==9408== I   refs:      167,774,548,454
==9408== I1  misses:              1,482
==9408== LLi misses:              1,479
==9408== I1  miss rate:            0.00%
==9408== LLi miss rate:            0.00%
==9408== 
==9408== D   refs:       19,989,520,856  (15,893,212,838 rd   + 4,096,308,018 wr)
==9408== D1  misses:        163,354,097  (   163,350,059 rd   +         4,038 wr)
==9408== LLd misses:         74,749,207  (    74,745,179 rd   +         4,028 wr)
==9408== D1  miss rate:             0.8% (           1.0%     +           0.0%  )
==9408== LLd miss rate:             0.3% (           0.4%     +           0.0%  )
==9408== 
==9408== LL refs:           163,355,579  (   163,351,541 rd   +         4,038 wr)
==9408== LL misses:          74,750,686  (    74,746,658 rd   +         4,028 wr)
==9408== LL miss rate:              0.0% (           0.0%     +           0.0%  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First thing, I&amp;nbsp;look at&amp;nbsp;&amp;mdash; cache misses. But here it’s&amp;nbsp;less then 1% so&amp;nbsp;it&amp;nbsp;can’t&amp;nbsp;be&amp;nbsp;the problem.&lt;/p&gt;
&lt;p&gt;If&amp;nbsp;you asking yourself how &lt;em&gt;Cachegrind&lt;/em&gt; can be&amp;nbsp;useful, I’ll&amp;nbsp;tell you one of&amp;nbsp;the work stories. To&amp;nbsp;accelerate some of&amp;nbsp;RAID calculation algorithm my&amp;nbsp;collegue has reduced multiplications for the price of&amp;nbsp;increased additions and complicated data structure. In&amp;nbsp;theory it&amp;nbsp;should’ve&amp;nbsp;worked better like in&amp;nbsp;Karatsuba multiplication. But in&amp;nbsp;reality it&amp;nbsp;became much worse. After few days of&amp;nbsp;hard debugging we&amp;nbsp;launched it&amp;nbsp;under &lt;em&gt;Cachegrind&lt;/em&gt; and saw cache miss rate about 80%. More additions invoked more memory accesses and reduced locality. So&amp;nbsp;we&amp;nbsp;abandoned the idea.&lt;/p&gt;
&lt;h2 id="massif"&gt;Massif&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Massif&lt;/em&gt;&amp;nbsp;&amp;mdash; heap profiler, in&amp;nbsp;the sense that it&amp;nbsp;shows dynamic of&amp;nbsp;heap allocations, i.e. how much memory your applications were using in&amp;nbsp;some moment.&lt;/p&gt;
&lt;p&gt;To&amp;nbsp;do&amp;nbsp;that &lt;em&gt;Massif&lt;/em&gt; samples heap state, generating file that later transformed to&amp;nbsp;report with help of&amp;nbsp;&lt;code&gt;ms_print&lt;/code&gt; tool.&lt;/p&gt;
&lt;p&gt;Ok, launch it&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@simplex block_hasher]# valgrind --tool=massif ./block_hasher -d /dev/md0 -b 1048576 -t 10 -n 100
==29856== Massif, a heap profiler
==29856== Copyright (C) 2003-2010, and GNU GPL&amp;#39;d, by Nicholas Nethercote
==29856== Using Valgrind-3.6.0 and LibVEX; rerun with -h for copyright info
==29856== Command: ./block_hasher -d /dev/md0 -b 1048576 -t 10 -n 100
==29856== 
==29856== &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Got a&amp;nbsp;&lt;em&gt;massif.out.29856&lt;/em&gt; file. Convert it&amp;nbsp;to&amp;nbsp;text profile:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@simplex block_hasher]# ms_print massif.out.29856 &amp;gt; massif.profile&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Profile conteins histogram of&amp;nbsp;heap allocations&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    MB
10.01^::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::#
     |:                                                                 #
     |@                                                                 #::
     |@                                                                 # :
     |@                                                                 # ::
     |@                                                                 # ::
     |@                                                                 # ::@
     |@                                                                 # ::@
     |@                                                                 # ::@
     |@                                                                 # ::@
     |@                                                                 # ::@
     |@                                                                 # ::@
     |@                                                                 # ::@@
     |@                                                                 # ::@@
     |@                                                                 # ::@@
     |@                                                                 # ::@@
     |@                                                                 # ::@@
     |@                                                                 # ::@@
     |@                                                                 # ::@@
     |@                                                                 # ::@@
   0 +-----------------------------------------------------------------------&amp;gt;Gi
     0                                                                   15.63&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and summary table of&amp;nbsp;most noticable allocations. Example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--------------------------------------------------------------------------------
  n        time(i)         total(B)   useful-heap(B) extra-heap(B)    stacks(B)
--------------------------------------------------------------------------------
 40        344,706        9,443,296        9,442,896           400            0
 41        346,448       10,491,880       10,491,472           408            0
 42        346,527       10,491,936       10,491,520           416            0
 43        346,723       10,492,056       10,491,624           432            0
 44 15,509,791,074       10,492,056       10,491,624           432            0
100.00% (10,491,624B) (heap allocation functions) malloc/new/new[], --alloc-fns, etc.
-&amp;gt;99.94% (10,485,760B) 0x401169: thread_func (block_hasher.c:142)
| -&amp;gt;99.94% (10,485,760B) 0x54189CF: start_thread (in /lib64/libpthread-2.12.so)
|   -&amp;gt;09.99% (1,048,576B) 0x6BDC6FE: ???
|   |
|   -&amp;gt;09.99% (1,048,576B) 0x7FDE6FE: ???
|   |
|   -&amp;gt;09.99% (1,048,576B) 0x75DD6FE: ???
|   |
|   -&amp;gt;09.99% (1,048,576B) 0x93E06FE: ???
|   |
|   -&amp;gt;09.99% (1,048,576B) 0x89DF6FE: ???
|   |
|   -&amp;gt;09.99% (1,048,576B) 0xA1E16FE: ???
|   |
|   -&amp;gt;09.99% (1,048,576B) 0xABE26FE: ???
|   |
|   -&amp;gt;09.99% (1,048,576B) 0xB9E36FE: ???
|   |
|   -&amp;gt;09.99% (1,048,576B) 0xC3E46FE: ???
|   |
|   -&amp;gt;09.99% (1,048,576B) 0xCDE56FE: ???
|
-&amp;gt;00.06% (5,864B) in 1+ places, all below ms_print&amp;#39;s threshold (01.00%)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In&amp;nbsp;the table above we&amp;nbsp;can see that we&amp;nbsp;usually allocate in&amp;nbsp;10 MiB portions that is&amp;nbsp;really just a&amp;nbsp;10 blocks of&amp;nbsp;1 MiB (our block size). Nothing special but it&amp;nbsp;was interesting.&lt;/p&gt;
&lt;p&gt;Of&amp;nbsp;course, &lt;em&gt;Massif&lt;/em&gt; is&amp;nbsp;useful, because it&amp;nbsp;can show you a&amp;nbsp;history of&amp;nbsp;allocation, how much memory was allocated with all the alignment and also what code pieces allocated most. Too bad I&amp;nbsp;don’t&amp;nbsp;have heap errors.&lt;/p&gt;
&lt;h2 id="helgrind"&gt;Helgrind&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Helgrind&lt;/em&gt; is&amp;nbsp;not a&amp;nbsp;profiler but a&amp;nbsp;tool to&amp;nbsp;detect threading errors. It’s&amp;nbsp;a&amp;nbsp;thread debugger.&lt;/p&gt;
&lt;p&gt;I&amp;nbsp;just show how I’ve&amp;nbsp;fixed bug in&amp;nbsp;my&amp;nbsp;code with &lt;em&gt;Helgrind&lt;/em&gt; help.&lt;/p&gt;
&lt;p&gt;When I’ve&amp;nbsp;launched my&amp;nbsp;&lt;code&gt;block_hasher&lt;/code&gt; under it&amp;nbsp;I&amp;nbsp;was sure that I&amp;nbsp;will have 0 errors, but stuck in&amp;nbsp;debugging for couple of&amp;nbsp;days.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@simplex block_hasher]# valgrind --tool=helgrind ./block_hasher -d /dev/md0 -b 1048576 -t 10 -n 100
==3930== Helgrind, a thread error detector
==3930== Copyright (C) 2007-2010, and GNU GPL&amp;#39;d, by OpenWorks LLP et al.
==3930== Using Valgrind-3.6.0 and LibVEX; rerun with -h for copyright info
==3930== Command: ./block_hasher -d /dev/md0 -b 1048576 -t 10 -n 100
==3930== 
==3930== Thread #3 was created
==3930==    at 0x571DB2E: clone (in /lib64/libc-2.12.so)
==3930==    by 0x541E8BF: do_clone.clone.0 (in /lib64/libpthread-2.12.so)
==3930==    by 0x541EDA1: pthread_create@@GLIBC_2.2.5 (in /lib64/libpthread-2.12.so)
==3930==    by 0x4C2CE76: pthread_create_WRK (hg_intercepts.c:257)
==3930==    by 0x4019F0: main (block_hasher.c:350)
==3930== 
==3930== Thread #2 was created
==3930==    at 0x571DB2E: clone (in /lib64/libc-2.12.so)
==3930==    by 0x541E8BF: do_clone.clone.0 (in /lib64/libpthread-2.12.so)
==3930==    by 0x541EDA1: pthread_create@@GLIBC_2.2.5 (in /lib64/libpthread-2.12.so)
==3930==    by 0x4C2CE76: pthread_create_WRK (hg_intercepts.c:257)
==3930==    by 0x4019F0: main (block_hasher.c:350)
==3930== 
==3930== Possible data race during write of size 4 at 0x5200380 by thread #3
==3930==    at 0x4E98AF8: CRYPTO_malloc (in /usr/lib64/libcrypto.so.1.0.1e)
==3930==    by 0x4F16FF6: EVP_MD_CTX_create (in /usr/lib64/libcrypto.so.1.0.1e)
==3930==    by 0x401231: thread_func (block_hasher.c:163)
==3930==    by 0x4C2D01D: mythread_wrapper (hg_intercepts.c:221)
==3930==    by 0x541F9D0: start_thread (in /lib64/libpthread-2.12.so)
==3930==    by 0x75E46FF: ???
==3930==  This conflicts with a previous write of size 4 by thread #2
==3930==    at 0x4E98AF8: CRYPTO_malloc (in /usr/lib64/libcrypto.so.1.0.1e)
==3930==    by 0x4F16FF6: EVP_MD_CTX_create (in /usr/lib64/libcrypto.so.1.0.1e)
==3930==    by 0x401231: thread_func (block_hasher.c:163)
==3930==    by 0x4C2D01D: mythread_wrapper (hg_intercepts.c:221)
==3930==    by 0x541F9D0: start_thread (in /lib64/libpthread-2.12.so)
==3930==    by 0x6BE36FF: ???
==3930== 
==3930== 
==3930== For counts of detected and suppressed errors, rerun with: -v
==3930== Use --history-level=approx or =none to gain increased speed, at
==3930== the cost of reduced accuracy of conflicting-access information
==3930== ERROR SUMMARY: 9 errors from 1 contexts (suppressed: 955 from 9)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As&amp;nbsp;we&amp;nbsp;see, &lt;code&gt;EVP_MD_CTX_create&lt;/code&gt; leads to&amp;nbsp;data race. This is&amp;nbsp;an&amp;nbsp;openssl’s&amp;nbsp;&lt;a href="#fn1" class="footnoteRef" id="fnref1"&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; function that initializes context for hash calculation. I&amp;nbsp;calculate hash for blocks read in&amp;nbsp;each thread with &lt;code&gt;EVP_DigestUpdate&lt;/code&gt; and then write it&amp;nbsp;to&amp;nbsp;file after final &lt;code&gt;EVP_DigesFinal_ex&lt;/code&gt;. So&amp;nbsp;this &lt;em&gt;Helgrind&lt;/em&gt; errors are related to&amp;nbsp;openssl functions. And I&amp;nbsp;asked myself&amp;nbsp;&amp;mdash; &amp;laquo;Is&amp;nbsp;libcrypto &lt;nobr&gt;thread-safe&lt;/nobr&gt;?&amp;raquo;. So&amp;nbsp;I&amp;nbsp;used my&amp;nbsp;&lt;nobr&gt;google-fu&lt;/nobr&gt; and the answer is&amp;nbsp;&amp;mdash; &lt;a href="http://wiki.openssl.org/index.php/Libcrypto_API#Thread_Safety"&gt;&lt;strong&gt;by&amp;nbsp;default&lt;/strong&gt; no&lt;/a&gt;. To&amp;nbsp;use EVP functions in&amp;nbsp;multithreaded applications openssl recommends to&amp;nbsp;either register 2 crazy callbacks or&amp;nbsp;use dynamic locks (see &lt;a href="http://www.openssl.org/docs/crypto/threads.html"&gt;here&lt;/a&gt;). As&amp;nbsp;for me, I’ve&amp;nbsp;just wrapped context initialization in&amp;nbsp;pthread mutex and &lt;a href="https://github.com/dzeban/block_hasher/commit/c1994f763d4fce8bb41e97af45eac6e2ad0dc3b7"&gt;that’s&amp;nbsp;it&lt;/a&gt;.&lt;/p&gt;
&lt;pre class="sourceCode diff"&gt;&lt;code class="sourceCode diff"&gt;
&lt;span class="dt"&gt;@@ -159,9 +159,11 @@ void *thread_func(void *arg)&lt;/span&gt;
     gap = num_threads * block_size; // Multiply here to avoid integer overflow
 
     // Initialize EVP and start reading
&lt;span class="ot"&gt;+    pthread_mutex_lock( &amp;amp;mutex );&lt;/span&gt;
     md = EVP_sha1();
     mdctx = EVP_MD_CTX_create();
     EVP_DigestInit_ex( mdctx, md, NULL );
&lt;span class="ot"&gt;+    pthread_mutex_unlock( &amp;amp;mutex );&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If&amp;nbsp;anyone knows something about this&amp;nbsp;&amp;mdash; please, tell me.&lt;/p&gt;
&lt;h2 id="drd"&gt;DRD&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;DRD&lt;/em&gt; is&amp;nbsp;one more tool in&amp;nbsp;&lt;em&gt;Valgrind&lt;/em&gt; suite that can detect thread errors. It’s&amp;nbsp;more thorough and has more features while less memory hungry.&lt;/p&gt;
&lt;p&gt;In&amp;nbsp;my&amp;nbsp;case it&amp;nbsp;has detected some mysterious &lt;code&gt;pread&lt;/code&gt; data race.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;==16358== Thread 3:
==16358== Conflicting load by thread 3 at 0x0563e398 size 4
==16358==    at 0x5431030: pread (in /lib64/libpthread-2.12.so)
==16358==    by 0x4012D9: thread_func (block_hasher.c:174)
==16358==    by 0x4C33470: vgDrd_thread_wrapper (drd_pthread_intercepts.c:281)
==16358==    by 0x54299D0: start_thread (in /lib64/libpthread-2.12.so)
==16358==    by 0x75EE6FF: ???&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;pread&lt;/code&gt; itself is&amp;nbsp;&lt;nobr&gt;thread-safe&lt;/nobr&gt; in&amp;nbsp;the sense that it&amp;nbsp;can be&amp;nbsp;called from multiple threads, but &lt;em&gt;access&lt;/em&gt; to&amp;nbsp;data might be&amp;nbsp;not synchronized. For example, you can call &lt;code&gt;pread&lt;/code&gt; in&amp;nbsp;one thread while calling &lt;code&gt;pwrite&lt;/code&gt; in&amp;nbsp;another and that’s&amp;nbsp;where you got &lt;em&gt;data&lt;/em&gt; race. But in&amp;nbsp;my&amp;nbsp;case data blocks do&amp;nbsp;not overlap, so&amp;nbsp;I&amp;nbsp;can’t&amp;nbsp;tell what’s&amp;nbsp;a&amp;nbsp;real problem here.&lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Conclusion will be&amp;nbsp;dead simple&amp;nbsp;&amp;mdash; learn how to&amp;nbsp;use Valgrind, it’s&amp;nbsp;extremely useful.&lt;/p&gt;
&lt;h2 id="to-read"&gt;To&amp;nbsp;read&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Success stories:
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://blog.gerhards.net/2009/01/rsyslog-data-race-analysis.html"&gt;rsyslog data race analysis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.evanweaver.com/2008/02/05/valgrind-and-ruby/"&gt;valgrind and ruby&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://sql.dzone.com/articles/profiling-mysql-memory-usage"&gt;Profiling MySQL Memory Usage With Valgrind Massif&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://courses.cs.washington.edu/courses/cse326/05wi/valgrind-doc/mc_techdocs.html"&gt;The design and implementation of&amp;nbsp;Valgrind. Detailed technical notes for hackers, maintainers and the &lt;nobr&gt;overly-curious&lt;/nobr&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="footnotes"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn1"&gt;&lt;p&gt;libcrypto is&amp;nbsp;a&amp;nbsp;library of&amp;nbsp;cryptography functions and primitives that’s&amp;nbsp;openssl is&amp;nbsp;based on.&lt;a href="#fnref1"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content>
  </entry>
  <entry xml:base="http://alex.dzyoba.com/feed">
    <title type="text">Profiling in Linux. gprof and gcov</title>
    <id>linux/profiling-gprof-gcov.html</id>
    <updated>2014-02-10T00:00:00Z</updated>
    <link href="linux/profiling-gprof-gcov.html" />
    <author>
      <name>Alex Dzyoba</name>
    </author>
    <content type="html">&lt;p&gt;TOC:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;&lt;a href="/linux/profiling-intro.html"&gt;Intro&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Userspace profiling: gprof, gcov&lt;/li&gt;
&lt;li&gt;&lt;a href="/linux/profiling-valgrind.html"&gt;Userspace profiling: Valgrind&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/linux/profiling-kernel.html"&gt;Kernel profiling: Intro&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/linux/profiling-ftrace.html"&gt;Kernel profiling: ftrace&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/linux/profiling-perf.html"&gt;Kernel profiling: perf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/linux/profiling-systemtap.html"&gt;Kernel profiling: SystemTap&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Various tools&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;em&gt;gprof&lt;/em&gt; and &lt;em&gt;gcov&lt;/em&gt; is&amp;nbsp;a&amp;nbsp;classical profilers that are still in&amp;nbsp;wide use. Since the dawn of&amp;nbsp;time they were used by&amp;nbsp;hackers though now everybody shifts their focus to&amp;nbsp;dynamic profilers like Valgrind.&lt;/p&gt;
&lt;h2 id="gprof"&gt;gprof&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;gprof&lt;/strong&gt; (GNU Profiler)&amp;nbsp;&amp;mdash; simple and easy profiler that can show how much time your program spends in&amp;nbsp;routines in&amp;nbsp;percents and seconds. &lt;em&gt;gprof&lt;/em&gt; uses source code instrumentation by&amp;nbsp;inserting special &lt;code&gt;mcount&lt;/code&gt; function call to&amp;nbsp;gather metrics of&amp;nbsp;your program.&lt;/p&gt;
&lt;h3 id="building-with-gprof-instrumentation"&gt;Building with gprof instrumentation&lt;/h3&gt;
&lt;p&gt;To&amp;nbsp;gather profile you need to&amp;nbsp;compile your program with &lt;code&gt;-pg&lt;/code&gt; gcc option and then launch under &lt;em&gt;gprof&lt;/em&gt;. For better results and statistical errors elimination it’s&amp;nbsp;recommended to&amp;nbsp;launch profiling subject several times.&lt;/p&gt;
&lt;p&gt;To&amp;nbsp;build with &lt;em&gt;gprof&lt;/em&gt; instrumentation invoke gcc like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@simplex block_hasher]# gcc -pg -g -lcrypto -pthread -lrt -Wall -Wextra block_hasher.c -o block_hasher&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As&amp;nbsp;a&amp;nbsp;result you’ll&amp;nbsp;get instrumented program. To&amp;nbsp;check if&amp;nbsp;it’s&amp;nbsp;really instrumented just grep &lt;code&gt;mcount&lt;/code&gt; symbol.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; [root@simplex block_hasher]# nm block_hasher | grep mcount
                  U mcount@@GLIBC_2.2.5&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="profiling-block_hasher-under-gprof"&gt;Profiling block_hasher under gprof&lt;/h3&gt;
&lt;p&gt;As&amp;nbsp;I&amp;nbsp;said earlier to&amp;nbsp;collect useful statistic we&amp;nbsp;should run program several times and accumulate metrics. To&amp;nbsp;do&amp;nbsp;that I’ve&amp;nbsp;written simple bash script:&lt;/p&gt;
&lt;pre class="sourceCode bash"&gt;&lt;code class="sourceCode bash"&gt;&lt;span class="co"&gt;#!/bin/bash&lt;/span&gt;

&lt;span class="kw"&gt;if [&lt;/span&gt; &lt;span class="ot"&gt;$#&lt;/span&gt; &lt;span class="ot"&gt;-ne&lt;/span&gt; 1&lt;span class="kw"&gt; ]&lt;/span&gt;; &lt;span class="kw"&gt;then&lt;/span&gt;
    &lt;span class="kw"&gt;echo&lt;/span&gt; &lt;span class="st"&gt;&amp;quot;gprof.sh &amp;lt;number of runs&amp;gt;&amp;quot;&lt;/span&gt;
    &lt;span class="kw"&gt;exit&lt;/span&gt; 1
&lt;span class="kw"&gt;fi&lt;/span&gt;

&lt;span class="kw"&gt;for&lt;/span&gt; &lt;span class="kw"&gt;i&lt;/span&gt; in &lt;span class="ot"&gt;$(&lt;/span&gt;&lt;span class="kw"&gt;seq&lt;/span&gt; 1 &lt;span class="ot"&gt;$1)&lt;/span&gt;&lt;span class="kw"&gt;;&lt;/span&gt; &lt;span class="kw"&gt;do&lt;/span&gt;

    &lt;span class="co"&gt;# Run profiled program&lt;/span&gt;
    &lt;span class="kw"&gt;./block_hasher&lt;/span&gt; -d /dev/md126 -b 1048576 -t 10 -n 1000

    &lt;span class="co"&gt;# Accumulate gprof statistic&lt;/span&gt;
    &lt;span class="kw"&gt;if [&lt;/span&gt; &lt;span class="ot"&gt;-e&lt;/span&gt; gmon.sum&lt;span class="kw"&gt; ]&lt;/span&gt;; &lt;span class="kw"&gt;then&lt;/span&gt;
        &lt;span class="kw"&gt;gprof&lt;/span&gt; -s block_hasher gmon.out gmon.sum
    &lt;span class="kw"&gt;else&lt;/span&gt;
        &lt;span class="kw"&gt;mv&lt;/span&gt; gmon.out gmon.sum
    &lt;span class="kw"&gt;fi&lt;/span&gt;
&lt;span class="kw"&gt;done&lt;/span&gt;

&lt;span class="co"&gt;# Make final profile&lt;/span&gt;
&lt;span class="kw"&gt;gprof&lt;/span&gt; block_hasher gmon.sum &lt;span class="kw"&gt;&amp;gt;&lt;/span&gt; gmon.profile&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So, each launch will create &lt;em&gt;gmon.out&lt;/em&gt; that gprof will combine in&amp;nbsp;&lt;em&gt;gmon.sum&lt;/em&gt;. Finally, &lt;em&gt;gmon.sum&lt;/em&gt; will be&amp;nbsp;feed to&amp;nbsp;&lt;em&gt;gprof&lt;/em&gt; to&amp;nbsp;get flat text profile and call graph.&lt;/p&gt;
&lt;h3 id="analyzing"&gt;Analyzing&lt;/h3&gt;
&lt;p&gt;Flat profile has info about program routines and time spent in&amp;nbsp;it.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Flat profile:

Each sample counts as 0.01 seconds.
  %   cumulative   self              self     total
 time   seconds   seconds    calls  Ts/call  Ts/call  name
100.24      0.01     0.01                             thread_func
  0.00      0.01     0.00       50     0.00     0.00  time_diff
  0.00      0.01     0.00        5     0.00     0.00  bdev_close
  0.00      0.01     0.00        5     0.00     0.00  bdev_open&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a name="not-application"&gt;&lt;/a&gt; &lt;em&gt;gprof&lt;/em&gt; metrics are clear from the name. As&amp;nbsp;we&amp;nbsp;can see almost all of&amp;nbsp;it’s&amp;nbsp;time our little program spent in&amp;nbsp;thread function, &lt;strong&gt;BUT&lt;/strong&gt; look at&amp;nbsp;the actual seconds&amp;nbsp;&amp;mdash; only 0.01 seconds from whole program execution. It&amp;nbsp;means that it’s&amp;nbsp;not the thread function who is&amp;nbsp;slowing down but something underlying. It’s&amp;nbsp;really obvious that &lt;code&gt;pread&lt;/code&gt; itself is&amp;nbsp;unlikely to&amp;nbsp;slack&amp;nbsp;&amp;mdash; the only reasonable candidate is&amp;nbsp;I/O work that make thread functions sleep in&amp;nbsp;waiting for I/O completion.&lt;/p&gt;
&lt;p&gt;Call graph is&amp;nbsp;really not interesting here, so&amp;nbsp;I&amp;nbsp;won’t&amp;nbsp;show you it, sorry.&lt;/p&gt;
&lt;h2 id="gcov"&gt;gcov&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;gcov&lt;/strong&gt; (short for GNU Coverage)&amp;nbsp;&amp;mdash; tool to&amp;nbsp;collect function call statistics &lt;nobr&gt;line-by-line&lt;/nobr&gt;. Usually it’s&amp;nbsp;used in&amp;nbsp;pair with &lt;em&gt;gprof&lt;/em&gt; to&amp;nbsp;understand what exact line in&amp;nbsp;slacking function is&amp;nbsp;holds your program down.&lt;/p&gt;
&lt;h3 id="building-with-gcov-instrumentation"&gt;Building with gcov instrumentation&lt;/h3&gt;
&lt;p&gt;Just as&amp;nbsp;&lt;em&gt;gprof&lt;/em&gt; you need to&amp;nbsp;recompile your program with &lt;em&gt;gcov&lt;/em&gt; flags&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# gcc -fprofile-arcs -ftest-coverage -lcrypto -pthread -lrt -Wall -Wextra block_hasher.c -o block_hasher&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are 2 &lt;em&gt;gcov&lt;/em&gt; flags: &lt;code&gt;-&lt;nobr&gt;fprofile-arcs&lt;/nobr&gt;&lt;/code&gt; и&amp;nbsp;&lt;code&gt;-&lt;nobr&gt;ftest-coverage&lt;/nobr&gt;&lt;/code&gt;. First will instrument your program to&amp;nbsp;profile so&amp;nbsp;called &lt;em&gt;arcs&lt;/em&gt;&amp;nbsp;&amp;mdash; pathes in&amp;nbsp;program’s&amp;nbsp;control flow. Second option will make gcc to&amp;nbsp;collect additional notes for arcs profiling and &lt;em&gt;gcov&lt;/em&gt; itself.&lt;/p&gt;
&lt;p&gt;You can simply put &lt;code&gt;-coverage&lt;/code&gt; option which implies both of&amp;nbsp;&lt;code&gt;-&lt;nobr&gt;fprofile-arcs&lt;/nobr&gt;&lt;/code&gt; and &lt;code&gt;-&lt;nobr&gt;ftest-coverage&lt;/nobr&gt;&lt;/code&gt; along with linker &lt;code&gt;-lgcov&lt;/code&gt; flag. See &lt;a href="https://gcc.gnu.org/onlinedocs/gcc/Debugging-Options.html"&gt;GCC debugging options&lt;/a&gt; for more info.&lt;/p&gt;
&lt;h3 id="profiling-block_hasher-under-gcov"&gt;Profiling block_hasher under gcov&lt;/h3&gt;
&lt;p&gt;Now, after instrumenting we&amp;nbsp;just launch program to&amp;nbsp;get 2 files&amp;nbsp;&amp;mdash; &lt;em&gt;block_hasher.gcda&lt;/em&gt; and &lt;em&gt;block_hasher.gcno&lt;/em&gt;. Please, don’t&amp;nbsp;look inside it&amp;nbsp;&amp;mdash; we&amp;nbsp;will transform it&amp;nbsp;to&amp;nbsp;text profile. To&amp;nbsp;do&amp;nbsp;this we&amp;nbsp;execute &lt;em&gt;gcov&lt;/em&gt; passing it&amp;nbsp;source code filename. It’s&amp;nbsp;important to&amp;nbsp;remember that you must have &lt;code&gt;&amp;lt;filename&amp;gt;.gcda&lt;/code&gt; and &lt;code&gt;&amp;lt;filename&amp;gt;.gcno&lt;/code&gt; files.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@simplex block_hasher]# gcov block_hasher.c
File &amp;#39;block_hasher.c&amp;#39;
Lines executed:77.69% of 121
block_hasher.c:creating &amp;#39;block_hasher.c.gcov&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally we’ll&amp;nbsp;get &lt;em&gt;block_hasher.c.gcov&lt;/em&gt;.&lt;/p&gt;
&lt;h3 id="analyzing-1"&gt;Analyzing&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;.gcov&lt;/code&gt; file is&amp;nbsp;result of&amp;nbsp;that whole &lt;em&gt;gcov&lt;/em&gt; work. Let’s&amp;nbsp;look at&amp;nbsp;it. For each of&amp;nbsp;your source files gcov will create annotated source codes with runtime coverage. Here is&amp;nbsp;excerpt from &lt;code&gt;thread_func&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;   10:  159:    gap = num_threads * block_size; // Multiply here to avoid integer overflow
    -:  160:
    -:  161:    // Initialize EVP and start reading
   10:  162:    md = EVP_sha1();
   10:  163:    mdctx = EVP_MD_CTX_create();
   10:  164:    EVP_DigestInit_ex( mdctx, md, NULL );
    -:  165:
   10:  166:    get_clock( &amp;amp;start );
10010:  167:    for( i = 0; i &amp;lt; nblocks; i++)
    -:  168:    {
10000:  169:        offset = j-&amp;gt;off + gap * i;
    -:  170:
    -:  171:        // Read at offset without changing file pointer
10000:  172:        err = pread( bdev-&amp;gt;fd, buf, block_size, offset );
 9999:  173:        if( err == -1 )
    -:  174:        {
#####:  175:            fprintf(stderr, &amp;quot;T%02d Failed to read at %llu\n&amp;quot;, j-&amp;gt;num, (unsigned long long)offset);
#####:  176:            perror(&amp;quot;pread&amp;quot;);
#####:  177:            pthread_exit(NULL);
    -:  178:        }
    -:  179:
 9999:  180:        bytes += err; // On success pread returns bytes read
    -:  181:
    -:  182:        // Update digest
 9999:  183:        EVP_DigestUpdate( mdctx, buf, block_size );
    -:  184:    }
   10:  185:    get_clock( &amp;amp;end );
   10:  186:    sec_diff = time_diff( start, end );
    -:  187:
   10:  188:    EVP_DigestFinal_ex( mdctx, j-&amp;gt;digest, &amp;amp;j-&amp;gt;digest_len );
   10:  189:    EVP_MD_CTX_destroy(mdctx);&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The left outmost column is&amp;nbsp;how many times this line of&amp;nbsp;code was invoked. As&amp;nbsp;expected, the &lt;em&gt;for&lt;/em&gt; loop was executed 10000 times&amp;nbsp;&amp;mdash; 10 threads each reading 1000 blocks. Nothing new.&lt;/p&gt;
&lt;p&gt;Though &lt;em&gt;gcov&lt;/em&gt; was not so&amp;nbsp;much useful for me, I’d&amp;nbsp;like to&amp;nbsp;say that it&amp;nbsp;has really cool feature&amp;nbsp;&amp;mdash; branch probabilities. If&amp;nbsp;you’ll&amp;nbsp;launch &lt;em&gt;gcov&lt;/em&gt; with &lt;code&gt;-b&lt;/code&gt; option&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@simplex block_hasher]# gcov -b block_hasher.c
File &amp;#39;block_hasher.c&amp;#39;
Lines executed:77.69% of 121
Branches executed:100.00% of 66
Taken at least once:60.61% of 66
Calls executed:51.47% of 68
block_hasher.c:creating &amp;#39;block_hasher.c.gcov&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You’ll&amp;nbsp;get nice branch annotation with probabilities. For example, here is&amp;nbsp;&lt;code&gt;time_diff&lt;/code&gt; function&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;113 function time_diff called 10 returned 100% blocks executed 100%
114        10:  106:double time_diff(struct timespec start, struct timespec end)
115         -:  107:{
116         -:  108:    struct timespec diff;
117         -:  109:    double sec;
118         -:  110:
119        10:  111:    if ( (end.tv_nsec - start.tv_nsec) &amp;lt; 0 )
120 branch  0 taken 60% (fallthrough)
121 branch  1 taken 40%
122         -:  112:    {
123         6:  113:        diff.tv_sec  = end.tv_sec - start.tv_sec - 1;
124         6:  114:        diff.tv_nsec = 1000000000 + end.tv_nsec - start.tv_nsec;
125         -:  115:    }
126         -:  116:    else
127         -:  117:    {
128         4:  118:        diff.tv_sec  = end.tv_sec - start.tv_sec;
129         4:  119:        diff.tv_nsec = end.tv_nsec - start.tv_nsec;
130         -:  120:    }
131         -:  121:
132        10:  122:    sec = (double)diff.tv_nsec / 1000000000 + diff.tv_sec;
133         -:  123:
134        10:  124:    return sec;
135         -:  125:}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In&amp;nbsp;60% of&amp;nbsp;&lt;code&gt;if&lt;/code&gt; calls we’ve&amp;nbsp;fallen in&amp;nbsp;branch to&amp;nbsp;calculate time diff with borrow, that actually means we&amp;nbsp;were executing for more than 1 second.&lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;gprof&lt;/em&gt; and &lt;em&gt;gcov&lt;/em&gt; are really entertaining tools despite a&amp;nbsp;lot of&amp;nbsp;people think about them as&amp;nbsp;obsolete. On&amp;nbsp;one hand these utilities are simple, they implementing and automating obvious method of&amp;nbsp;source code instrumentation to&amp;nbsp;measure function hit count.&lt;/p&gt;
&lt;p&gt;But on&amp;nbsp;the other hand such simple metrics won’t&amp;nbsp;help with problems outside of&amp;nbsp;your application. Although there are ways to&amp;nbsp;use it&amp;nbsp;for operating system, e.g. &lt;a href="https://www.kernel.org/doc/Documentation/gcov.txt"&gt;for Linux kernel&lt;/a&gt;. Anyway &lt;em&gt;gprof&lt;/em&gt; and &lt;em&gt;gcov&lt;/em&gt; is&amp;nbsp;useless in&amp;nbsp;case when your application spends most of&amp;nbsp;it’s&amp;nbsp;time in&amp;nbsp;waiting for some syscall (&lt;code&gt;pread&lt;/code&gt; in&amp;nbsp;my&amp;nbsp;case).&lt;/p&gt;
&lt;h2 id="to-read"&gt;To&amp;nbsp;read&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://sourceware.org/binutils/docs/gprof/"&gt;gprof manual&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.ibm.com/developerworks/ru/library/l-gnuprof/"&gt;IBM tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.cs.utah.edu/dept/old/texinfo/as/gprof.html"&gt;Utah university manual&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>
  </entry>
  <entry xml:base="http://alex.dzyoba.com/feed">
    <title type="text">Linux profiling. Intro</title>
    <id>linux/profiling-intro.html</id>
    <updated>2014-01-30T00:00:00Z</updated>
    <link href="linux/profiling-intro.html" />
    <author>
      <name>Alex Dzyoba</name>
    </author>
    <content type="html">&lt;h2 id="intro-to-intro"&gt;Intro to&amp;nbsp;intro&lt;/h2&gt;
&lt;p&gt;Initially I’ve&amp;nbsp;wanted to&amp;nbsp;write single article with review of&amp;nbsp;Linux profiling tools, but being very curious person I’ve&amp;nbsp;overblew it. And so&amp;nbsp;I’ve&amp;nbsp;decided to&amp;nbsp;create a&amp;nbsp;series of&amp;nbsp;articles that will be&amp;nbsp;interesting from techical point of&amp;nbsp;view and not to&amp;nbsp;broad as&amp;nbsp;in&amp;nbsp;some book. So&amp;nbsp;now, please welcome, a&amp;nbsp;whole sequence of&amp;nbsp;articles.&lt;/p&gt;
&lt;p&gt;TOC:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;Intro&lt;/li&gt;
&lt;li&gt;&lt;a href="/linux/profiling-gprof-gcov.html"&gt;Userspace profiling: gprof, gcov&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/linux/profiling-valgrind.html"&gt;Userspace profiling: Valgrind&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/linux/profiling-kernel.html"&gt;Kernel profiling: Intro&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/linux/profiling-ftrace.html"&gt;Kernel profiling: ftrace&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/linux/profiling-perf.html"&gt;Kernel profiling: perf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/linux/profiling-systemtap.html"&gt;Kernel profiling: SystemTap&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Various tools&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="faq"&gt;FAQ&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Profiling&lt;/strong&gt;&amp;nbsp;&amp;mdash; dynamic analysis of&amp;nbsp;software, consisting of&amp;nbsp;gathering various metrics and calculating some statistical info from it. Usually, you do&amp;nbsp;profiling to&amp;nbsp;analyze performance though it’s&amp;nbsp;not the single case, e.g. there are works about profiling for &lt;a href="http://infoscience.epfl.ch/record/181628/files/eprof.pdf"&gt;energy consumption analysis&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Do&amp;nbsp;not confuse profiling and tracing. &lt;em&gt;Tracing&lt;/em&gt; is&amp;nbsp;a&amp;nbsp;procedure of&amp;nbsp;saving program runtime steps to&amp;nbsp;debug it&amp;nbsp;&amp;mdash; you are not gathering any metrics.&lt;/p&gt;
&lt;p&gt;Also don’t&amp;nbsp;confuse profiling and benchmarking. Benchmarking is&amp;nbsp;all about marketing. You launch some predefined procedure to&amp;nbsp;get couple of&amp;nbsp;numbers that you can print in&amp;nbsp;your marketing brochures.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Profiler&lt;/strong&gt;&amp;nbsp;&amp;mdash; program that do&amp;nbsp;profiling.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Profile&lt;/strong&gt;&amp;nbsp;&amp;mdash; result of&amp;nbsp;profiling, some statistical info calculated from gathered metrics.&lt;/p&gt;
&lt;p&gt;There are a&amp;nbsp;lot of&amp;nbsp;metrics that profiler can gather and analyze and I&amp;nbsp;won’t&amp;nbsp;list them all but instead try to&amp;nbsp;make some hierarchy of&amp;nbsp;it:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Time metrics
&lt;ul&gt;
&lt;li&gt;Program/function runtime&lt;/li&gt;
&lt;li&gt;I/O latency&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Space metrics
&lt;ul&gt;
&lt;li&gt;Memory usage&lt;/li&gt;
&lt;li&gt;Open files&lt;/li&gt;
&lt;li&gt;Bandwidth&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Code metrics
&lt;ul&gt;
&lt;li&gt;Call graph&lt;/li&gt;
&lt;li&gt;Function hit count&lt;/li&gt;
&lt;li&gt;Loops depth&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Hardware metrics
&lt;ul&gt;
&lt;li&gt;CPU cache hit/miss ratio&lt;/li&gt;
&lt;li&gt;Interrupts count&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Variety of&amp;nbsp;metrics imply variety of&amp;nbsp;methods to&amp;nbsp;gather it. And I&amp;nbsp;have a&amp;nbsp;beautiful hierarchy for that, yeah:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Invasive profiling&amp;nbsp;&amp;mdash; changing profiled code
&lt;ul&gt;
&lt;li&gt;Source code instrumentation&lt;/li&gt;
&lt;li&gt;Static binary instrumentation&lt;/li&gt;
&lt;li&gt;Dynamic binary instrumentation&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;nobr&gt;Non-invasive&lt;/nobr&gt; profiling&amp;nbsp;&amp;mdash; without changing any code
&lt;ul&gt;
&lt;li&gt;Sampling&lt;/li&gt;
&lt;li&gt;&lt;nobr&gt;Event-based&lt;/nobr&gt;&lt;/li&gt;
&lt;li&gt;Emulation&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(That’s&amp;nbsp;all the methods I&amp;nbsp;know. If&amp;nbsp;you come up&amp;nbsp;with another&amp;nbsp;&amp;mdash; feel free to&amp;nbsp;contact me).&lt;/p&gt;
&lt;p&gt;Quick review of&amp;nbsp;methods.&lt;/p&gt;
&lt;p&gt;Source code instrumentation is&amp;nbsp;the simplest one. If&amp;nbsp;you have source codes you can add special profiling calls to&amp;nbsp;every function (not manually, of&amp;nbsp;course) and then launch your program. Profiling calls will trace function graph and can also compute time spent in&amp;nbsp;functions and also branch prediction probability and a&amp;nbsp;lot of&amp;nbsp;other things. But oftentimes you don’t&amp;nbsp;have source code. And that makes me&amp;nbsp;saaaaad panda.&lt;/p&gt;
&lt;p&gt;Binary instrumentation is&amp;nbsp;what you can guess by&amp;nbsp;yourself&amp;nbsp;&amp;mdash; you are modifying program binary image&amp;nbsp;&amp;mdash; either on&amp;nbsp;disk (program.exe) or&amp;nbsp;in&amp;nbsp;memory. This is&amp;nbsp;what reverse engineers love to&amp;nbsp;do. To&amp;nbsp;research some commercial critical software or&amp;nbsp;analyze malware they do&amp;nbsp;binary instrumentation and analyze program behaviour. If&amp;nbsp;you’re&amp;nbsp;interesting in&amp;nbsp;this, please, call my&amp;nbsp;good friend and uni groupmate Dima Evdokimov (&lt;a href="https://twitter.com/evdokimovds"&gt;@evdokimovds&lt;/a&gt;)&amp;nbsp;&amp;mdash; he&amp;nbsp;is&amp;nbsp;research director in&amp;nbsp;Digital Security. He&amp;nbsp;is&amp;nbsp;really in&amp;nbsp;this theme (see, for example, &lt;a href="http://habrahabr.ru/company/dsec/blog/142575/"&gt;DBI in&amp;nbsp;informational security (in&amp;nbsp;Russian)&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Anyway, binary instrumentation also really useful in&amp;nbsp;profiling&amp;nbsp;&amp;mdash; many modern instruments are built on&amp;nbsp;top binary instrumentation ideas (SystemTap, ktap, dtrace).&lt;/p&gt;
&lt;p&gt;Ok, so&amp;nbsp;sometimes you can’t&amp;nbsp;instrument even binary code, e.g. you’re&amp;nbsp;profiling OS&amp;nbsp;kernel, or&amp;nbsp;some pretty complicated system consisting of&amp;nbsp;many tightly coupled modules that won’t&amp;nbsp;work after instrumenting. That’s&amp;nbsp;why you have &lt;nobr&gt;non-invasive&lt;/nobr&gt; profiling.&lt;/p&gt;
&lt;p&gt;Sampling is&amp;nbsp;the first natural idea that you can come up&amp;nbsp;with when you can’t&amp;nbsp;modify any code. The point is&amp;nbsp;that profiler periodically asks CPU registers (e.g. PSW) and analyze what is&amp;nbsp;going on. By&amp;nbsp;the way, this is&amp;nbsp;the only reasonable way you can get hardware metrics&amp;nbsp;&amp;mdash; by&amp;nbsp;periodical polling of&amp;nbsp;[PMU] (performance monitoring unit).&lt;/p&gt;
&lt;p&gt;&lt;nobr&gt;Event-based&lt;/nobr&gt; profiling is&amp;nbsp;about gathering events that must somehow be&amp;nbsp;prepared/preinstalled by&amp;nbsp;vendor of&amp;nbsp;profiling subject. Examples are inotify, kernel tracepoints in&amp;nbsp;Linux and &lt;a href="http://software.intel.com/sites/products/documentation/doclib/iss/2013/amplifier/lin/ug_docs/GUID-EEC5294C-5599-44F7-909D-9D617DE8AB92.htm"&gt;VTune events&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;And finally emulation is&amp;nbsp;just running your program in&amp;nbsp;isolated environment like virtual machine or&amp;nbsp;QEMU thus giving you full control over program execution but garbling behaviour.&lt;/p&gt;
&lt;h2 id="problem-definition"&gt;Problem definition&lt;/h2&gt;
&lt;p&gt;I’m&amp;nbsp;a&amp;nbsp;big fan of&amp;nbsp;studying something with the &lt;nobr&gt;real-world&lt;/nobr&gt; examples, instead of&amp;nbsp;thoughtless manual reading. That’s&amp;nbsp;why I’ll&amp;nbsp;define problem and will try to&amp;nbsp;solve it&amp;nbsp;using profiling.&lt;/p&gt;
&lt;p&gt;That said, I&amp;nbsp;have a&amp;nbsp;nice little program that checks data integrity on&amp;nbsp;given block device. Simply put, it&amp;nbsp;reads data blocks in&amp;nbsp;multiple threads and computes checksums along with bandwith. Here are the &lt;a href="https://github.com/dzeban/block_hasher"&gt;sources&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;So, I&amp;nbsp;use that utility to&amp;nbsp;check my&amp;nbsp;8 disks RAID 0 (standard Linux mdraid). This is&amp;nbsp;how I&amp;nbsp;do&amp;nbsp;reading:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./block_hasher -d /dev/md126 -b 1048576 -t 10 -n 1000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;1000 blocks of&amp;nbsp;size 1 MiB for each of&amp;nbsp;10 threads.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;block_hasher&lt;/code&gt; also computes bandwith by&amp;nbsp;simply dividing data read on&amp;nbsp;thread running time. And so&amp;nbsp;I’ve&amp;nbsp;got that bandwidth:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@simplex block_hasher]# cat bad.out 
T06: 57.12 MB/s c86253f827c0e40a056d2afc7d6605c291e57400
T08: 56.72 MB/s 9364a42836daa9beadf02c15777b3e1779f57b00
T04: 54.82 MB/s d0d7c3e2faed39d83ea25e468b5714bbfe23e200
T00: 53.06 MB/s c32caf8e5bdebeb2ffa73707e61fad50a751e800
T02: 53.00 MB/s 34a7495fe2ccaac4afee0e7460d9dff051701900
T07: 29.93 MB/s 95b3dc919fc4d61548a3b0737dd2ab03a0bab400
T03: 29.93 MB/s c1228ce6d4920e3bc101f1874bd5beeeb25ec600
T01: 29.89 MB/s 63d484d0fc2456c9a3c18d1d0ef43d60957d1200
T05: 29.89 MB/s 5c229e2fe168fb60a0d56b22f6eaa8fc6675d700
T09: 29.88 MB/s f6eb529ee5b59824a657fb8de43c8c6d3e29cb00&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If&amp;nbsp;you sum bandwidth for all threads you’ll&amp;nbsp;get total bandwidth for whole RAID.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@simplex block_hasher]# cut -f2 -d&amp;#39; &amp;#39; bad.out |  paste -sd + | bc
424.24&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Namely, &lt;strong&gt;424.24 MB/s&lt;/strong&gt; which is&amp;nbsp;pretty bad. In&amp;nbsp;theory, you can get&lt;a href="#fn1" class="footnoteRef" id="fnref1"&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Speed = &amp;lt;IOPS from 1 disk&amp;gt; * &amp;lt;block size&amp;gt; * &amp;lt;disks count&amp;gt; 

180 * 1048576 * 8 = 1509949440 Bytes/s = 1.5 GB/s&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In&amp;nbsp;real life you’ll&amp;nbsp;get something about 1 GB/s.&lt;/p&gt;
&lt;p&gt;To&amp;nbsp;determine why is&amp;nbsp;it&amp;nbsp;slow we’ll&amp;nbsp;use profilers. We’ll&amp;nbsp;profile &lt;code&gt;block_hasher&lt;/code&gt; as&amp;nbsp;much as&amp;nbsp;everything below including Linux kernel.&lt;/p&gt;
&lt;p&gt;In&amp;nbsp;this series of&amp;nbsp;articles I’ll&amp;nbsp;try to&amp;nbsp;review next profilers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;gprof&lt;/li&gt;
&lt;li&gt;gcov&lt;/li&gt;
&lt;li&gt;Valgrind&lt;/li&gt;
&lt;li&gt;perf&lt;/li&gt;
&lt;li&gt;SystemTap&lt;/li&gt;
&lt;li&gt;ktap&lt;/li&gt;
&lt;li&gt;VTune&lt;/li&gt;
&lt;li&gt;Block devices related tools: blktrace, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="references"&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://en.wikibooks.org/wiki/Introduction_to_Software_Engineering/Testing/Profiling"&gt;Profiling wikibook&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="footnotes"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn1"&gt;&lt;p&gt;This trivial formulae implies that block reading time is&amp;nbsp;the same for any sizes which in&amp;nbsp;fact is&amp;nbsp;not. Also it’s&amp;nbsp;applicable only for RAID level 0.&lt;a href="#fnref1"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content>
  </entry>
  <entry xml:base="http://alex.dzyoba.com/feed">
    <title type="text">Tale about data corruption, stack and red zone</title>
    <id>programming/redzone.html</id>
    <updated>2014-01-27T00:00:00Z</updated>
    <link href="programming/redzone.html" />
    <author>
      <name>avd</name>
    </author>
    <content type="html">&lt;p&gt;It&amp;nbsp;was a&amp;nbsp;nice and calm work day when suddenly a&amp;nbsp;wild collegue appeared in&amp;nbsp;front of&amp;nbsp;my&amp;nbsp;desk and asked:&lt;/p&gt;
&lt;p&gt;&amp;mdash;&amp;nbsp;Hey, uhmm, could you help me&amp;nbsp;with some strange thing?&lt;br /&gt;
&amp;mdash;&amp;nbsp;Yeah, sure, what’s&amp;nbsp;matter?&lt;br /&gt;
&amp;mdash;&amp;nbsp;I&amp;nbsp;have data corruption and it’s&amp;nbsp;happening in&amp;nbsp;a&amp;nbsp;really crazy manner.&lt;/p&gt;
&lt;p&gt;If&amp;nbsp;you don’t&amp;nbsp;know, data/memory corruption is&amp;nbsp;the single most nasty and awful bug that can happen in&amp;nbsp;your program. Especially, when you are storage developer.&lt;/p&gt;
&lt;p&gt;So&amp;nbsp;here was the case. We&amp;nbsp;have RAID calculation algorithm. Nothing fancy&amp;nbsp;&amp;mdash; just a&amp;nbsp;bunch of&amp;nbsp;functions that gets pointer to&amp;nbsp;buffer, do&amp;nbsp;some math over that buffer and then return it. Initially, calculation algorithm was written in&amp;nbsp;userspace for simpler debugging, correctness proof and profiling and then ported to&amp;nbsp;kernel space. And that’s&amp;nbsp;where the problem started.&lt;/p&gt;
&lt;p&gt;Firstly, when building from &lt;a href="http://www.linuxjournal.com/content/kbuild-linux-kernel-build-system"&gt;kbuild&lt;/a&gt;, gcc was just crashing&lt;a href="#fn1" class="footnoteRef" id="fnref1"&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; eating all the memory available. But I&amp;nbsp;was not surprized at&amp;nbsp;all considering files size&amp;nbsp;&amp;mdash; dozen of&amp;nbsp;files each about 10 megabytes. Yes, 10 MB. Though that was not surprizing for me, too. That sources was generated from assembly and were actually a&amp;nbsp;bunch of&amp;nbsp;&lt;a href="http://en.wikipedia.org/wiki/Intrinsic_function"&gt;intrinsics&lt;/a&gt;. Anyway, it&amp;nbsp;would be&amp;nbsp;much better if&amp;nbsp;gcc would not just crash.&lt;/p&gt;
&lt;p&gt;So&amp;nbsp;we’ve&amp;nbsp;just written separate Makefile to&amp;nbsp;build object files that will later be&amp;nbsp;linked in&amp;nbsp;kernel module.&lt;/p&gt;
&lt;p&gt;Secondly, data was not corrupted every time. When you were reading 1 GB&amp;nbsp;from disks it&amp;nbsp;was fine. And when you were reading 2 GB&amp;nbsp;sometimes it&amp;nbsp;was ok&amp;nbsp;and sometimes not.&lt;/p&gt;
&lt;p&gt;Thorough source code reading had led to&amp;nbsp;nothing. We&amp;nbsp;saw that memory buffer was corrupted exactly in&amp;nbsp;calculation functions. But that functions was pure math: just a&amp;nbsp;calculation with no&amp;nbsp;side effects&amp;nbsp;&amp;mdash; it&amp;nbsp;didn’t&amp;nbsp;call any library functions, it&amp;nbsp;didn’t&amp;nbsp;change anything except passed buffer and local variables. And that changes to&amp;nbsp;buffer were right, while corruption was really corruption&amp;nbsp;&amp;mdash; calc functions just cannot generate such data.&lt;/p&gt;
&lt;p&gt;And then we&amp;nbsp;saw a&amp;nbsp;pure magic. If&amp;nbsp;we&amp;nbsp;added to&amp;nbsp;calc function single&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;printk(&amp;quot;&amp;quot;);&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;then data was not corrupted at&amp;nbsp;all. I&amp;nbsp;thought such things were only subject of&amp;nbsp;DailyWTF stories or&amp;nbsp;developers jokes. We&amp;nbsp;checked everything several times on&amp;nbsp;different hosts&amp;nbsp;&amp;mdash; data was correct. Well, there were nothing left for us&amp;nbsp;except disassemble object files to&amp;nbsp;determine what was so&amp;nbsp;special about &lt;code&gt;printk&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;So&amp;nbsp;we&amp;nbsp;did a&amp;nbsp;diff between 2 object files with and without &lt;code&gt;printk&lt;/code&gt;.&lt;/p&gt;
&lt;pre class="sourceCode diff"&gt;&lt;code class="sourceCode diff"&gt;&lt;span class="kw"&gt;--- Calculation.s    2014-01-27 15:52:11.581387291 +0300&lt;/span&gt;
&lt;span class="dt"&gt;+++ Calculation_printk.s 2014-01-27 15:51:50.109512524 +0300&lt;/span&gt;
&lt;span class="dt"&gt;@@ -1,10 +1,15 @@&lt;/span&gt;
    .file   &amp;quot;Calculation.c&amp;quot;
&lt;span class="ot"&gt;+   .section    .rodata.str1.1,&amp;quot;aMS&amp;quot;,@progbits,1&lt;/span&gt;
&lt;span class="ot"&gt;+.LC0:&lt;/span&gt;
&lt;span class="ot"&gt;+   .string &amp;quot;&amp;quot;&lt;/span&gt;
    .text
    .p2align 4,,15
 .globl Calculation_5d
    .type   Calculation_5d, @function
 Calculation_5d:
 .LFB20:
&lt;span class="ot"&gt;+   subq    $24, %rsp&lt;/span&gt;
&lt;span class="ot"&gt;+.LCFI0:&lt;/span&gt;
    movq    (%rdi), %rax
    movslq  %ecx, %rcx
    movdqa  (%rax,%rcx), %xmm4
&lt;span class="dt"&gt;@@ -46,7 +51,7 @@&lt;/span&gt;
    pxor    %xmm2, %xmm6
    movdqa  96(%rax,%rcx), %xmm2
    pxor    %xmm5, %xmm1
&lt;span class="st"&gt;-   movdqa  %xmm14, -24(%rsp)&lt;/span&gt;
&lt;span class="ot"&gt;+   movdqa  %xmm14, (%rsp)&lt;/span&gt;
    pxor    %xmm15, %xmm2
    pxor    %xmm5, %xmm0
    movdqa  112(%rax,%rcx), %xmm14
&lt;span class="dt"&gt;@@ -108,11 +113,16 @@&lt;/span&gt;
    movq    24(%rdi), %rax
    movdqa  %xmm6, 80(%rax,%rcx)
    movq    24(%rdi), %rax
&lt;span class="st"&gt;-   movdqa  -24(%rsp), %xmm0&lt;/span&gt;
&lt;span class="ot"&gt;+   movdqa  (%rsp), %xmm0&lt;/span&gt;
    movdqa  %xmm0, 96(%rax,%rcx)
    movq    24(%rdi), %rax
&lt;span class="ot"&gt;+   movl    $.LC0, %edi&lt;/span&gt;
    movdqa  %xmm14, 112(%rax,%rcx)
&lt;span class="ot"&gt;+   xorl    %eax, %eax&lt;/span&gt;
&lt;span class="ot"&gt;+   call    printk&lt;/span&gt;
    movl    $128, %eax
&lt;span class="ot"&gt;+   addq    $24, %rsp&lt;/span&gt;
&lt;span class="ot"&gt;+.LCFI1:&lt;/span&gt;
    ret
 .LFE20:
    .size   Calculation_5d, .-Calculation_5d
&lt;span class="dt"&gt;@@ -143,6 +153,14 @@&lt;/span&gt;
    .long   .LFB20
    .long   .LFE20-.LFB20
    .uleb128 0x0
&lt;span class="ot"&gt;+   .byte   0x4&lt;/span&gt;
&lt;span class="ot"&gt;+   .long   .LCFI0-.LFB20&lt;/span&gt;
&lt;span class="ot"&gt;+   .byte   0xe&lt;/span&gt;
&lt;span class="ot"&gt;+   .uleb128 0x20&lt;/span&gt;
&lt;span class="ot"&gt;+   .byte   0x4&lt;/span&gt;
&lt;span class="ot"&gt;+   .long   .LCFI1-.LCFI0&lt;/span&gt;
&lt;span class="ot"&gt;+   .byte   0xe&lt;/span&gt;
&lt;span class="ot"&gt;+   .uleb128 0x8&lt;/span&gt;
    .align 8
 .LEFDE1:
    .ident  &amp;quot;GCC: (GNU) 4.4.5 20110214 (Red Hat 4.4.5-6)&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ok, looks like nothing changed much. String declaration in&amp;nbsp;&lt;code&gt;.rodata&lt;/code&gt; section, call to&amp;nbsp;&lt;code&gt;printk&lt;/code&gt; in&amp;nbsp;the end. But what looked really strange to&amp;nbsp;me&amp;nbsp;is&amp;nbsp;changes in&amp;nbsp;&lt;code&gt;%rsp&lt;/code&gt; manipulations. Seems like there were doing the same, but in&amp;nbsp;the printk version they shifted in&amp;nbsp;24 bytes because in&amp;nbsp;the start it&amp;nbsp;does &lt;code&gt;subq $24, %rsp&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;We&amp;nbsp;didn’t&amp;nbsp;care much about it&amp;nbsp;at&amp;nbsp;first. On&amp;nbsp;x86 architecture stack grows down, i.e. to&amp;nbsp;smaller addresses. So&amp;nbsp;to&amp;nbsp;access local variables (these are on&amp;nbsp;stack) you create new stack frame by&amp;nbsp;saving current &lt;code&gt;%rsp&lt;/code&gt; in&amp;nbsp;&lt;code&gt;%rbp&lt;/code&gt; and shifting &lt;code&gt;%rsp&lt;/code&gt; thus allocating space on&amp;nbsp;stack. This is&amp;nbsp;called function prologue and it&amp;nbsp;was absent in&amp;nbsp;our assembly function without printk.&lt;/p&gt;
&lt;p&gt;You need this stack manipulation later to&amp;nbsp;access your local vars by&amp;nbsp;subtracting from &lt;code&gt;%rbp&lt;/code&gt;. But we&amp;nbsp;were subtratcting from &lt;code&gt;%rsp&lt;/code&gt;, isn’t&amp;nbsp;it&amp;nbsp;strange?&lt;/p&gt;
&lt;p&gt;Wait a&amp;nbsp;minute&amp;hellip; I&amp;nbsp;decided to&amp;nbsp;draw stack frame and got it!&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img src="/assets/img/red-zone.png" alt="Stack" /&gt;
&lt;p class="caption"&gt;Stack&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Holy shucks! We&amp;nbsp;are processing undefined memory. All instructions like this&lt;/p&gt;
&lt;pre class="asm"&gt;&lt;code&gt;movdqa  -24(%rsp), %xmm0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;moving aligned data from &lt;code&gt;xmm0&lt;/code&gt; to&amp;nbsp;address &lt;code&gt;&lt;nobr&gt;rsp-24&lt;/nobr&gt;&lt;/code&gt; is&amp;nbsp;actually the access over the top of&amp;nbsp;the stack!&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img src="https://mlpforums.com/uploads/monthly_03_2012/post-2103-0-68261500-1332210132.png" /&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;WHY?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I&amp;nbsp;was really shocked. So&amp;nbsp;shocked that I&amp;nbsp;even asked &lt;a href="http://stackoverflow.com/questions/20661190/gcc-access-memory-above-stack-top"&gt;on&amp;nbsp;stackoverflow&lt;/a&gt;. And the answer was&lt;/p&gt;
&lt;p&gt;&lt;span style="text-decoration:underline;color:red"&gt;&lt;a href="http://eli.thegreenplace.net/2011/09/06/stack-frame-layout-on-x86-64/"&gt;&lt;strong&gt;Red Zone&lt;/strong&gt;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In&amp;nbsp;short, &lt;em&gt;red zone&lt;/em&gt; is&amp;nbsp;a&amp;nbsp;memory piece of&amp;nbsp;size 128 bytes &lt;strong&gt;over stack top&lt;/strong&gt;, that according to&amp;nbsp;&lt;a href="http://www.x86-64.org/documentation/abi.pdf"&gt;amd64 ABI&lt;/a&gt; should not be&amp;nbsp;accessed by&amp;nbsp;any interrupt or&amp;nbsp;signal handlers. And it&amp;nbsp;was rock solid true, but for userspace. When you are in&amp;nbsp;kernel space leave the hope for extra memory&amp;nbsp;&amp;mdash; stack is&amp;nbsp;worth its weight in&amp;nbsp;gold here. And you got a&amp;nbsp;whole lot of&amp;nbsp;interrupt handling here.&lt;/p&gt;
&lt;p&gt;When interruption occurs, the interrupt handler uses stack frame of&amp;nbsp;current kernel thread, but to&amp;nbsp;avoid thread data corruption it&amp;nbsp;holds it’s&amp;nbsp;own data over stack top. And when our own code were compiled with red zone support the thread data were located over stack top as&amp;nbsp;much as&amp;nbsp;interrupt handlers data.&lt;/p&gt;
&lt;p&gt;That’s&amp;nbsp;why kernel compilation is&amp;nbsp;done with &lt;code&gt;-&lt;nobr&gt;mno-red-zone&lt;/nobr&gt;&lt;/code&gt; gcc flag. It’s&amp;nbsp;set implicitly by&amp;nbsp;&lt;code&gt;kbuild&lt;/code&gt;&lt;a href="#fn2" class="footnoteRef" id="fnref2"&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;But remember that we&amp;nbsp;weren’t&amp;nbsp;be&amp;nbsp;able to&amp;nbsp;build with &lt;code&gt;kbuild&lt;/code&gt; because it&amp;nbsp;was crashing every time due to&amp;nbsp;huge files.&lt;/p&gt;
&lt;p&gt;Anyway, we&amp;nbsp;just added in&amp;nbsp;our Makefile &lt;code&gt;EXTRA_CFLAGS += -&lt;nobr&gt;mno-red-zone&lt;/nobr&gt;&lt;/code&gt; and it’s&amp;nbsp;working now. But still I&amp;nbsp;have a&amp;nbsp;question why adding &lt;code&gt;printk(&amp;laquo;&amp;laquo;)&lt;/code&gt; leads to&amp;nbsp;preventing using red zone and space allocation for local variables with &lt;code&gt;subq $24, %rsp&lt;/code&gt;?&lt;/p&gt;
&lt;p&gt;So, that day I&amp;nbsp;learned a&amp;nbsp;&lt;a href="http://programmers.stackexchange.com/questions/230089/what-is-the-purpose-of-red-zone"&gt;really tricky optimization&lt;/a&gt; that at&amp;nbsp;the cost of&amp;nbsp;potential memory corruption could save you couple of&amp;nbsp;instructions for every leaf function.&lt;/p&gt;
&lt;p&gt;That’s&amp;nbsp;all, folks!&lt;/p&gt;
&lt;div class="footnotes"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn1"&gt;&lt;p&gt;Crashed only as&amp;nbsp;part of&amp;nbsp;kbuild and only on&amp;nbsp;version 4.4.&lt;a href="#fnref1"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn2"&gt;&lt;p&gt;To&amp;nbsp;get all flags that kbuild set one can simply look at&amp;nbsp;&lt;code&gt;.&amp;lt;source&amp;gt;.o.cmd&lt;/code&gt;.&lt;a href="#fnref2"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content>
  </entry>
</feed>
